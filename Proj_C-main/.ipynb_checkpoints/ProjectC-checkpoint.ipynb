{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qaZRxm5SbPuD"
   },
   "outputs": [],
   "source": [
    "## Import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L40GTLgScB3i"
   },
   "outputs": [],
   "source": [
    "## Import autograd\n",
    "import autograd.numpy as ag_np\n",
    "import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZEdkE_xscDHa"
   },
   "outputs": [],
   "source": [
    "# Import plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OGBdQ2pUcG-I"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import autograd.numpy as ag_np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HIsIWSI6cII6"
   },
   "outputs": [],
   "source": [
    "from AbstractBaseCollabFilterSGD import AbstractBaseCollabFilterSGD\n",
    "from CollabFilterMeanOnly import CollabFilterMeanOnly\n",
    "from CollabFilterOneScalarPerItem import CollabFilterOneScalarPerItem\n",
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem\n",
    "from train_valid_test_loader import load_train_valid_test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BP1W90PtcPZ5"
   },
   "outputs": [],
   "source": [
    "data_path = 'data_movie_lens_100k/' # Path to where dataset csv files live on your system\n",
    "train_tuple, test_tuple, valid_tuple, n_users, n_items = load_train_valid_test_datasets(data_path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6DRKtqw1iMIT"
   },
   "outputs": [],
   "source": [
    "SEED = 101\n",
    "M1 = CollabFilterMeanOnly(batch_size=100, random_state=SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "Ld8OfKjTjMMo",
    "outputId": "7760a1e2-a762-40c7-975d-f87cf34d1275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total    14.56000 | train_MAE     3.53059 | valid_MAE     3.50620 | grad_wrt_mu     7.28000\n",
      "epoch       0.001 | loss_total    10.02910 | train_MAE     2.80259 | valid_MAE     2.77820 | grad_wrt_mu     6.00400\n",
      "epoch       0.003 | loss_total     6.12301 | train_MAE     2.24249 | valid_MAE     2.21846 | grad_wrt_mu     4.44320\n",
      "epoch       0.004 | loss_total     4.84986 | train_MAE     1.85269 | valid_MAE     1.82914 | grad_wrt_mu     3.83456\n",
      "epoch       0.126 | loss_total     1.34168 | train_MAE     0.94225 | valid_MAE     0.94411 | grad_wrt_mu     0.28129\n",
      "epoch       0.250 | loss_total     1.35873 | train_MAE     0.93863 | valid_MAE     0.94144 | grad_wrt_mu     0.42723\n",
      "epoch       0.376 | loss_total     1.20521 | train_MAE     0.94343 | valid_MAE     0.94498 | grad_wrt_mu     0.08034\n",
      "epoch       0.500 | loss_total     1.35773 | train_MAE     0.94159 | valid_MAE     0.94363 | grad_wrt_mu     0.19321\n",
      "epoch       0.626 | loss_total     1.40530 | train_MAE     0.94598 | valid_MAE     0.94686 | grad_wrt_mu     0.26681\n",
      "epoch       0.750 | loss_total     1.49975 | train_MAE     0.95176 | valid_MAE     0.95112 | grad_wrt_mu     0.24782\n",
      "epoch       0.876 | loss_total     1.25721 | train_MAE     0.93905 | valid_MAE     0.94175 | grad_wrt_mu     0.08028\n",
      "epoch       1.000 | loss_total     1.14653 | train_MAE     0.94257 | valid_MAE     0.94435 | grad_wrt_mu     0.44466\n",
      "epoch       1.126 | loss_total     1.25544 | train_MAE     0.93885 | valid_MAE     0.94160 | grad_wrt_mu     0.09675\n",
      "epoch       1.250 | loss_total     1.44932 | train_MAE     0.94948 | valid_MAE     0.94944 | grad_wrt_mu     0.02940\n",
      "epoch       1.376 | loss_total     1.21700 | train_MAE     0.95068 | valid_MAE     0.95032 | grad_wrt_mu     0.29256\n",
      "epoch       1.500 | loss_total     1.20728 | train_MAE     0.94598 | valid_MAE     0.94686 | grad_wrt_mu     0.14675\n",
      "epoch       1.626 | loss_total     1.35587 | train_MAE     0.94078 | valid_MAE     0.94303 | grad_wrt_mu     0.46805\n",
      "epoch       1.750 | loss_total     0.99220 | train_MAE     0.94002 | valid_MAE     0.94247 | grad_wrt_mu     0.10192\n",
      "epoch       1.876 | loss_total     1.37012 | train_MAE     0.94786 | valid_MAE     0.94825 | grad_wrt_mu     0.20117\n",
      "epoch       2.000 | loss_total     1.28962 | train_MAE     0.93958 | valid_MAE     0.94214 | grad_wrt_mu     0.06991\n",
      "epoch       2.500 | loss_total     1.26867 | train_MAE     0.93985 | valid_MAE     0.94234 | grad_wrt_mu     0.70499\n",
      "epoch       3.000 | loss_total     1.26880 | train_MAE     0.94895 | valid_MAE     0.94905 | grad_wrt_mu     0.34099\n",
      "epoch       3.500 | loss_total     1.27416 | train_MAE     0.94185 | valid_MAE     0.94381 | grad_wrt_mu     0.38860\n",
      "epoch       4.000 | loss_total     1.26927 | train_MAE     0.94767 | valid_MAE     0.94810 | grad_wrt_mu     0.08240\n",
      "epoch       4.500 | loss_total     1.27065 | train_MAE     0.94752 | valid_MAE     0.94800 | grad_wrt_mu     0.02502\n",
      "epoch       5.000 | loss_total     1.26862 | train_MAE     0.94526 | valid_MAE     0.94633 | grad_wrt_mu     0.13371\n",
      "epoch       5.500 | loss_total     1.26448 | train_MAE     0.94222 | valid_MAE     0.94409 | grad_wrt_mu     0.10179\n",
      "epoch       6.000 | loss_total     1.26904 | train_MAE     0.95106 | valid_MAE     0.95060 | grad_wrt_mu     0.17942\n",
      "epoch       6.500 | loss_total     1.26909 | train_MAE     0.94479 | valid_MAE     0.94598 | grad_wrt_mu     0.26507\n",
      "epoch       7.000 | loss_total     1.26870 | train_MAE     0.94372 | valid_MAE     0.94519 | grad_wrt_mu     0.08560\n",
      "epoch       7.500 | loss_total     1.27601 | train_MAE     0.94284 | valid_MAE     0.94455 | grad_wrt_mu     0.12960\n",
      "epoch       8.000 | loss_total     1.26889 | train_MAE     0.94746 | valid_MAE     0.94795 | grad_wrt_mu     0.42612\n",
      "epoch       9.000 | loss_total     1.26855 | train_MAE     0.94078 | valid_MAE     0.94303 | grad_wrt_mu     0.15198\n",
      "epoch      10.000 | loss_total     1.26861 | train_MAE     0.94468 | valid_MAE     0.94590 | grad_wrt_mu     0.26308\n",
      "epoch      11.000 | loss_total     1.26911 | train_MAE     0.94671 | valid_MAE     0.94739 | grad_wrt_mu     0.12005\n",
      "epoch      12.000 | loss_total     1.26859 | train_MAE     0.94606 | valid_MAE     0.94692 | grad_wrt_mu     0.04826\n",
      "epoch      13.000 | loss_total     1.26935 | train_MAE     0.95029 | valid_MAE     0.95004 | grad_wrt_mu     0.30549\n",
      "epoch      14.000 | loss_total     1.26851 | train_MAE     0.94315 | valid_MAE     0.94477 | grad_wrt_mu     0.25509\n",
      "epoch      15.000 | loss_total     1.26867 | train_MAE     0.94135 | valid_MAE     0.94345 | grad_wrt_mu     0.05760\n",
      "epoch      16.000 | loss_total     1.26889 | train_MAE     0.94646 | valid_MAE     0.94721 | grad_wrt_mu     0.16445\n",
      "epoch      17.000 | loss_total     1.26902 | train_MAE     0.94152 | valid_MAE     0.94357 | grad_wrt_mu     0.12545\n",
      "epoch      18.000 | loss_total     1.26928 | train_MAE     0.93895 | valid_MAE     0.94168 | grad_wrt_mu     0.01855\n",
      "epoch      19.000 | loss_total     1.26905 | train_MAE     0.94130 | valid_MAE     0.94341 | grad_wrt_mu     0.12135\n",
      "epoch      20.000 | loss_total     1.26884 | train_MAE     0.94587 | valid_MAE     0.94678 | grad_wrt_mu     0.03527\n",
      "epoch      21.000 | loss_total     1.26862 | train_MAE     0.94469 | valid_MAE     0.94590 | grad_wrt_mu     0.01682\n",
      "epoch      22.000 | loss_total     1.26945 | train_MAE     0.94626 | valid_MAE     0.94707 | grad_wrt_mu     0.08806\n",
      "epoch      23.000 | loss_total     1.26836 | train_MAE     0.93832 | valid_MAE     0.94122 | grad_wrt_mu     0.09287\n",
      "epoch      24.000 | loss_total     1.26898 | train_MAE     0.93770 | valid_MAE     0.94075 | grad_wrt_mu     0.40429\n",
      "epoch      25.000 | loss_total     1.26834 | train_MAE     0.94472 | valid_MAE     0.94593 | grad_wrt_mu     0.42379\n",
      "epoch      26.000 | loss_total     1.26932 | train_MAE     0.94242 | valid_MAE     0.94423 | grad_wrt_mu     0.31814\n",
      "epoch      27.000 | loss_total     1.26841 | train_MAE     0.93922 | valid_MAE     0.94188 | grad_wrt_mu     0.33652\n",
      "epoch      28.000 | loss_total     1.26861 | train_MAE     0.94584 | valid_MAE     0.94675 | grad_wrt_mu     0.29581\n",
      "epoch      29.000 | loss_total     1.26875 | train_MAE     0.94817 | valid_MAE     0.94848 | grad_wrt_mu     0.25317\n",
      "epoch      30.000 | loss_total     1.26878 | train_MAE     0.94086 | valid_MAE     0.94308 | grad_wrt_mu     0.40668\n",
      "epoch      31.000 | loss_total     1.26880 | train_MAE     0.94463 | valid_MAE     0.94587 | grad_wrt_mu     0.07778\n",
      "epoch      32.000 | loss_total     1.26920 | train_MAE     0.94467 | valid_MAE     0.94589 | grad_wrt_mu     0.11710\n",
      "epoch      34.000 | loss_total     1.26835 | train_MAE     0.93516 | valid_MAE     0.93888 | grad_wrt_mu     0.14940\n",
      "epoch      36.000 | loss_total     1.26903 | train_MAE     0.94012 | valid_MAE     0.94254 | grad_wrt_mu     0.04006\n",
      "epoch      38.000 | loss_total     1.26912 | train_MAE     0.95004 | valid_MAE     0.94985 | grad_wrt_mu     0.10079\n",
      "epoch      40.000 | loss_total     1.26876 | train_MAE     0.95161 | valid_MAE     0.95101 | grad_wrt_mu     0.19046\n",
      "epoch      42.000 | loss_total     1.26855 | train_MAE     0.94525 | valid_MAE     0.94632 | grad_wrt_mu     0.04650\n",
      "epoch      44.000 | loss_total     1.26849 | train_MAE     0.94328 | valid_MAE     0.94487 | grad_wrt_mu     0.14251\n",
      "epoch      46.000 | loss_total     1.26899 | train_MAE     0.95680 | valid_MAE     0.95483 | grad_wrt_mu     0.00416\n",
      "epoch      48.000 | loss_total     1.26905 | train_MAE     0.93983 | valid_MAE     0.94233 | grad_wrt_mu     0.09465\n",
      "epoch      50.000 | loss_total     1.26798 | train_MAE     0.93616 | valid_MAE     0.93962 | grad_wrt_mu     0.19235\n",
      "epoch      52.000 | loss_total     1.26931 | train_MAE     0.94625 | valid_MAE     0.94706 | grad_wrt_mu     0.14826\n",
      "epoch      54.000 | loss_total     1.26832 | train_MAE     0.94659 | valid_MAE     0.94731 | grad_wrt_mu     0.16210\n",
      "epoch      56.000 | loss_total     1.26840 | train_MAE     0.94389 | valid_MAE     0.94532 | grad_wrt_mu     0.21127\n",
      "epoch      58.000 | loss_total     1.26890 | train_MAE     0.94202 | valid_MAE     0.94394 | grad_wrt_mu     0.06541\n",
      "epoch      60.000 | loss_total     1.26907 | train_MAE     0.94878 | valid_MAE     0.94892 | grad_wrt_mu     0.12210\n",
      "epoch      62.000 | loss_total     1.26870 | train_MAE     0.94554 | valid_MAE     0.94653 | grad_wrt_mu     0.43869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      64.000 | loss_total     1.26875 | train_MAE     0.94376 | valid_MAE     0.94522 | grad_wrt_mu     0.08626\n",
      "epoch      66.000 | loss_total     1.26898 | train_MAE     0.94968 | valid_MAE     0.94959 | grad_wrt_mu     0.51429\n",
      "epoch      68.000 | loss_total     1.26842 | train_MAE     0.94377 | valid_MAE     0.94523 | grad_wrt_mu     0.17356\n",
      "epoch      70.000 | loss_total     1.26925 | train_MAE     0.94749 | valid_MAE     0.94797 | grad_wrt_mu     0.14568\n",
      "epoch      72.000 | loss_total     1.26930 | train_MAE     0.94604 | valid_MAE     0.94691 | grad_wrt_mu     0.16795\n",
      "epoch      74.000 | loss_total     1.26876 | train_MAE     0.94675 | valid_MAE     0.94743 | grad_wrt_mu     0.17911\n",
      "epoch      76.000 | loss_total     1.26916 | train_MAE     0.94844 | valid_MAE     0.94867 | grad_wrt_mu     0.31171\n",
      "epoch      78.000 | loss_total     1.26852 | train_MAE     0.94509 | valid_MAE     0.94620 | grad_wrt_mu     0.11048\n",
      "epoch      80.000 | loss_total     1.26866 | train_MAE     0.94166 | valid_MAE     0.94367 | grad_wrt_mu     0.17205\n",
      "epoch      82.000 | loss_total     1.26957 | train_MAE     0.94100 | valid_MAE     0.94319 | grad_wrt_mu     0.38402\n",
      "epoch      84.000 | loss_total     1.26895 | train_MAE     0.94932 | valid_MAE     0.94932 | grad_wrt_mu     0.37236\n",
      "epoch      86.000 | loss_total     1.26907 | train_MAE     0.93839 | valid_MAE     0.94126 | grad_wrt_mu     0.53171\n",
      "epoch      88.000 | loss_total     1.26855 | train_MAE     0.94073 | valid_MAE     0.94299 | grad_wrt_mu     0.24900\n",
      "epoch      90.000 | loss_total     1.26860 | train_MAE     0.94792 | valid_MAE     0.94829 | grad_wrt_mu     0.07779\n",
      "epoch      92.000 | loss_total     1.26869 | train_MAE     0.94507 | valid_MAE     0.94619 | grad_wrt_mu     0.48980\n",
      "epoch      94.000 | loss_total     1.26917 | train_MAE     0.95330 | valid_MAE     0.95225 | grad_wrt_mu     0.25965\n",
      "epoch      96.000 | loss_total     1.26911 | train_MAE     0.94839 | valid_MAE     0.94863 | grad_wrt_mu     0.05071\n",
      "epoch      98.000 | loss_total     1.26867 | train_MAE     0.94688 | valid_MAE     0.94752 | grad_wrt_mu     0.18326\n",
      "epoch      99.999 | loss_total     1.26859 | train_MAE     0.95093 | valid_MAE     0.95050 | grad_wrt_mu     0.00297\n"
     ]
    }
   ],
   "source": [
    "M1.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M1.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPosyRtJkdc7",
    "outputId": "90aeb84a-6266-41df-84bd-88bae000b176"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu': array([3.47118788])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1.param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch size 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_10000 = CollabFilterMeanOnly(batch_size=10000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total    13.78920 | train_MAE     3.53059 | valid_MAE     3.50620 | grad_wrt_mu     7.07640\n",
      "epoch       0.143 | loss_total     9.10570 | train_MAE     2.82295 | valid_MAE     2.79856 | grad_wrt_mu     5.60192\n",
      "epoch       0.286 | loss_total     6.37457 | train_MAE     2.29562 | valid_MAE     2.27153 | grad_wrt_mu     4.50654\n",
      "epoch       0.429 | loss_total     4.57906 | train_MAE     1.90027 | valid_MAE     1.87666 | grad_wrt_mu     3.64143\n",
      "epoch       0.571 | loss_total     3.38356 | train_MAE     1.59953 | valid_MAE     1.57700 | grad_wrt_mu     2.90954\n",
      "epoch       0.714 | loss_total     2.59510 | train_MAE     1.41022 | valid_MAE     1.39038 | grad_wrt_mu     2.31523\n",
      "epoch       0.857 | loss_total     2.12756 | train_MAE     1.25957 | valid_MAE     1.24188 | grad_wrt_mu     1.86659\n",
      "epoch       1.000 | loss_total     1.80878 | train_MAE     1.13811 | valid_MAE     1.12216 | grad_wrt_mu     1.47547\n",
      "epoch       1.143 | loss_total     1.59192 | train_MAE     1.04210 | valid_MAE     1.02753 | grad_wrt_mu     1.15838\n",
      "epoch       1.286 | loss_total     1.47737 | train_MAE     0.99657 | valid_MAE     0.98414 | grad_wrt_mu     0.97350\n",
      "epoch       1.429 | loss_total     1.39973 | train_MAE     0.98590 | valid_MAE     0.97628 | grad_wrt_mu     0.74500\n",
      "epoch       1.571 | loss_total     1.39008 | train_MAE     0.97773 | valid_MAE     0.97026 | grad_wrt_mu     0.61760\n",
      "epoch       1.714 | loss_total     1.32422 | train_MAE     0.97096 | valid_MAE     0.96527 | grad_wrt_mu     0.47168\n",
      "epoch       1.857 | loss_total     1.32665 | train_MAE     0.96579 | valid_MAE     0.96146 | grad_wrt_mu     0.40574\n",
      "epoch       2.000 | loss_total     1.25979 | train_MAE     0.96134 | valid_MAE     0.95818 | grad_wrt_mu     0.29020\n",
      "epoch       2.571 | loss_total     1.28816 | train_MAE     0.95129 | valid_MAE     0.95077 | grad_wrt_mu     0.13458\n",
      "epoch       3.000 | loss_total     1.27741 | train_MAE     0.94807 | valid_MAE     0.94840 | grad_wrt_mu     0.08057\n",
      "epoch       3.571 | loss_total     1.27596 | train_MAE     0.94579 | valid_MAE     0.94672 | grad_wrt_mu     0.00977\n",
      "epoch       4.000 | loss_total     1.26956 | train_MAE     0.94526 | valid_MAE     0.94633 | grad_wrt_mu     0.01152\n",
      "epoch       4.571 | loss_total     1.26402 | train_MAE     0.94501 | valid_MAE     0.94614 | grad_wrt_mu     0.03687\n",
      "epoch       5.000 | loss_total     1.26317 | train_MAE     0.94451 | valid_MAE     0.94578 | grad_wrt_mu     0.02678\n",
      "epoch       5.571 | loss_total     1.26422 | train_MAE     0.94463 | valid_MAE     0.94587 | grad_wrt_mu     0.02283\n",
      "epoch       6.000 | loss_total     1.27236 | train_MAE     0.94446 | valid_MAE     0.94574 | grad_wrt_mu     0.01371\n",
      "epoch       6.571 | loss_total     1.27010 | train_MAE     0.94414 | valid_MAE     0.94550 | grad_wrt_mu     0.03318\n",
      "epoch       7.000 | loss_total     1.26484 | train_MAE     0.94464 | valid_MAE     0.94587 | grad_wrt_mu     0.01827\n",
      "epoch       7.571 | loss_total     1.27158 | train_MAE     0.94461 | valid_MAE     0.94585 | grad_wrt_mu     0.00082\n",
      "epoch       8.000 | loss_total     1.26769 | train_MAE     0.94439 | valid_MAE     0.94568 | grad_wrt_mu     0.02849\n",
      "epoch       9.000 | loss_total     1.26405 | train_MAE     0.94448 | valid_MAE     0.94575 | grad_wrt_mu     0.00056\n",
      "epoch      10.000 | loss_total     1.27104 | train_MAE     0.94418 | valid_MAE     0.94553 | grad_wrt_mu     0.00732\n",
      "epoch      11.000 | loss_total     1.26778 | train_MAE     0.94465 | valid_MAE     0.94588 | grad_wrt_mu     0.02866\n",
      "epoch      12.000 | loss_total     1.26471 | train_MAE     0.94455 | valid_MAE     0.94580 | grad_wrt_mu     0.01390\n",
      "epoch      13.000 | loss_total     1.26661 | train_MAE     0.94482 | valid_MAE     0.94600 | grad_wrt_mu     0.03039\n",
      "epoch      14.000 | loss_total     1.27327 | train_MAE     0.94495 | valid_MAE     0.94610 | grad_wrt_mu     0.00318\n",
      "epoch      15.000 | loss_total     1.26129 | train_MAE     0.94434 | valid_MAE     0.94565 | grad_wrt_mu     0.00106\n",
      "epoch      16.000 | loss_total     1.26939 | train_MAE     0.94432 | valid_MAE     0.94564 | grad_wrt_mu     0.01077\n",
      "epoch      17.000 | loss_total     1.27127 | train_MAE     0.94456 | valid_MAE     0.94581 | grad_wrt_mu     0.02931\n",
      "epoch      18.000 | loss_total     1.26164 | train_MAE     0.94440 | valid_MAE     0.94569 | grad_wrt_mu     0.03070\n",
      "epoch      19.000 | loss_total     1.26799 | train_MAE     0.94467 | valid_MAE     0.94589 | grad_wrt_mu     0.02908\n",
      "epoch      20.000 | loss_total     1.26856 | train_MAE     0.94442 | valid_MAE     0.94571 | grad_wrt_mu     0.02882\n",
      "epoch      21.000 | loss_total     1.26982 | train_MAE     0.94431 | valid_MAE     0.94562 | grad_wrt_mu     0.00564\n",
      "epoch      22.000 | loss_total     1.26421 | train_MAE     0.94452 | valid_MAE     0.94578 | grad_wrt_mu     0.02339\n",
      "epoch      23.000 | loss_total     1.27224 | train_MAE     0.94444 | valid_MAE     0.94573 | grad_wrt_mu     0.01343\n",
      "epoch      24.000 | loss_total     1.26644 | train_MAE     0.94408 | valid_MAE     0.94546 | grad_wrt_mu     0.02198\n",
      "epoch      25.000 | loss_total     1.26551 | train_MAE     0.94445 | valid_MAE     0.94573 | grad_wrt_mu     0.02770\n",
      "epoch      26.000 | loss_total     1.26874 | train_MAE     0.94428 | valid_MAE     0.94561 | grad_wrt_mu     0.00606\n",
      "epoch      27.000 | loss_total     1.26461 | train_MAE     0.94428 | valid_MAE     0.94561 | grad_wrt_mu     0.00719\n",
      "epoch      28.000 | loss_total     1.26745 | train_MAE     0.94443 | valid_MAE     0.94572 | grad_wrt_mu     0.01607\n",
      "epoch      29.000 | loss_total     1.26747 | train_MAE     0.94440 | valid_MAE     0.94569 | grad_wrt_mu     0.00512\n",
      "epoch      30.000 | loss_total     1.26324 | train_MAE     0.94443 | valid_MAE     0.94572 | grad_wrt_mu     0.01146\n",
      "epoch      31.000 | loss_total     1.27147 | train_MAE     0.94439 | valid_MAE     0.94569 | grad_wrt_mu     0.01858\n",
      "epoch      32.000 | loss_total     1.26769 | train_MAE     0.94444 | valid_MAE     0.94572 | grad_wrt_mu     0.00313\n",
      "epoch      34.000 | loss_total     1.26032 | train_MAE     0.94432 | valid_MAE     0.94563 | grad_wrt_mu     0.00786\n",
      "epoch      36.000 | loss_total     1.26766 | train_MAE     0.94433 | valid_MAE     0.94564 | grad_wrt_mu     0.00435\n",
      "epoch      38.000 | loss_total     1.26481 | train_MAE     0.94464 | valid_MAE     0.94587 | grad_wrt_mu     0.00383\n",
      "epoch      40.000 | loss_total     1.27096 | train_MAE     0.94412 | valid_MAE     0.94549 | grad_wrt_mu     0.04355\n",
      "epoch      42.000 | loss_total     1.27024 | train_MAE     0.94468 | valid_MAE     0.94590 | grad_wrt_mu     0.01221\n",
      "epoch      44.000 | loss_total     1.26239 | train_MAE     0.94425 | valid_MAE     0.94559 | grad_wrt_mu     0.02768\n",
      "epoch      46.000 | loss_total     1.26614 | train_MAE     0.94477 | valid_MAE     0.94597 | grad_wrt_mu     0.01429\n",
      "epoch      48.000 | loss_total     1.27197 | train_MAE     0.94454 | valid_MAE     0.94580 | grad_wrt_mu     0.00327\n",
      "epoch      50.000 | loss_total     1.27125 | train_MAE     0.94439 | valid_MAE     0.94569 | grad_wrt_mu     0.00360\n",
      "epoch      52.000 | loss_total     1.26778 | train_MAE     0.94444 | valid_MAE     0.94572 | grad_wrt_mu     0.03548\n",
      "epoch      54.000 | loss_total     1.26766 | train_MAE     0.94419 | valid_MAE     0.94554 | grad_wrt_mu     0.02260\n",
      "epoch      56.000 | loss_total     1.26664 | train_MAE     0.94426 | valid_MAE     0.94559 | grad_wrt_mu     0.01605\n",
      "epoch      58.000 | loss_total     1.26510 | train_MAE     0.94433 | valid_MAE     0.94564 | grad_wrt_mu     0.01024\n",
      "epoch      60.000 | loss_total     1.26406 | train_MAE     0.94452 | valid_MAE     0.94578 | grad_wrt_mu     0.01548\n",
      "epoch      62.000 | loss_total     1.26596 | train_MAE     0.94444 | valid_MAE     0.94572 | grad_wrt_mu     0.04091\n",
      "epoch      64.000 | loss_total     1.26815 | train_MAE     0.94427 | valid_MAE     0.94560 | grad_wrt_mu     0.00062\n",
      "epoch      66.000 | loss_total     1.26875 | train_MAE     0.94462 | valid_MAE     0.94586 | grad_wrt_mu     0.00698\n",
      "epoch      68.000 | loss_total     1.26868 | train_MAE     0.94409 | valid_MAE     0.94546 | grad_wrt_mu     0.00166\n",
      "epoch      70.000 | loss_total     1.26849 | train_MAE     0.94459 | valid_MAE     0.94583 | grad_wrt_mu     0.00100\n",
      "epoch      72.000 | loss_total     1.27018 | train_MAE     0.94447 | valid_MAE     0.94575 | grad_wrt_mu     0.00370\n",
      "epoch      74.000 | loss_total     1.26768 | train_MAE     0.94444 | valid_MAE     0.94573 | grad_wrt_mu     0.00055\n",
      "epoch      76.000 | loss_total     1.26821 | train_MAE     0.94449 | valid_MAE     0.94576 | grad_wrt_mu     0.00750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      78.000 | loss_total     1.26823 | train_MAE     0.94426 | valid_MAE     0.94559 | grad_wrt_mu     0.04199\n",
      "epoch      80.000 | loss_total     1.26496 | train_MAE     0.94443 | valid_MAE     0.94571 | grad_wrt_mu     0.02132\n",
      "epoch      82.000 | loss_total     1.27333 | train_MAE     0.94455 | valid_MAE     0.94580 | grad_wrt_mu     0.01715\n",
      "epoch      84.000 | loss_total     1.27120 | train_MAE     0.94445 | valid_MAE     0.94573 | grad_wrt_mu     0.00964\n",
      "epoch      86.000 | loss_total     1.26787 | train_MAE     0.94462 | valid_MAE     0.94586 | grad_wrt_mu     0.01343\n",
      "epoch      88.000 | loss_total     1.26328 | train_MAE     0.94438 | valid_MAE     0.94568 | grad_wrt_mu     0.00886\n",
      "epoch      90.000 | loss_total     1.27296 | train_MAE     0.94467 | valid_MAE     0.94590 | grad_wrt_mu     0.01157\n",
      "epoch      92.000 | loss_total     1.26876 | train_MAE     0.94493 | valid_MAE     0.94608 | grad_wrt_mu     0.00084\n",
      "epoch      94.000 | loss_total     1.26972 | train_MAE     0.94451 | valid_MAE     0.94577 | grad_wrt_mu     0.00590\n",
      "epoch      96.000 | loss_total     1.26604 | train_MAE     0.94470 | valid_MAE     0.94592 | grad_wrt_mu     0.01592\n",
      "epoch      98.000 | loss_total     1.26730 | train_MAE     0.94436 | valid_MAE     0.94566 | grad_wrt_mu     0.00779\n",
      "epoch      99.857 | loss_total     1.26742 | train_MAE     0.94424 | valid_MAE     0.94558 | grad_wrt_mu     0.03826\n"
     ]
    }
   ],
   "source": [
    "M1_10000.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M1_10000.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu': array([3.52860334])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_10000.param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose the model with batch zise = 100. mu = 3.5290442, MAE validation = 0.94584."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([772, 471, 641, ..., 926, 522, 788]),\n",
       " array([ 36, 228, 401, ...,  94, 547, 247]),\n",
       " array([3, 5, 4, ..., 5, 4, 3]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9505280194568044"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid\n",
    "ratigs_hat_va_M1 = M1.predict(valid_tuple[0], valid_tuple[1], M1.param_dict['mu'])\n",
    "metrics.mean_absolute_error(valid_tuple[2], ratigs_hat_va_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951795841614518"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "ratigs_hat_test_M1 = M1.predict(test_tuple[0], test_tuple[1], M1.param_dict['mu'])\n",
    "metrics.mean_absolute_error(test_tuple[2], ratigs_hat_test_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9458888500752332"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid batch size 10000\n",
    "ratigs_hat_va_M1_10000 = M1_10000.predict(valid_tuple[0], valid_tuple[1])\n",
    "metrics.mean_absolute_error(valid_tuple[2], ratigs_hat_va_M1_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9449464389453122"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test batch size 10000\n",
    "ratigs_hat_test_M1_10000 = M1_10000.predict(test_tuple[0], test_tuple[1])\n",
    "metrics.mean_absolute_error(test_tuple[2], ratigs_hat_test_M1_10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8053885407266962, 3.6603570082647154) (0.94, 0.97)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5)) #, sharex=True, sharey=True)\n",
    "ax[0].plot(M2.trace_epoch, M2.trace_mae_train, '-b',  label='train')\n",
    "ax[0].plot(M2.trace_epoch, M2.trace_mae_valid, '.r', label='validation')\n",
    "ax[1].plot(M1.trace_epoch, M1.trace_mae_train, '-b')\n",
    "ax[1].plot(M1.trace_epoch, M1.trace_mae_valid, '.r')\n",
    "\n",
    "ax[0].set_xlabel('epochs');\n",
    "ax[0].set_ylabel('MAE');\n",
    "\n",
    "ax[1].set_xlabel('epochs');\n",
    "ax[1].set_ylabel('MAE');\n",
    "\n",
    "ax[1].set_title('Batch Size = 100')\n",
    "ax[0].set_title('Batch Size = 10000');\n",
    "\n",
    "pre = ax[1].get_xlim()\n",
    "ax[1].set_xlim(left=2)\n",
    "post = ax[1].get_xlim()\n",
    "\n",
    "pre = ax[1].get_ylim()\n",
    "ax[1].set_ylim(bottom=0.94, top=0.97)\n",
    "post = ax[1].get_ylim()\n",
    "print(pre, post)\n",
    "\n",
    "ax[1].legend(bbox_to_anchor=(1.5, 0.5));\n",
    "plt.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5305857142857144"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mu = np.mean(train_tuple[2])\n",
    "true_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 101\n",
    "M2_100 = CollabFilterOneScalarPerItem(batch_size=100, random_state=SEED)\n",
    "M2_10000 = CollabFilterOneScalarPerItem(batch_size=10000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total    14.56000 | train_MAE     3.53059 | valid_MAE     3.50620 | grad_wrt_mu     7.28000 | grad_wrt_b_per_user     0.00772 | grad_wrt_c_per_item     0.00433\n",
      "epoch       0.001 | loss_total    10.00658 | train_MAE     2.79995 | valid_MAE     2.77560 | grad_wrt_mu     5.99664 | grad_wrt_b_per_user     0.00636 | grad_wrt_c_per_item     0.00357\n",
      "epoch       0.003 | loss_total     6.10266 | train_MAE     2.23866 | valid_MAE     2.21469 | grad_wrt_mu     4.43384 | grad_wrt_b_per_user     0.00477 | grad_wrt_c_per_item     0.00268\n",
      "epoch       0.004 | loss_total     4.82917 | train_MAE     1.84801 | valid_MAE     1.82457 | grad_wrt_mu     3.82423 | grad_wrt_b_per_user     0.00419 | grad_wrt_c_per_item     0.00235\n",
      "epoch       0.126 | loss_total     1.30810 | train_MAE     0.93083 | valid_MAE     0.93331 | grad_wrt_mu     0.28271 | grad_wrt_b_per_user     0.00191 | grad_wrt_c_per_item     0.00108\n",
      "epoch       0.250 | loss_total     1.26684 | train_MAE     0.91717 | valid_MAE     0.92115 | grad_wrt_mu     0.39429 | grad_wrt_b_per_user     0.00193 | grad_wrt_c_per_item     0.00111\n",
      "epoch       0.376 | loss_total     1.14235 | train_MAE     0.91175 | valid_MAE     0.91502 | grad_wrt_mu     0.05743 | grad_wrt_b_per_user     0.00190 | grad_wrt_c_per_item     0.00104\n",
      "epoch       0.500 | loss_total     1.26969 | train_MAE     0.90161 | valid_MAE     0.90580 | grad_wrt_mu     0.21503 | grad_wrt_b_per_user     0.00187 | grad_wrt_c_per_item     0.00112\n",
      "epoch       0.626 | loss_total     1.28384 | train_MAE     0.89718 | valid_MAE     0.90096 | grad_wrt_mu     0.27564 | grad_wrt_b_per_user     0.00186 | grad_wrt_c_per_item     0.00108\n",
      "epoch       0.750 | loss_total     1.32251 | train_MAE     0.89445 | valid_MAE     0.89714 | grad_wrt_mu     0.23784 | grad_wrt_b_per_user     0.00192 | grad_wrt_c_per_item     0.00102\n",
      "epoch       0.876 | loss_total     1.17178 | train_MAE     0.87431 | valid_MAE     0.88068 | grad_wrt_mu     0.12682 | grad_wrt_b_per_user     0.00182 | grad_wrt_c_per_item     0.00105\n",
      "epoch       1.000 | loss_total     1.01315 | train_MAE     0.87169 | valid_MAE     0.87742 | grad_wrt_mu     0.37723 | grad_wrt_b_per_user     0.00173 | grad_wrt_c_per_item     0.00097\n",
      "epoch       1.126 | loss_total     1.09692 | train_MAE     0.86124 | valid_MAE     0.86859 | grad_wrt_mu     0.08014 | grad_wrt_b_per_user     0.00193 | grad_wrt_c_per_item     0.00106\n",
      "epoch       1.250 | loss_total     1.23614 | train_MAE     0.86497 | valid_MAE     0.86999 | grad_wrt_mu     0.08623 | grad_wrt_b_per_user     0.00187 | grad_wrt_c_per_item     0.00105\n",
      "epoch       1.376 | loss_total     1.00862 | train_MAE     0.86029 | valid_MAE     0.86536 | grad_wrt_mu     0.25780 | grad_wrt_b_per_user     0.00174 | grad_wrt_c_per_item     0.00100\n",
      "epoch       1.500 | loss_total     1.08807 | train_MAE     0.85135 | valid_MAE     0.85783 | grad_wrt_mu     0.19129 | grad_wrt_b_per_user     0.00173 | grad_wrt_c_per_item     0.00097\n",
      "epoch       1.626 | loss_total     1.16539 | train_MAE     0.83938 | valid_MAE     0.84803 | grad_wrt_mu     0.48051 | grad_wrt_b_per_user     0.00178 | grad_wrt_c_per_item     0.00095\n",
      "epoch       1.750 | loss_total     0.83552 | train_MAE     0.83465 | valid_MAE     0.84346 | grad_wrt_mu     0.12886 | grad_wrt_b_per_user     0.00146 | grad_wrt_c_per_item     0.00086\n",
      "epoch       1.876 | loss_total     1.12789 | train_MAE     0.83601 | valid_MAE     0.84335 | grad_wrt_mu     0.18680 | grad_wrt_b_per_user     0.00183 | grad_wrt_c_per_item     0.00096\n",
      "epoch       2.000 | loss_total     1.07631 | train_MAE     0.82489 | valid_MAE     0.83437 | grad_wrt_mu     0.07642 | grad_wrt_b_per_user     0.00171 | grad_wrt_c_per_item     0.00101\n",
      "epoch       2.500 | loss_total     1.03219 | train_MAE     0.81009 | valid_MAE     0.82045 | grad_wrt_mu     0.62507 | grad_wrt_b_per_user     0.00165 | grad_wrt_c_per_item     0.00097\n",
      "epoch       3.000 | loss_total     1.00759 | train_MAE     0.80626 | valid_MAE     0.81548 | grad_wrt_mu     0.25564 | grad_wrt_b_per_user     0.00157 | grad_wrt_c_per_item     0.00090\n",
      "epoch       3.500 | loss_total     0.99127 | train_MAE     0.79127 | valid_MAE     0.80320 | grad_wrt_mu     0.37374 | grad_wrt_b_per_user     0.00151 | grad_wrt_c_per_item     0.00090\n",
      "epoch       4.000 | loss_total     0.97310 | train_MAE     0.78852 | valid_MAE     0.79948 | grad_wrt_mu     0.00817 | grad_wrt_b_per_user     0.00165 | grad_wrt_c_per_item     0.00094\n",
      "epoch       4.500 | loss_total     0.96557 | train_MAE     0.78396 | valid_MAE     0.79516 | grad_wrt_mu     0.02888 | grad_wrt_b_per_user     0.00169 | grad_wrt_c_per_item     0.00092\n",
      "epoch       5.000 | loss_total     0.94948 | train_MAE     0.77494 | valid_MAE     0.78786 | grad_wrt_mu     0.07578 | grad_wrt_b_per_user     0.00157 | grad_wrt_c_per_item     0.00084\n",
      "epoch       5.500 | loss_total     0.93194 | train_MAE     0.76928 | valid_MAE     0.78304 | grad_wrt_mu     0.08599 | grad_wrt_b_per_user     0.00163 | grad_wrt_c_per_item     0.00097\n",
      "epoch       6.000 | loss_total     0.93265 | train_MAE     0.77154 | valid_MAE     0.78373 | grad_wrt_mu     0.11733 | grad_wrt_b_per_user     0.00141 | grad_wrt_c_per_item     0.00085\n",
      "epoch       6.500 | loss_total     0.92779 | train_MAE     0.76456 | valid_MAE     0.77820 | grad_wrt_mu     0.23977 | grad_wrt_b_per_user     0.00133 | grad_wrt_c_per_item     0.00076\n",
      "epoch       7.000 | loss_total     0.91958 | train_MAE     0.75988 | valid_MAE     0.77463 | grad_wrt_mu     0.10886 | grad_wrt_b_per_user     0.00143 | grad_wrt_c_per_item     0.00087\n",
      "epoch       7.500 | loss_total     0.91769 | train_MAE     0.75871 | valid_MAE     0.77322 | grad_wrt_mu     0.11055 | grad_wrt_b_per_user     0.00151 | grad_wrt_c_per_item     0.00082\n",
      "epoch       8.000 | loss_total     0.90997 | train_MAE     0.75722 | valid_MAE     0.77162 | grad_wrt_mu     0.25900 | grad_wrt_b_per_user     0.00172 | grad_wrt_c_per_item     0.00093\n",
      "epoch       9.000 | loss_total     0.90119 | train_MAE     0.75138 | valid_MAE     0.76718 | grad_wrt_mu     0.08764 | grad_wrt_b_per_user     0.00152 | grad_wrt_c_per_item     0.00086\n",
      "epoch      10.000 | loss_total     0.89451 | train_MAE     0.74917 | valid_MAE     0.76490 | grad_wrt_mu     0.21588 | grad_wrt_b_per_user     0.00140 | grad_wrt_c_per_item     0.00075\n",
      "epoch      11.000 | loss_total     0.88912 | train_MAE     0.74834 | valid_MAE     0.76375 | grad_wrt_mu     0.15995 | grad_wrt_b_per_user     0.00155 | grad_wrt_c_per_item     0.00092\n",
      "epoch      12.000 | loss_total     0.88397 | train_MAE     0.74461 | valid_MAE     0.76080 | grad_wrt_mu     0.11774 | grad_wrt_b_per_user     0.00148 | grad_wrt_c_per_item     0.00084\n",
      "epoch      13.000 | loss_total     0.88000 | train_MAE     0.74483 | valid_MAE     0.76050 | grad_wrt_mu     0.30650 | grad_wrt_b_per_user     0.00151 | grad_wrt_c_per_item     0.00082\n",
      "epoch      14.000 | loss_total     0.87585 | train_MAE     0.74219 | valid_MAE     0.75844 | grad_wrt_mu     0.33790 | grad_wrt_b_per_user     0.00150 | grad_wrt_c_per_item     0.00085\n",
      "epoch      15.000 | loss_total     0.87260 | train_MAE     0.73684 | valid_MAE     0.75492 | grad_wrt_mu     0.24141 | grad_wrt_b_per_user     0.00138 | grad_wrt_c_per_item     0.00074\n",
      "epoch      16.000 | loss_total     0.86990 | train_MAE     0.73767 | valid_MAE     0.75487 | grad_wrt_mu     0.14247 | grad_wrt_b_per_user     0.00140 | grad_wrt_c_per_item     0.00071\n",
      "epoch      17.000 | loss_total     0.86719 | train_MAE     0.73473 | valid_MAE     0.75289 | grad_wrt_mu     0.21234 | grad_wrt_b_per_user     0.00151 | grad_wrt_c_per_item     0.00089\n",
      "epoch      18.000 | loss_total     0.86507 | train_MAE     0.73335 | valid_MAE     0.75181 | grad_wrt_mu     0.07808 | grad_wrt_b_per_user     0.00133 | grad_wrt_c_per_item     0.00077\n",
      "epoch      19.000 | loss_total     0.86303 | train_MAE     0.73322 | valid_MAE     0.75134 | grad_wrt_mu     0.17765 | grad_wrt_b_per_user     0.00151 | grad_wrt_c_per_item     0.00081\n",
      "epoch      20.000 | loss_total     0.86055 | train_MAE     0.73553 | valid_MAE     0.75257 | grad_wrt_mu     0.10195 | grad_wrt_b_per_user     0.00155 | grad_wrt_c_per_item     0.00087\n",
      "epoch      21.000 | loss_total     0.85872 | train_MAE     0.73368 | valid_MAE     0.75124 | grad_wrt_mu     0.03511 | grad_wrt_b_per_user     0.00125 | grad_wrt_c_per_item     0.00071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      22.000 | loss_total     0.85799 | train_MAE     0.73312 | valid_MAE     0.75076 | grad_wrt_mu     0.06163 | grad_wrt_b_per_user     0.00175 | grad_wrt_c_per_item     0.00097\n",
      "epoch      23.000 | loss_total     0.85580 | train_MAE     0.72842 | valid_MAE     0.74811 | grad_wrt_mu     0.04736 | grad_wrt_b_per_user     0.00161 | grad_wrt_c_per_item     0.00092\n",
      "epoch      24.000 | loss_total     0.85433 | train_MAE     0.72763 | valid_MAE     0.74772 | grad_wrt_mu     0.18942 | grad_wrt_b_per_user     0.00140 | grad_wrt_c_per_item     0.00078\n",
      "epoch      25.000 | loss_total     0.85343 | train_MAE     0.73055 | valid_MAE     0.74873 | grad_wrt_mu     0.37531 | grad_wrt_b_per_user     0.00140 | grad_wrt_c_per_item     0.00089\n",
      "epoch      26.000 | loss_total     0.85230 | train_MAE     0.72824 | valid_MAE     0.74720 | grad_wrt_mu     0.28435 | grad_wrt_b_per_user     0.00153 | grad_wrt_c_per_item     0.00087\n",
      "epoch      27.000 | loss_total     0.85093 | train_MAE     0.72797 | valid_MAE     0.74694 | grad_wrt_mu     0.25052 | grad_wrt_b_per_user     0.00146 | grad_wrt_c_per_item     0.00082\n",
      "epoch      28.000 | loss_total     0.85030 | train_MAE     0.72755 | valid_MAE     0.74661 | grad_wrt_mu     0.32393 | grad_wrt_b_per_user     0.00144 | grad_wrt_c_per_item     0.00082\n",
      "epoch      29.000 | loss_total     0.84882 | train_MAE     0.73082 | valid_MAE     0.74865 | grad_wrt_mu     0.10219 | grad_wrt_b_per_user     0.00133 | grad_wrt_c_per_item     0.00073\n",
      "epoch      30.000 | loss_total     0.84856 | train_MAE     0.72553 | valid_MAE     0.74515 | grad_wrt_mu     0.26730 | grad_wrt_b_per_user     0.00144 | grad_wrt_c_per_item     0.00082\n",
      "epoch      31.000 | loss_total     0.84743 | train_MAE     0.72647 | valid_MAE     0.74560 | grad_wrt_mu     0.01627 | grad_wrt_b_per_user     0.00146 | grad_wrt_c_per_item     0.00081\n",
      "epoch      32.000 | loss_total     0.84678 | train_MAE     0.72498 | valid_MAE     0.74459 | grad_wrt_mu     0.24275 | grad_wrt_b_per_user     0.00158 | grad_wrt_c_per_item     0.00082\n",
      "epoch      34.000 | loss_total     0.84540 | train_MAE     0.72327 | valid_MAE     0.74423 | grad_wrt_mu     0.15774 | grad_wrt_b_per_user     0.00136 | grad_wrt_c_per_item     0.00076\n",
      "epoch      36.000 | loss_total     0.84430 | train_MAE     0.72337 | valid_MAE     0.74336 | grad_wrt_mu     0.12609 | grad_wrt_b_per_user     0.00137 | grad_wrt_c_per_item     0.00080\n",
      "epoch      38.000 | loss_total     0.84319 | train_MAE     0.72584 | valid_MAE     0.74479 | grad_wrt_mu     0.12032 | grad_wrt_b_per_user     0.00165 | grad_wrt_c_per_item     0.00092\n",
      "epoch      40.000 | loss_total     0.84203 | train_MAE     0.72682 | valid_MAE     0.74540 | grad_wrt_mu     0.21541 | grad_wrt_b_per_user     0.00159 | grad_wrt_c_per_item     0.00093\n",
      "epoch      42.000 | loss_total     0.84154 | train_MAE     0.72268 | valid_MAE     0.74261 | grad_wrt_mu     0.07722 | grad_wrt_b_per_user     0.00145 | grad_wrt_c_per_item     0.00082\n",
      "epoch      44.000 | loss_total     0.84061 | train_MAE     0.72383 | valid_MAE     0.74318 | grad_wrt_mu     0.13299 | grad_wrt_b_per_user     0.00133 | grad_wrt_c_per_item     0.00069\n",
      "epoch      46.000 | loss_total     0.84010 | train_MAE     0.73301 | valid_MAE     0.75005 | grad_wrt_mu     0.02122 | grad_wrt_b_per_user     0.00140 | grad_wrt_c_per_item     0.00084\n",
      "epoch      48.000 | loss_total     0.83979 | train_MAE     0.72118 | valid_MAE     0.74148 | grad_wrt_mu     0.11027 | grad_wrt_b_per_user     0.00169 | grad_wrt_c_per_item     0.00087\n",
      "epoch      50.000 | loss_total     0.83849 | train_MAE     0.72053 | valid_MAE     0.74109 | grad_wrt_mu     0.19404 | grad_wrt_b_per_user     0.00148 | grad_wrt_c_per_item     0.00081\n",
      "epoch      52.000 | loss_total     0.83860 | train_MAE     0.72524 | valid_MAE     0.74406 | grad_wrt_mu     0.02711 | grad_wrt_b_per_user     0.00139 | grad_wrt_c_per_item     0.00079\n",
      "epoch      54.000 | loss_total     0.83745 | train_MAE     0.72373 | valid_MAE     0.74294 | grad_wrt_mu     0.00992 | grad_wrt_b_per_user     0.00119 | grad_wrt_c_per_item     0.00077\n",
      "epoch      56.000 | loss_total     0.83726 | train_MAE     0.72066 | valid_MAE     0.74106 | grad_wrt_mu     0.07362 | grad_wrt_b_per_user     0.00149 | grad_wrt_c_per_item     0.00080\n",
      "epoch      58.000 | loss_total     0.83735 | train_MAE     0.71977 | valid_MAE     0.74057 | grad_wrt_mu     0.08578 | grad_wrt_b_per_user     0.00143 | grad_wrt_c_per_item     0.00084\n",
      "epoch      60.000 | loss_total     0.83645 | train_MAE     0.72384 | valid_MAE     0.74319 | grad_wrt_mu     0.01893 | grad_wrt_b_per_user     0.00151 | grad_wrt_c_per_item     0.00088\n",
      "epoch      62.000 | loss_total     0.83617 | train_MAE     0.72200 | valid_MAE     0.74187 | grad_wrt_mu     0.16690 | grad_wrt_b_per_user     0.00135 | grad_wrt_c_per_item     0.00077\n",
      "epoch      64.000 | loss_total     0.83640 | train_MAE     0.71972 | valid_MAE     0.74033 | grad_wrt_mu     0.28228 | grad_wrt_b_per_user     0.00130 | grad_wrt_c_per_item     0.00082\n",
      "epoch      66.000 | loss_total     0.83589 | train_MAE     0.72195 | valid_MAE     0.74183 | grad_wrt_mu     0.38765 | grad_wrt_b_per_user     0.00157 | grad_wrt_c_per_item     0.00089\n",
      "epoch      68.000 | loss_total     0.83542 | train_MAE     0.72125 | valid_MAE     0.74140 | grad_wrt_mu     0.13367 | grad_wrt_b_per_user     0.00149 | grad_wrt_c_per_item     0.00084\n",
      "epoch      70.000 | loss_total     0.83578 | train_MAE     0.72289 | valid_MAE     0.74257 | grad_wrt_mu     0.01745 | grad_wrt_b_per_user     0.00154 | grad_wrt_c_per_item     0.00094\n",
      "epoch      72.000 | loss_total     0.83558 | train_MAE     0.72078 | valid_MAE     0.74098 | grad_wrt_mu     0.04145 | grad_wrt_b_per_user     0.00157 | grad_wrt_c_per_item     0.00084\n",
      "epoch      74.000 | loss_total     0.83496 | train_MAE     0.72435 | valid_MAE     0.74375 | grad_wrt_mu     0.03333 | grad_wrt_b_per_user     0.00142 | grad_wrt_c_per_item     0.00078\n",
      "epoch      76.000 | loss_total     0.83480 | train_MAE     0.72108 | valid_MAE     0.74136 | grad_wrt_mu     0.11879 | grad_wrt_b_per_user     0.00147 | grad_wrt_c_per_item     0.00081\n",
      "epoch      78.000 | loss_total     0.83411 | train_MAE     0.72086 | valid_MAE     0.74120 | grad_wrt_mu     0.17813 | grad_wrt_b_per_user     0.00150 | grad_wrt_c_per_item     0.00087\n",
      "epoch      80.000 | loss_total     0.83431 | train_MAE     0.71923 | valid_MAE     0.74014 | grad_wrt_mu     0.19277 | grad_wrt_b_per_user     0.00146 | grad_wrt_c_per_item     0.00083\n",
      "epoch      82.000 | loss_total     0.83430 | train_MAE     0.71787 | valid_MAE     0.73938 | grad_wrt_mu     0.27160 | grad_wrt_b_per_user     0.00134 | grad_wrt_c_per_item     0.00081\n",
      "epoch      84.000 | loss_total     0.83390 | train_MAE     0.72110 | valid_MAE     0.74144 | grad_wrt_mu     0.23781 | grad_wrt_b_per_user     0.00149 | grad_wrt_c_per_item     0.00087\n",
      "epoch      86.000 | loss_total     0.83402 | train_MAE     0.71760 | valid_MAE     0.73938 | grad_wrt_mu     0.34799 | grad_wrt_b_per_user     0.00162 | grad_wrt_c_per_item     0.00093\n",
      "epoch      88.000 | loss_total     0.83331 | train_MAE     0.71783 | valid_MAE     0.73941 | grad_wrt_mu     0.04647 | grad_wrt_b_per_user     0.00111 | grad_wrt_c_per_item     0.00067\n",
      "epoch      90.000 | loss_total     0.83381 | train_MAE     0.72503 | valid_MAE     0.74445 | grad_wrt_mu     0.05413 | grad_wrt_b_per_user     0.00151 | grad_wrt_c_per_item     0.00090\n",
      "epoch      92.000 | loss_total     0.83312 | train_MAE     0.71941 | valid_MAE     0.74044 | grad_wrt_mu     0.33262 | grad_wrt_b_per_user     0.00151 | grad_wrt_c_per_item     0.00091\n",
      "epoch      94.000 | loss_total     0.83343 | train_MAE     0.72633 | valid_MAE     0.74551 | grad_wrt_mu     0.11305 | grad_wrt_b_per_user     0.00150 | grad_wrt_c_per_item     0.00085\n",
      "epoch      96.000 | loss_total     0.83355 | train_MAE     0.72347 | valid_MAE     0.74336 | grad_wrt_mu     0.09091 | grad_wrt_b_per_user     0.00165 | grad_wrt_c_per_item     0.00090\n",
      "epoch      98.000 | loss_total     0.83269 | train_MAE     0.72247 | valid_MAE     0.74263 | grad_wrt_mu     0.14606 | grad_wrt_b_per_user     0.00141 | grad_wrt_c_per_item     0.00081\n",
      "epoch      99.999 | loss_total     0.83280 | train_MAE     0.72226 | valid_MAE     0.74245 | grad_wrt_mu     0.11884 | grad_wrt_b_per_user     0.00151 | grad_wrt_c_per_item     0.00081\n"
     ]
    }
   ],
   "source": [
    "M2_100.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M2_100.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total    13.78920 | train_MAE     3.53059 | valid_MAE     3.50620 | grad_wrt_mu     7.07640 | grad_wrt_b_per_user     0.00750 | grad_wrt_c_per_item     0.00421\n",
      "epoch       0.143 | loss_total     9.09039 | train_MAE     2.82028 | valid_MAE     2.79592 | grad_wrt_mu     5.59665 | grad_wrt_b_per_user     0.00593 | grad_wrt_c_per_item     0.00333\n",
      "epoch       0.286 | loss_total     6.35474 | train_MAE     2.29178 | valid_MAE     2.26773 | grad_wrt_mu     4.49816 | grad_wrt_b_per_user     0.00477 | grad_wrt_c_per_item     0.00268\n",
      "epoch       0.429 | loss_total     4.55931 | train_MAE     1.89563 | valid_MAE     1.87208 | grad_wrt_mu     3.63135 | grad_wrt_b_per_user     0.00386 | grad_wrt_c_per_item     0.00217\n",
      "epoch       0.571 | loss_total     3.36625 | train_MAE     1.59552 | valid_MAE     1.57310 | grad_wrt_mu     2.89888 | grad_wrt_b_per_user     0.00311 | grad_wrt_c_per_item     0.00176\n",
      "epoch       0.714 | loss_total     2.58030 | train_MAE     1.40608 | valid_MAE     1.38637 | grad_wrt_mu     2.30440 | grad_wrt_b_per_user     0.00250 | grad_wrt_c_per_item     0.00143\n",
      "epoch       0.857 | loss_total     2.11539 | train_MAE     1.25546 | valid_MAE     1.23790 | grad_wrt_mu     1.85622 | grad_wrt_b_per_user     0.00206 | grad_wrt_c_per_item     0.00119\n",
      "epoch       1.000 | loss_total     1.79824 | train_MAE     1.13411 | valid_MAE     1.11830 | grad_wrt_mu     1.46541 | grad_wrt_b_per_user     0.00168 | grad_wrt_c_per_item     0.00101\n",
      "epoch       1.143 | loss_total     1.58317 | train_MAE     1.03829 | valid_MAE     1.02385 | grad_wrt_mu     1.14935 | grad_wrt_b_per_user     0.00141 | grad_wrt_c_per_item     0.00086\n",
      "epoch       1.286 | loss_total     1.46958 | train_MAE     0.99470 | valid_MAE     0.98249 | grad_wrt_mu     0.96537 | grad_wrt_b_per_user     0.00126 | grad_wrt_c_per_item     0.00080\n",
      "epoch       1.429 | loss_total     1.39290 | train_MAE     0.98394 | valid_MAE     0.97453 | grad_wrt_mu     0.73769 | grad_wrt_b_per_user     0.00111 | grad_wrt_c_per_item     0.00071\n",
      "epoch       1.571 | loss_total     1.38346 | train_MAE     0.97569 | valid_MAE     0.96842 | grad_wrt_mu     0.61141 | grad_wrt_b_per_user     0.00110 | grad_wrt_c_per_item     0.00069\n",
      "epoch       1.714 | loss_total     1.31818 | train_MAE     0.96882 | valid_MAE     0.96333 | grad_wrt_mu     0.46616 | grad_wrt_b_per_user     0.00097 | grad_wrt_c_per_item     0.00065\n",
      "epoch       1.857 | loss_total     1.32030 | train_MAE     0.96356 | valid_MAE     0.95942 | grad_wrt_mu     0.40120 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00064\n",
      "epoch       2.000 | loss_total     1.25370 | train_MAE     0.95901 | valid_MAE     0.95604 | grad_wrt_mu     0.28587 | grad_wrt_b_per_user     0.00090 | grad_wrt_c_per_item     0.00060\n",
      "epoch       2.571 | loss_total     1.28164 | train_MAE     0.94855 | valid_MAE     0.94823 | grad_wrt_mu     0.13192 | grad_wrt_b_per_user     0.00090 | grad_wrt_c_per_item     0.00056\n",
      "epoch       3.000 | loss_total     1.27000 | train_MAE     0.94500 | valid_MAE     0.94553 | grad_wrt_mu     0.07863 | grad_wrt_b_per_user     0.00088 | grad_wrt_c_per_item     0.00058\n",
      "epoch       3.571 | loss_total     1.26724 | train_MAE     0.94225 | valid_MAE     0.94340 | grad_wrt_mu     0.00903 | grad_wrt_b_per_user     0.00090 | grad_wrt_c_per_item     0.00056\n",
      "epoch       4.000 | loss_total     1.25997 | train_MAE     0.94135 | valid_MAE     0.94265 | grad_wrt_mu     0.01250 | grad_wrt_b_per_user     0.00087 | grad_wrt_c_per_item     0.00057\n",
      "epoch       4.571 | loss_total     1.25311 | train_MAE     0.94062 | valid_MAE     0.94201 | grad_wrt_mu     0.03636 | grad_wrt_b_per_user     0.00088 | grad_wrt_c_per_item     0.00058\n",
      "epoch       5.000 | loss_total     1.25116 | train_MAE     0.93974 | valid_MAE     0.94128 | grad_wrt_mu     0.02622 | grad_wrt_b_per_user     0.00086 | grad_wrt_c_per_item     0.00056\n",
      "epoch       5.571 | loss_total     1.25076 | train_MAE     0.93937 | valid_MAE     0.94090 | grad_wrt_mu     0.02232 | grad_wrt_b_per_user     0.00085 | grad_wrt_c_per_item     0.00055\n",
      "epoch       6.000 | loss_total     1.25775 | train_MAE     0.93882 | valid_MAE     0.94042 | grad_wrt_mu     0.01367 | grad_wrt_b_per_user     0.00090 | grad_wrt_c_per_item     0.00058\n",
      "epoch       6.571 | loss_total     1.25408 | train_MAE     0.93799 | valid_MAE     0.93970 | grad_wrt_mu     0.03348 | grad_wrt_b_per_user     0.00088 | grad_wrt_c_per_item     0.00056\n",
      "epoch       7.000 | loss_total     1.24813 | train_MAE     0.93813 | valid_MAE     0.93973 | grad_wrt_mu     0.01754 | grad_wrt_b_per_user     0.00088 | grad_wrt_c_per_item     0.00056\n",
      "epoch       7.571 | loss_total     1.25340 | train_MAE     0.93760 | valid_MAE     0.93923 | grad_wrt_mu     0.00125 | grad_wrt_b_per_user     0.00086 | grad_wrt_c_per_item     0.00056\n",
      "epoch       8.000 | loss_total     1.24835 | train_MAE     0.93701 | valid_MAE     0.93872 | grad_wrt_mu     0.02843 | grad_wrt_b_per_user     0.00089 | grad_wrt_c_per_item     0.00054\n",
      "epoch       9.000 | loss_total     1.24270 | train_MAE     0.93625 | valid_MAE     0.93798 | grad_wrt_mu     0.00104 | grad_wrt_b_per_user     0.00083 | grad_wrt_c_per_item     0.00055\n",
      "epoch      10.000 | loss_total     1.24711 | train_MAE     0.93508 | valid_MAE     0.93693 | grad_wrt_mu     0.00697 | grad_wrt_b_per_user     0.00086 | grad_wrt_c_per_item     0.00056\n",
      "epoch      11.000 | loss_total     1.24136 | train_MAE     0.93471 | valid_MAE     0.93648 | grad_wrt_mu     0.02827 | grad_wrt_b_per_user     0.00088 | grad_wrt_c_per_item     0.00056\n",
      "epoch      12.000 | loss_total     1.23654 | train_MAE     0.93376 | valid_MAE     0.93560 | grad_wrt_mu     0.01395 | grad_wrt_b_per_user     0.00085 | grad_wrt_c_per_item     0.00055\n",
      "epoch      13.000 | loss_total     1.23595 | train_MAE     0.93318 | valid_MAE     0.93500 | grad_wrt_mu     0.02960 | grad_wrt_b_per_user     0.00083 | grad_wrt_c_per_item     0.00056\n",
      "epoch      14.000 | loss_total     1.24009 | train_MAE     0.93247 | valid_MAE     0.93429 | grad_wrt_mu     0.00236 | grad_wrt_b_per_user     0.00084 | grad_wrt_c_per_item     0.00057\n",
      "epoch      15.000 | loss_total     1.22672 | train_MAE     0.93103 | valid_MAE     0.93306 | grad_wrt_mu     0.00194 | grad_wrt_b_per_user     0.00085 | grad_wrt_c_per_item     0.00054\n",
      "epoch      16.000 | loss_total     1.23206 | train_MAE     0.93017 | valid_MAE     0.93225 | grad_wrt_mu     0.01012 | grad_wrt_b_per_user     0.00084 | grad_wrt_c_per_item     0.00055\n",
      "epoch      17.000 | loss_total     1.23153 | train_MAE     0.92958 | valid_MAE     0.93164 | grad_wrt_mu     0.02875 | grad_wrt_b_per_user     0.00082 | grad_wrt_c_per_item     0.00055\n",
      "epoch      18.000 | loss_total     1.22022 | train_MAE     0.92860 | valid_MAE     0.93074 | grad_wrt_mu     0.02994 | grad_wrt_b_per_user     0.00084 | grad_wrt_c_per_item     0.00055\n",
      "epoch      19.000 | loss_total     1.22429 | train_MAE     0.92805 | valid_MAE     0.93017 | grad_wrt_mu     0.02683 | grad_wrt_b_per_user     0.00082 | grad_wrt_c_per_item     0.00055\n",
      "epoch      20.000 | loss_total     1.22274 | train_MAE     0.92699 | valid_MAE     0.92921 | grad_wrt_mu     0.02885 | grad_wrt_b_per_user     0.00085 | grad_wrt_c_per_item     0.00055\n",
      "epoch      21.000 | loss_total     1.22188 | train_MAE     0.92606 | valid_MAE     0.92835 | grad_wrt_mu     0.00640 | grad_wrt_b_per_user     0.00084 | grad_wrt_c_per_item     0.00055\n",
      "epoch      22.000 | loss_total     1.21434 | train_MAE     0.92546 | valid_MAE     0.92774 | grad_wrt_mu     0.02139 | grad_wrt_b_per_user     0.00081 | grad_wrt_c_per_item     0.00055\n",
      "epoch      23.000 | loss_total     1.22011 | train_MAE     0.92456 | valid_MAE     0.92691 | grad_wrt_mu     0.01435 | grad_wrt_b_per_user     0.00082 | grad_wrt_c_per_item     0.00055\n",
      "epoch      24.000 | loss_total     1.21266 | train_MAE     0.92341 | valid_MAE     0.92589 | grad_wrt_mu     0.02007 | grad_wrt_b_per_user     0.00083 | grad_wrt_c_per_item     0.00053\n",
      "epoch      25.000 | loss_total     1.20932 | train_MAE     0.92298 | valid_MAE     0.92541 | grad_wrt_mu     0.02646 | grad_wrt_b_per_user     0.00081 | grad_wrt_c_per_item     0.00055\n",
      "epoch      26.000 | loss_total     1.21080 | train_MAE     0.92203 | valid_MAE     0.92454 | grad_wrt_mu     0.00502 | grad_wrt_b_per_user     0.00081 | grad_wrt_c_per_item     0.00055\n",
      "epoch      27.000 | loss_total     1.20521 | train_MAE     0.92122 | valid_MAE     0.92378 | grad_wrt_mu     0.00778 | grad_wrt_b_per_user     0.00080 | grad_wrt_c_per_item     0.00053\n",
      "epoch      28.000 | loss_total     1.20568 | train_MAE     0.92059 | valid_MAE     0.92315 | grad_wrt_mu     0.01561 | grad_wrt_b_per_user     0.00079 | grad_wrt_c_per_item     0.00052\n",
      "epoch      29.000 | loss_total     1.20298 | train_MAE     0.91977 | valid_MAE     0.92238 | grad_wrt_mu     0.00437 | grad_wrt_b_per_user     0.00082 | grad_wrt_c_per_item     0.00055\n",
      "epoch      30.000 | loss_total     1.19801 | train_MAE     0.91902 | valid_MAE     0.92166 | grad_wrt_mu     0.00956 | grad_wrt_b_per_user     0.00083 | grad_wrt_c_per_item     0.00052\n",
      "epoch      31.000 | loss_total     1.20428 | train_MAE     0.91821 | valid_MAE     0.92090 | grad_wrt_mu     0.01982 | grad_wrt_b_per_user     0.00083 | grad_wrt_c_per_item     0.00052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      32.000 | loss_total     1.19791 | train_MAE     0.91748 | valid_MAE     0.92020 | grad_wrt_mu     0.00310 | grad_wrt_b_per_user     0.00080 | grad_wrt_c_per_item     0.00053\n",
      "epoch      34.000 | loss_total     1.18751 | train_MAE     0.91583 | valid_MAE     0.91867 | grad_wrt_mu     0.00900 | grad_wrt_b_per_user     0.00082 | grad_wrt_c_per_item     0.00051\n",
      "epoch      36.000 | loss_total     1.19156 | train_MAE     0.91432 | valid_MAE     0.91724 | grad_wrt_mu     0.00424 | grad_wrt_b_per_user     0.00079 | grad_wrt_c_per_item     0.00053\n",
      "epoch      38.000 | loss_total     1.18472 | train_MAE     0.91315 | valid_MAE     0.91608 | grad_wrt_mu     0.00400 | grad_wrt_b_per_user     0.00079 | grad_wrt_c_per_item     0.00054\n",
      "epoch      40.000 | loss_total     1.18714 | train_MAE     0.91117 | valid_MAE     0.91433 | grad_wrt_mu     0.04159 | grad_wrt_b_per_user     0.00081 | grad_wrt_c_per_item     0.00052\n",
      "epoch      42.000 | loss_total     1.18246 | train_MAE     0.91023 | valid_MAE     0.91335 | grad_wrt_mu     0.00990 | grad_wrt_b_per_user     0.00081 | grad_wrt_c_per_item     0.00052\n",
      "epoch      44.000 | loss_total     1.17190 | train_MAE     0.90840 | valid_MAE     0.91170 | grad_wrt_mu     0.02650 | grad_wrt_b_per_user     0.00079 | grad_wrt_c_per_item     0.00052\n",
      "epoch      46.000 | loss_total     1.17197 | train_MAE     0.90747 | valid_MAE     0.91074 | grad_wrt_mu     0.01325 | grad_wrt_b_per_user     0.00079 | grad_wrt_c_per_item     0.00053\n",
      "epoch      48.000 | loss_total     1.17387 | train_MAE     0.90589 | valid_MAE     0.90929 | grad_wrt_mu     0.00145 | grad_wrt_b_per_user     0.00083 | grad_wrt_c_per_item     0.00052\n",
      "epoch      50.000 | loss_total     1.17032 | train_MAE     0.90432 | valid_MAE     0.90785 | grad_wrt_mu     0.00404 | grad_wrt_b_per_user     0.00078 | grad_wrt_c_per_item     0.00052\n",
      "epoch      52.000 | loss_total     1.16372 | train_MAE     0.90301 | valid_MAE     0.90660 | grad_wrt_mu     0.03023 | grad_wrt_b_per_user     0.00079 | grad_wrt_c_per_item     0.00053\n",
      "epoch      54.000 | loss_total     1.16174 | train_MAE     0.90141 | valid_MAE     0.90514 | grad_wrt_mu     0.02232 | grad_wrt_b_per_user     0.00077 | grad_wrt_c_per_item     0.00049\n",
      "epoch      56.000 | loss_total     1.15617 | train_MAE     0.90011 | valid_MAE     0.90390 | grad_wrt_mu     0.01829 | grad_wrt_b_per_user     0.00079 | grad_wrt_c_per_item     0.00051\n",
      "epoch      58.000 | loss_total     1.15353 | train_MAE     0.89884 | valid_MAE     0.90269 | grad_wrt_mu     0.01080 | grad_wrt_b_per_user     0.00075 | grad_wrt_c_per_item     0.00050\n",
      "epoch      60.000 | loss_total     1.14923 | train_MAE     0.89769 | valid_MAE     0.90157 | grad_wrt_mu     0.01752 | grad_wrt_b_per_user     0.00072 | grad_wrt_c_per_item     0.00050\n",
      "epoch      62.000 | loss_total     1.14767 | train_MAE     0.89633 | valid_MAE     0.90030 | grad_wrt_mu     0.04038 | grad_wrt_b_per_user     0.00073 | grad_wrt_c_per_item     0.00050\n",
      "epoch      64.000 | loss_total     1.14735 | train_MAE     0.89481 | valid_MAE     0.89891 | grad_wrt_mu     0.00209 | grad_wrt_b_per_user     0.00073 | grad_wrt_c_per_item     0.00051\n",
      "epoch      66.000 | loss_total     1.14519 | train_MAE     0.89389 | valid_MAE     0.89796 | grad_wrt_mu     0.00669 | grad_wrt_b_per_user     0.00074 | grad_wrt_c_per_item     0.00049\n",
      "epoch      68.000 | loss_total     1.14240 | train_MAE     0.89210 | valid_MAE     0.89638 | grad_wrt_mu     0.00326 | grad_wrt_b_per_user     0.00075 | grad_wrt_c_per_item     0.00049\n",
      "epoch      70.000 | loss_total     1.13921 | train_MAE     0.89129 | valid_MAE     0.89552 | grad_wrt_mu     0.00310 | grad_wrt_b_per_user     0.00071 | grad_wrt_c_per_item     0.00052\n",
      "epoch      72.000 | loss_total     1.13707 | train_MAE     0.88989 | valid_MAE     0.89423 | grad_wrt_mu     0.00493 | grad_wrt_b_per_user     0.00074 | grad_wrt_c_per_item     0.00051\n",
      "epoch      74.000 | loss_total     1.13419 | train_MAE     0.88863 | valid_MAE     0.89304 | grad_wrt_mu     0.00609 | grad_wrt_b_per_user     0.00074 | grad_wrt_c_per_item     0.00050\n",
      "epoch      76.000 | loss_total     1.13105 | train_MAE     0.88746 | valid_MAE     0.89193 | grad_wrt_mu     0.00139 | grad_wrt_b_per_user     0.00074 | grad_wrt_c_per_item     0.00050\n",
      "epoch      78.000 | loss_total     1.12796 | train_MAE     0.88601 | valid_MAE     0.89060 | grad_wrt_mu     0.04196 | grad_wrt_b_per_user     0.00074 | grad_wrt_c_per_item     0.00050\n",
      "epoch      80.000 | loss_total     1.12345 | train_MAE     0.88490 | valid_MAE     0.88954 | grad_wrt_mu     0.02760 | grad_wrt_b_per_user     0.00074 | grad_wrt_c_per_item     0.00047\n",
      "epoch      82.000 | loss_total     1.12912 | train_MAE     0.88385 | valid_MAE     0.88851 | grad_wrt_mu     0.02032 | grad_wrt_b_per_user     0.00072 | grad_wrt_c_per_item     0.00048\n",
      "epoch      84.000 | loss_total     1.12515 | train_MAE     0.88254 | valid_MAE     0.88729 | grad_wrt_mu     0.01147 | grad_wrt_b_per_user     0.00073 | grad_wrt_c_per_item     0.00050\n",
      "epoch      86.000 | loss_total     1.11953 | train_MAE     0.88153 | valid_MAE     0.88631 | grad_wrt_mu     0.01455 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00049\n",
      "epoch      88.000 | loss_total     1.11204 | train_MAE     0.88011 | valid_MAE     0.88501 | grad_wrt_mu     0.00657 | grad_wrt_b_per_user     0.00073 | grad_wrt_c_per_item     0.00047\n",
      "epoch      90.000 | loss_total     1.11786 | train_MAE     0.87924 | valid_MAE     0.88413 | grad_wrt_mu     0.01248 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00050\n",
      "epoch      92.000 | loss_total     1.11208 | train_MAE     0.87833 | valid_MAE     0.88323 | grad_wrt_mu     0.00046 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00049\n",
      "epoch      94.000 | loss_total     1.11039 | train_MAE     0.87678 | valid_MAE     0.88185 | grad_wrt_mu     0.00843 | grad_wrt_b_per_user     0.00073 | grad_wrt_c_per_item     0.00049\n",
      "epoch      96.000 | loss_total     1.10635 | train_MAE     0.87587 | valid_MAE     0.88095 | grad_wrt_mu     0.01622 | grad_wrt_b_per_user     0.00072 | grad_wrt_c_per_item     0.00047\n",
      "epoch      98.000 | loss_total     1.10355 | train_MAE     0.87438 | valid_MAE     0.87962 | grad_wrt_mu     0.00423 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00048\n",
      "epoch      99.857 | loss_total     1.10296 | train_MAE     0.87325 | valid_MAE     0.87858 | grad_wrt_mu     0.03853 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00048\n"
     ]
    }
   ],
   "source": [
    "M2_10000.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M2_10000.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8788178557453462"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation 10000\n",
    "ratigs_hat_va_M2_10000 = M2_10000.predict(valid_tuple[0], valid_tuple[1])\n",
    "metrics.mean_absolute_error(valid_tuple[2], ratigs_hat_va_M2_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8796695654461151"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 10000\n",
    "ratigs_hat_te_M2_10000 = M2_10000.predict(test_tuple[0], test_tuple[1])\n",
    "metrics.mean_absolute_error(test_tuple[2], ratigs_hat_te_M2_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7416258512070968"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation 100\n",
    "ratigs_hat_va_M2_100 = M2_100.predict(valid_tuple[0], valid_tuple[1])\n",
    "metrics.mean_absolute_error(valid_tuple[2], ratigs_hat_va_M2_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7517782717364137"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 100\n",
    "ratigs_hat_te_M2_100 = M2_100.predict(test_tuple[0], test_tuple[1])\n",
    "metrics.mean_absolute_error(test_tuple[2], ratigs_hat_te_M2_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 100\n",
    "M3_2f = CollabFilterOneVectorPerItem(step_size=0.2, n_epochs=100, batch_size=1000, random_state=SEED, n_factors=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 2)\n",
      "(1682, 2)\n",
      "epoch       0.000 | loss_total     1.53400 | train_MAE     1.00261 | valid_MAE     0.98860 | grad_wrt_mu     1.06400 | grad_wrt_b_per_user     0.00168 | grad_wrt_c_per_item     0.00102 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.014 | loss_total     1.37016 | train_MAE     0.97896 | valid_MAE     0.97112 | grad_wrt_mu     0.68079 | grad_wrt_b_per_user     0.00160 | grad_wrt_c_per_item     0.00098 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.029 | loss_total     1.27621 | train_MAE     0.96369 | valid_MAE     0.95983 | grad_wrt_mu     0.33532 | grad_wrt_b_per_user     0.00145 | grad_wrt_c_per_item     0.00086 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.043 | loss_total     1.21707 | train_MAE     0.95605 | valid_MAE     0.95414 | grad_wrt_mu     0.26210 | grad_wrt_b_per_user     0.00137 | grad_wrt_c_per_item     0.00083 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.129 | loss_total     1.25902 | train_MAE     0.94385 | valid_MAE     0.94481 | grad_wrt_mu     0.11801 | grad_wrt_b_per_user     0.00147 | grad_wrt_c_per_item     0.00086 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.257 | loss_total     1.29601 | train_MAE     0.93917 | valid_MAE     0.94095 | grad_wrt_mu     0.05604 | grad_wrt_b_per_user     0.00146 | grad_wrt_c_per_item     0.00086 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.386 | loss_total     1.23989 | train_MAE     0.94006 | valid_MAE     0.94111 | grad_wrt_mu     0.07524 | grad_wrt_b_per_user     0.00139 | grad_wrt_c_per_item     0.00083 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.500 | loss_total     1.20823 | train_MAE     0.93764 | valid_MAE     0.93887 | grad_wrt_mu     0.10029 | grad_wrt_b_per_user     0.00140 | grad_wrt_c_per_item     0.00083 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.629 | loss_total     1.27709 | train_MAE     0.93334 | valid_MAE     0.93527 | grad_wrt_mu     0.01275 | grad_wrt_b_per_user     0.00144 | grad_wrt_c_per_item     0.00083 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.757 | loss_total     1.19410 | train_MAE     0.93259 | valid_MAE     0.93426 | grad_wrt_mu     0.09139 | grad_wrt_b_per_user     0.00137 | grad_wrt_c_per_item     0.00082 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.886 | loss_total     1.20379 | train_MAE     0.92728 | valid_MAE     0.92987 | grad_wrt_mu     0.02473 | grad_wrt_b_per_user     0.00136 | grad_wrt_c_per_item     0.00084 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.000 | loss_total     1.16684 | train_MAE     0.92716 | valid_MAE     0.92937 | grad_wrt_mu     0.13388 | grad_wrt_b_per_user     0.00137 | grad_wrt_c_per_item     0.00084 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.129 | loss_total     1.13527 | train_MAE     0.92551 | valid_MAE     0.92775 | grad_wrt_mu     0.04223 | grad_wrt_b_per_user     0.00125 | grad_wrt_c_per_item     0.00078 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.257 | loss_total     1.28639 | train_MAE     0.92373 | valid_MAE     0.92598 | grad_wrt_mu     0.13009 | grad_wrt_b_per_user     0.00145 | grad_wrt_c_per_item     0.00090 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.386 | loss_total     1.12637 | train_MAE     0.92152 | valid_MAE     0.92392 | grad_wrt_mu     0.12956 | grad_wrt_b_per_user     0.00133 | grad_wrt_c_per_item     0.00077 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.500 | loss_total     1.20395 | train_MAE     0.91873 | valid_MAE     0.92148 | grad_wrt_mu     0.06825 | grad_wrt_b_per_user     0.00133 | grad_wrt_c_per_item     0.00085 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.629 | loss_total     1.14330 | train_MAE     0.91722 | valid_MAE     0.91999 | grad_wrt_mu     0.03829 | grad_wrt_b_per_user     0.00135 | grad_wrt_c_per_item     0.00085 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.757 | loss_total     1.19494 | train_MAE     0.91573 | valid_MAE     0.91849 | grad_wrt_mu     0.08160 | grad_wrt_b_per_user     0.00137 | grad_wrt_c_per_item     0.00080 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.886 | loss_total     1.21667 | train_MAE     0.91188 | valid_MAE     0.91523 | grad_wrt_mu     0.01899 | grad_wrt_b_per_user     0.00145 | grad_wrt_c_per_item     0.00082 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.000 | loss_total     1.16507 | train_MAE     0.91416 | valid_MAE     0.91660 | grad_wrt_mu     0.00493 | grad_wrt_b_per_user     0.00132 | grad_wrt_c_per_item     0.00077 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.500 | loss_total     1.18081 | train_MAE     0.90403 | valid_MAE     0.90758 | grad_wrt_mu     0.06848 | grad_wrt_b_per_user     0.00132 | grad_wrt_c_per_item     0.00078 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.000 | loss_total     1.16865 | train_MAE     0.89876 | valid_MAE     0.90240 | grad_wrt_mu     0.04624 | grad_wrt_b_per_user     0.00131 | grad_wrt_c_per_item     0.00080 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.500 | loss_total     1.14794 | train_MAE     0.88973 | valid_MAE     0.89446 | grad_wrt_mu     0.05668 | grad_wrt_b_per_user     0.00134 | grad_wrt_c_per_item     0.00078 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.000 | loss_total     1.14041 | train_MAE     0.88721 | valid_MAE     0.89128 | grad_wrt_mu     0.06379 | grad_wrt_b_per_user     0.00137 | grad_wrt_c_per_item     0.00082 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.500 | loss_total     1.13433 | train_MAE     0.87870 | valid_MAE     0.88377 | grad_wrt_mu     0.00539 | grad_wrt_b_per_user     0.00132 | grad_wrt_c_per_item     0.00082 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.000 | loss_total     1.11412 | train_MAE     0.87487 | valid_MAE     0.87979 | grad_wrt_mu     0.04440 | grad_wrt_b_per_user     0.00135 | grad_wrt_c_per_item     0.00078 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.500 | loss_total     1.10433 | train_MAE     0.86897 | valid_MAE     0.87432 | grad_wrt_mu     0.19215 | grad_wrt_b_per_user     0.00136 | grad_wrt_c_per_item     0.00081 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.000 | loss_total     1.09460 | train_MAE     0.86461 | valid_MAE     0.87011 | grad_wrt_mu     0.12587 | grad_wrt_b_per_user     0.00131 | grad_wrt_c_per_item     0.00078 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.500 | loss_total     1.08674 | train_MAE     0.85849 | valid_MAE     0.86460 | grad_wrt_mu     0.02545 | grad_wrt_b_per_user     0.00124 | grad_wrt_c_per_item     0.00074 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.000 | loss_total     1.07481 | train_MAE     0.85442 | valid_MAE     0.86071 | grad_wrt_mu     0.07209 | grad_wrt_b_per_user     0.00129 | grad_wrt_c_per_item     0.00074 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.500 | loss_total     1.06610 | train_MAE     0.84790 | valid_MAE     0.85506 | grad_wrt_mu     0.02081 | grad_wrt_b_per_user     0.00120 | grad_wrt_c_per_item     0.00074 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       8.000 | loss_total     1.05918 | train_MAE     0.84534 | valid_MAE     0.85230 | grad_wrt_mu     0.01092 | grad_wrt_b_per_user     0.00121 | grad_wrt_c_per_item     0.00074 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       9.000 | loss_total     1.04515 | train_MAE     0.83787 | valid_MAE     0.84524 | grad_wrt_mu     0.08303 | grad_wrt_b_per_user     0.00119 | grad_wrt_c_per_item     0.00071 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      10.000 | loss_total     1.03494 | train_MAE     0.82864 | valid_MAE     0.83706 | grad_wrt_mu     0.04695 | grad_wrt_b_per_user     0.00120 | grad_wrt_c_per_item     0.00075 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      11.000 | loss_total     1.02122 | train_MAE     0.82267 | valid_MAE     0.83140 | grad_wrt_mu     0.03582 | grad_wrt_b_per_user     0.00114 | grad_wrt_c_per_item     0.00070 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      12.000 | loss_total     1.01362 | train_MAE     0.81715 | valid_MAE     0.82622 | grad_wrt_mu     0.01756 | grad_wrt_b_per_user     0.00119 | grad_wrt_c_per_item     0.00073 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      13.000 | loss_total     1.00243 | train_MAE     0.81326 | valid_MAE     0.82234 | grad_wrt_mu     0.07872 | grad_wrt_b_per_user     0.00114 | grad_wrt_c_per_item     0.00070 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      14.000 | loss_total     0.99539 | train_MAE     0.80516 | valid_MAE     0.81561 | grad_wrt_mu     0.00424 | grad_wrt_b_per_user     0.00118 | grad_wrt_c_per_item     0.00070 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      15.000 | loss_total     0.98873 | train_MAE     0.80636 | valid_MAE     0.81556 | grad_wrt_mu     0.05902 | grad_wrt_b_per_user     0.00118 | grad_wrt_c_per_item     0.00069 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      16.000 | loss_total     0.98123 | train_MAE     0.80158 | valid_MAE     0.81131 | grad_wrt_mu     0.03820 | grad_wrt_b_per_user     0.00114 | grad_wrt_c_per_item     0.00072 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      17.000 | loss_total     0.97342 | train_MAE     0.79523 | valid_MAE     0.80611 | grad_wrt_mu     0.00675 | grad_wrt_b_per_user     0.00114 | grad_wrt_c_per_item     0.00068 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      18.000 | loss_total     0.96930 | train_MAE     0.79437 | valid_MAE     0.80477 | grad_wrt_mu     0.02792 | grad_wrt_b_per_user     0.00108 | grad_wrt_c_per_item     0.00071 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      19.000 | loss_total     0.96359 | train_MAE     0.79053 | valid_MAE     0.80149 | grad_wrt_mu     0.03462 | grad_wrt_b_per_user     0.00110 | grad_wrt_c_per_item     0.00066 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      20.000 | loss_total     0.95995 | train_MAE     0.78766 | valid_MAE     0.79894 | grad_wrt_mu     0.01135 | grad_wrt_b_per_user     0.00116 | grad_wrt_c_per_item     0.00071 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      21.000 | loss_total     0.95265 | train_MAE     0.78536 | valid_MAE     0.79683 | grad_wrt_mu     0.09510 | grad_wrt_b_per_user     0.00108 | grad_wrt_c_per_item     0.00069 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      22.000 | loss_total     0.94988 | train_MAE     0.78066 | valid_MAE     0.79320 | grad_wrt_mu     0.01083 | grad_wrt_b_per_user     0.00111 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      23.000 | loss_total     0.94501 | train_MAE     0.77801 | valid_MAE     0.79096 | grad_wrt_mu     0.03361 | grad_wrt_b_per_user     0.00105 | grad_wrt_c_per_item     0.00065 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      24.000 | loss_total     0.94475 | train_MAE     0.77737 | valid_MAE     0.78998 | grad_wrt_mu     0.06895 | grad_wrt_b_per_user     0.00121 | grad_wrt_c_per_item     0.00073 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      25.000 | loss_total     0.93661 | train_MAE     0.77482 | valid_MAE     0.78786 | grad_wrt_mu     0.02440 | grad_wrt_b_per_user     0.00109 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      26.000 | loss_total     0.93639 | train_MAE     0.77524 | valid_MAE     0.78764 | grad_wrt_mu     0.00735 | grad_wrt_b_per_user     0.00103 | grad_wrt_c_per_item     0.00072 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      27.000 | loss_total     0.93093 | train_MAE     0.77151 | valid_MAE     0.78480 | grad_wrt_mu     0.01626 | grad_wrt_b_per_user     0.00109 | grad_wrt_c_per_item     0.00062 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      28.000 | loss_total     0.92916 | train_MAE     0.77225 | valid_MAE     0.78484 | grad_wrt_mu     0.04377 | grad_wrt_b_per_user     0.00107 | grad_wrt_c_per_item     0.00065 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      29.000 | loss_total     0.92666 | train_MAE     0.77156 | valid_MAE     0.78403 | grad_wrt_mu     0.00540 | grad_wrt_b_per_user     0.00112 | grad_wrt_c_per_item     0.00062 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      30.000 | loss_total     0.92461 | train_MAE     0.76900 | valid_MAE     0.78197 | grad_wrt_mu     0.00526 | grad_wrt_b_per_user     0.00117 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      31.000 | loss_total     0.91960 | train_MAE     0.76722 | valid_MAE     0.78046 | grad_wrt_mu     0.01384 | grad_wrt_b_per_user     0.00108 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      32.000 | loss_total     0.91904 | train_MAE     0.76500 | valid_MAE     0.77870 | grad_wrt_mu     0.01947 | grad_wrt_b_per_user     0.00109 | grad_wrt_c_per_item     0.00064 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      34.000 | loss_total     0.91434 | train_MAE     0.76267 | valid_MAE     0.77658 | grad_wrt_mu     0.05316 | grad_wrt_b_per_user     0.00107 | grad_wrt_c_per_item     0.00066 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      36.000 | loss_total     0.91120 | train_MAE     0.76193 | valid_MAE     0.77557 | grad_wrt_mu     0.09753 | grad_wrt_b_per_user     0.00118 | grad_wrt_c_per_item     0.00065 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      38.000 | loss_total     0.90703 | train_MAE     0.75820 | valid_MAE     0.77276 | grad_wrt_mu     0.04667 | grad_wrt_b_per_user     0.00113 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      40.000 | loss_total     0.90421 | train_MAE     0.75605 | valid_MAE     0.77100 | grad_wrt_mu     0.11184 | grad_wrt_b_per_user     0.00110 | grad_wrt_c_per_item     0.00066 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      42.000 | loss_total     0.90080 | train_MAE     0.75579 | valid_MAE     0.77036 | grad_wrt_mu     0.08196 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00068 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      44.000 | loss_total     0.89572 | train_MAE     0.75372 | valid_MAE     0.76871 | grad_wrt_mu     0.03452 | grad_wrt_b_per_user     0.00114 | grad_wrt_c_per_item     0.00065 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      46.000 | loss_total     0.89348 | train_MAE     0.75361 | valid_MAE     0.76829 | grad_wrt_mu     0.02135 | grad_wrt_b_per_user     0.00109 | grad_wrt_c_per_item     0.00065 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      48.000 | loss_total     0.89086 | train_MAE     0.75106 | valid_MAE     0.76639 | grad_wrt_mu     0.02491 | grad_wrt_b_per_user     0.00107 | grad_wrt_c_per_item     0.00065 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      50.000 | loss_total     0.88882 | train_MAE     0.74951 | valid_MAE     0.76513 | grad_wrt_mu     0.04796 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00063 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      52.000 | loss_total     0.88621 | train_MAE     0.74846 | valid_MAE     0.76418 | grad_wrt_mu     0.03682 | grad_wrt_b_per_user     0.00108 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      54.000 | loss_total     0.88500 | train_MAE     0.74939 | valid_MAE     0.76452 | grad_wrt_mu     0.06655 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00064 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      56.000 | loss_total     0.88333 | train_MAE     0.74896 | valid_MAE     0.76406 | grad_wrt_mu     0.01612 | grad_wrt_b_per_user     0.00113 | grad_wrt_c_per_item     0.00064 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      58.000 | loss_total     0.88085 | train_MAE     0.74482 | valid_MAE     0.76119 | grad_wrt_mu     0.10407 | grad_wrt_b_per_user     0.00105 | grad_wrt_c_per_item     0.00062 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      60.000 | loss_total     0.87898 | train_MAE     0.74558 | valid_MAE     0.76142 | grad_wrt_mu     0.09673 | grad_wrt_b_per_user     0.00109 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      62.000 | loss_total     0.87674 | train_MAE     0.74445 | valid_MAE     0.76052 | grad_wrt_mu     0.09466 | grad_wrt_b_per_user     0.00105 | grad_wrt_c_per_item     0.00063 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      64.000 | loss_total     0.87784 | train_MAE     0.74262 | valid_MAE     0.75922 | grad_wrt_mu     0.06638 | grad_wrt_b_per_user     0.00112 | grad_wrt_c_per_item     0.00066 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      66.000 | loss_total     0.87402 | train_MAE     0.74070 | valid_MAE     0.75795 | grad_wrt_mu     0.08297 | grad_wrt_b_per_user     0.00105 | grad_wrt_c_per_item     0.00064 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      68.000 | loss_total     0.87323 | train_MAE     0.74261 | valid_MAE     0.75887 | grad_wrt_mu     0.02168 | grad_wrt_b_per_user     0.00110 | grad_wrt_c_per_item     0.00064 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      70.000 | loss_total     0.87032 | train_MAE     0.74095 | valid_MAE     0.75768 | grad_wrt_mu     0.02514 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00060 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      72.000 | loss_total     0.86990 | train_MAE     0.74163 | valid_MAE     0.75795 | grad_wrt_mu     0.02603 | grad_wrt_b_per_user     0.00114 | grad_wrt_c_per_item     0.00063 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      74.000 | loss_total     0.86796 | train_MAE     0.74107 | valid_MAE     0.75745 | grad_wrt_mu     0.09072 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00062 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      76.000 | loss_total     0.86835 | train_MAE     0.73817 | valid_MAE     0.75553 | grad_wrt_mu     0.01426 | grad_wrt_b_per_user     0.00108 | grad_wrt_c_per_item     0.00065 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      78.000 | loss_total     0.86550 | train_MAE     0.73817 | valid_MAE     0.75538 | grad_wrt_mu     0.13716 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00060 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      80.000 | loss_total     0.86506 | train_MAE     0.73845 | valid_MAE     0.75541 | grad_wrt_mu     0.04927 | grad_wrt_b_per_user     0.00105 | grad_wrt_c_per_item     0.00063 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      82.000 | loss_total     0.86473 | train_MAE     0.73663 | valid_MAE     0.75418 | grad_wrt_mu     0.01277 | grad_wrt_b_per_user     0.00105 | grad_wrt_c_per_item     0.00064 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      84.000 | loss_total     0.86536 | train_MAE     0.73739 | valid_MAE     0.75452 | grad_wrt_mu     0.09964 | grad_wrt_b_per_user     0.00112 | grad_wrt_c_per_item     0.00066 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      86.000 | loss_total     0.86338 | train_MAE     0.73623 | valid_MAE     0.75368 | grad_wrt_mu     0.00293 | grad_wrt_b_per_user     0.00111 | grad_wrt_c_per_item     0.00064 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      88.000 | loss_total     0.86129 | train_MAE     0.73662 | valid_MAE     0.75382 | grad_wrt_mu     0.03233 | grad_wrt_b_per_user     0.00103 | grad_wrt_c_per_item     0.00058 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      90.000 | loss_total     0.86233 | train_MAE     0.73563 | valid_MAE     0.75309 | grad_wrt_mu     0.09686 | grad_wrt_b_per_user     0.00105 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      92.000 | loss_total     0.85986 | train_MAE     0.73463 | valid_MAE     0.75237 | grad_wrt_mu     0.05428 | grad_wrt_b_per_user     0.00112 | grad_wrt_c_per_item     0.00065 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      94.000 | loss_total     0.85803 | train_MAE     0.73426 | valid_MAE     0.75205 | grad_wrt_mu     0.02311 | grad_wrt_b_per_user     0.00104 | grad_wrt_c_per_item     0.00062 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      96.000 | loss_total     0.85942 | train_MAE     0.73398 | valid_MAE     0.75177 | grad_wrt_mu     0.07600 | grad_wrt_b_per_user     0.00107 | grad_wrt_c_per_item     0.00057 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      98.000 | loss_total     0.85737 | train_MAE     0.73306 | valid_MAE     0.75113 | grad_wrt_mu     0.00935 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00058 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      99.986 | loss_total     0.85673 | train_MAE     0.73371 | valid_MAE     0.75145 | grad_wrt_mu     0.01592 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00062 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n"
     ]
    }
   ],
   "source": [
    "M3_2f.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M3_2f.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7516040716005185"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation\n",
    "ratigs_hat_va_M3 = M3_2f.predict(valid_tuple[0], valid_tuple[1])\n",
    "metrics.mean_absolute_error(valid_tuple[2], ratigs_hat_va_M3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7576869944092113"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratigs_hat_te_M3 = M3_2f.predict(test_tuple[0], test_tuple[1])\n",
    "metrics.mean_absolute_error(test_tuple[2], ratigs_hat_te_M3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total     3.64000 | train_MAE     3.53059 | valid_MAE     3.50620 | grad_wrt_mu     1.00000\n",
      "epoch       0.001 | loss_total     3.63000 | train_MAE     3.43059 | valid_MAE     3.40620 | grad_wrt_mu     1.00000\n",
      "epoch       0.003 | loss_total     3.35000 | train_MAE     3.33059 | valid_MAE     3.30620 | grad_wrt_mu     1.00000\n",
      "epoch       0.004 | loss_total     3.39000 | train_MAE     3.23059 | valid_MAE     3.20620 | grad_wrt_mu     1.00000\n",
      "epoch       0.126 | loss_total     0.96720 | train_MAE     0.94013 | valid_MAE     0.94254 | grad_wrt_mu     0.04000\n",
      "epoch       0.250 | loss_total     0.98880 | train_MAE     0.89518 | valid_MAE     0.90942 | grad_wrt_mu     0.06000\n",
      "epoch       0.376 | loss_total     0.94104 | train_MAE     0.89584 | valid_MAE     0.90990 | grad_wrt_mu     0.04000\n",
      "epoch       0.500 | loss_total     0.94144 | train_MAE     0.89496 | valid_MAE     0.90925 | grad_wrt_mu     0.08000\n",
      "epoch       0.626 | loss_total     0.91900 | train_MAE     0.89847 | valid_MAE     0.91184 | grad_wrt_mu     0.18000\n",
      "epoch       0.750 | loss_total     1.03876 | train_MAE     0.89978 | valid_MAE     0.91281 | grad_wrt_mu     0.02000\n",
      "epoch       0.876 | loss_total     0.86312 | train_MAE     0.89644 | valid_MAE     0.91132 | grad_wrt_mu     0.52000\n",
      "epoch       1.000 | loss_total     0.79672 | train_MAE     0.89562 | valid_MAE     0.90974 | grad_wrt_mu     0.28000\n",
      "epoch       1.126 | loss_total     0.95756 | train_MAE     0.90336 | valid_MAE     0.91835 | grad_wrt_mu     0.42000\n",
      "epoch       1.250 | loss_total     0.97240 | train_MAE     0.89737 | valid_MAE     0.91103 | grad_wrt_mu     0.06000\n",
      "epoch       1.376 | loss_total     0.86180 | train_MAE     0.89408 | valid_MAE     0.90861 | grad_wrt_mu     0.18000\n",
      "epoch       1.500 | loss_total     0.85736 | train_MAE     0.89803 | valid_MAE     0.91152 | grad_wrt_mu     0.16000\n",
      "epoch       1.626 | loss_total     0.95000 | train_MAE     0.89408 | valid_MAE     0.90861 | grad_wrt_mu     0.00000\n",
      "epoch       1.750 | loss_total     0.78040 | train_MAE     0.89342 | valid_MAE     0.90812 | grad_wrt_mu     0.10000\n",
      "epoch       1.876 | loss_total     0.92768 | train_MAE     0.89825 | valid_MAE     0.91168 | grad_wrt_mu     0.16000\n",
      "epoch       2.000 | loss_total     0.90144 | train_MAE     0.89430 | valid_MAE     0.90877 | grad_wrt_mu     0.12000\n",
      "epoch       2.500 | loss_total     0.89651 | train_MAE     0.89320 | valid_MAE     0.90796 | grad_wrt_mu     0.18000\n",
      "epoch       3.000 | loss_total     0.89658 | train_MAE     0.89759 | valid_MAE     0.91119 | grad_wrt_mu     0.14000\n",
      "epoch       3.500 | loss_total     0.89793 | train_MAE     0.89320 | valid_MAE     0.90796 | grad_wrt_mu     0.00000\n",
      "epoch       4.000 | loss_total     0.89690 | train_MAE     0.89891 | valid_MAE     0.91216 | grad_wrt_mu     0.04000\n",
      "epoch       4.500 | loss_total     0.89989 | train_MAE     0.89737 | valid_MAE     0.91103 | grad_wrt_mu     0.06000\n",
      "epoch       5.000 | loss_total     0.89628 | train_MAE     0.89606 | valid_MAE     0.91006 | grad_wrt_mu     0.08000\n",
      "epoch       5.500 | loss_total     0.89279 | train_MAE     0.89474 | valid_MAE     0.90909 | grad_wrt_mu     0.12000\n",
      "epoch       6.000 | loss_total     0.89667 | train_MAE     0.89693 | valid_MAE     0.91071 | grad_wrt_mu     0.18000\n",
      "epoch       6.500 | loss_total     0.89715 | train_MAE     0.89342 | valid_MAE     0.90812 | grad_wrt_mu     0.12000\n",
      "epoch       7.000 | loss_total     0.89649 | train_MAE     0.89912 | valid_MAE     0.91232 | grad_wrt_mu     0.22000\n",
      "epoch       7.500 | loss_total     0.89961 | train_MAE     0.89364 | valid_MAE     0.90828 | grad_wrt_mu     0.18000\n",
      "epoch       8.000 | loss_total     0.89681 | train_MAE     0.89693 | valid_MAE     0.91071 | grad_wrt_mu     0.06000\n",
      "epoch       9.000 | loss_total     0.89635 | train_MAE     0.89414 | valid_MAE     0.90897 | grad_wrt_mu     0.54000\n",
      "epoch      10.000 | loss_total     0.89652 | train_MAE     0.89606 | valid_MAE     0.91006 | grad_wrt_mu     0.26000\n",
      "epoch      11.000 | loss_total     0.89691 | train_MAE     0.89562 | valid_MAE     0.90974 | grad_wrt_mu     0.14000\n",
      "epoch      12.000 | loss_total     0.89631 | train_MAE     0.89540 | valid_MAE     0.90958 | grad_wrt_mu     0.14000\n",
      "epoch      13.000 | loss_total     0.89688 | train_MAE     0.89847 | valid_MAE     0.91184 | grad_wrt_mu     0.16000\n",
      "epoch      14.000 | loss_total     0.89633 | train_MAE     0.89452 | valid_MAE     0.90893 | grad_wrt_mu     0.18000\n",
      "epoch      15.000 | loss_total     0.89651 | train_MAE     0.90567 | valid_MAE     0.92069 | grad_wrt_mu     0.66000\n",
      "epoch      16.000 | loss_total     0.89684 | train_MAE     0.89430 | valid_MAE     0.90877 | grad_wrt_mu     0.00000\n",
      "epoch      17.000 | loss_total     0.89649 | train_MAE     0.89364 | valid_MAE     0.90828 | grad_wrt_mu     0.16000\n",
      "epoch      18.000 | loss_total     0.89662 | train_MAE     0.89649 | valid_MAE     0.91039 | grad_wrt_mu     0.20000\n",
      "epoch      19.000 | loss_total     0.89660 | train_MAE     0.89781 | valid_MAE     0.91136 | grad_wrt_mu     0.18000\n",
      "epoch      20.000 | loss_total     0.89665 | train_MAE     0.89803 | valid_MAE     0.91152 | grad_wrt_mu     0.10000\n",
      "epoch      21.000 | loss_total     0.89674 | train_MAE     0.89540 | valid_MAE     0.90958 | grad_wrt_mu     0.06000\n",
      "epoch      22.000 | loss_total     0.89680 | train_MAE     0.89386 | valid_MAE     0.90845 | grad_wrt_mu     0.06000\n",
      "epoch      23.000 | loss_total     0.89648 | train_MAE     0.89408 | valid_MAE     0.90861 | grad_wrt_mu     0.10000\n",
      "epoch      24.000 | loss_total     0.89676 | train_MAE     0.89474 | valid_MAE     0.90909 | grad_wrt_mu     0.02000\n",
      "epoch      25.000 | loss_total     0.89642 | train_MAE     0.89759 | valid_MAE     0.91119 | grad_wrt_mu     0.20000\n",
      "epoch      26.000 | loss_total     0.89673 | train_MAE     0.89715 | valid_MAE     0.91087 | grad_wrt_mu     0.10000\n",
      "epoch      27.000 | loss_total     0.89666 | train_MAE     0.89891 | valid_MAE     0.91216 | grad_wrt_mu     0.08000\n",
      "epoch      28.000 | loss_total     0.89665 | train_MAE     0.89299 | valid_MAE     0.90780 | grad_wrt_mu     0.04000\n",
      "epoch      29.000 | loss_total     0.89658 | train_MAE     0.89414 | valid_MAE     0.90897 | grad_wrt_mu     0.70000\n",
      "epoch      30.000 | loss_total     0.89658 | train_MAE     0.89452 | valid_MAE     0.90893 | grad_wrt_mu     0.08000\n",
      "epoch      31.000 | loss_total     0.89668 | train_MAE     0.89518 | valid_MAE     0.90942 | grad_wrt_mu     0.02000\n",
      "epoch      32.000 | loss_total     0.89668 | train_MAE     0.89644 | valid_MAE     0.91132 | grad_wrt_mu     0.56000\n",
      "epoch      34.000 | loss_total     0.89656 | train_MAE     0.89474 | valid_MAE     0.90909 | grad_wrt_mu     0.22000\n",
      "epoch      36.000 | loss_total     0.89656 | train_MAE     0.89760 | valid_MAE     0.91249 | grad_wrt_mu     0.58000\n",
      "epoch      38.000 | loss_total     0.89683 | train_MAE     0.89737 | valid_MAE     0.91103 | grad_wrt_mu     0.08000\n",
      "epoch      40.000 | loss_total     0.89660 | train_MAE     0.89869 | valid_MAE     0.91200 | grad_wrt_mu     0.04000\n",
      "epoch      42.000 | loss_total     0.89674 | train_MAE     0.89364 | valid_MAE     0.90828 | grad_wrt_mu     0.10000\n",
      "epoch      44.000 | loss_total     0.89661 | train_MAE     0.89803 | valid_MAE     0.91152 | grad_wrt_mu     0.08000\n",
      "epoch      46.000 | loss_total     0.89693 | train_MAE     0.89627 | valid_MAE     0.91022 | grad_wrt_mu     0.02000\n",
      "epoch      48.000 | loss_total     0.89670 | train_MAE     0.89781 | valid_MAE     0.91136 | grad_wrt_mu     0.18000\n",
      "epoch      50.000 | loss_total     0.89638 | train_MAE     0.89562 | valid_MAE     0.90974 | grad_wrt_mu     0.06000\n",
      "epoch      52.000 | loss_total     0.89670 | train_MAE     0.89529 | valid_MAE     0.91014 | grad_wrt_mu     0.60000\n",
      "epoch      54.000 | loss_total     0.89648 | train_MAE     0.89693 | valid_MAE     0.91071 | grad_wrt_mu     0.04000\n",
      "epoch      56.000 | loss_total     0.89633 | train_MAE     0.89869 | valid_MAE     0.91200 | grad_wrt_mu     0.10000\n",
      "epoch      58.000 | loss_total     0.89664 | train_MAE     0.89649 | valid_MAE     0.91039 | grad_wrt_mu     0.16000\n",
      "epoch      60.000 | loss_total     0.89691 | train_MAE     0.89627 | valid_MAE     0.91022 | grad_wrt_mu     0.06000\n",
      "epoch      62.000 | loss_total     0.89653 | train_MAE     0.89990 | valid_MAE     0.91483 | grad_wrt_mu     0.44000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      64.000 | loss_total     0.89667 | train_MAE     0.89737 | valid_MAE     0.91103 | grad_wrt_mu     0.14000\n",
      "epoch      66.000 | loss_total     0.89687 | train_MAE     0.89496 | valid_MAE     0.90925 | grad_wrt_mu     0.14000\n",
      "epoch      68.000 | loss_total     0.89641 | train_MAE     0.89737 | valid_MAE     0.91103 | grad_wrt_mu     0.06000\n",
      "epoch      70.000 | loss_total     0.89707 | train_MAE     0.89847 | valid_MAE     0.91184 | grad_wrt_mu     0.10000\n",
      "epoch      72.000 | loss_total     0.89695 | train_MAE     0.89540 | valid_MAE     0.90958 | grad_wrt_mu     0.16000\n",
      "epoch      74.000 | loss_total     0.89658 | train_MAE     0.89869 | valid_MAE     0.91200 | grad_wrt_mu     0.04000\n",
      "epoch      76.000 | loss_total     0.89651 | train_MAE     0.89760 | valid_MAE     0.91249 | grad_wrt_mu     0.46000\n",
      "epoch      78.000 | loss_total     0.89661 | train_MAE     0.90000 | valid_MAE     0.91297 | grad_wrt_mu     0.22000\n",
      "epoch      80.000 | loss_total     0.89643 | train_MAE     0.89759 | valid_MAE     0.91119 | grad_wrt_mu     0.10000\n",
      "epoch      82.000 | loss_total     0.89712 | train_MAE     0.89715 | valid_MAE     0.91087 | grad_wrt_mu     0.04000\n",
      "epoch      84.000 | loss_total     0.89673 | train_MAE     0.89825 | valid_MAE     0.91168 | grad_wrt_mu     0.04000\n",
      "epoch      86.000 | loss_total     0.89689 | train_MAE     0.89408 | valid_MAE     0.90861 | grad_wrt_mu     0.00000\n",
      "epoch      88.000 | loss_total     0.89634 | train_MAE     0.89875 | valid_MAE     0.91366 | grad_wrt_mu     0.70000\n",
      "epoch      90.000 | loss_total     0.89651 | train_MAE     0.89781 | valid_MAE     0.91136 | grad_wrt_mu     0.06000\n",
      "epoch      92.000 | loss_total     0.89659 | train_MAE     0.89386 | valid_MAE     0.90845 | grad_wrt_mu     0.02000\n",
      "epoch      94.000 | loss_total     0.89682 | train_MAE     0.89430 | valid_MAE     0.90877 | grad_wrt_mu     0.06000\n",
      "epoch      96.000 | loss_total     0.89669 | train_MAE     0.89759 | valid_MAE     0.91119 | grad_wrt_mu     0.14000\n",
      "epoch      98.000 | loss_total     0.89654 | train_MAE     0.89386 | valid_MAE     0.90845 | grad_wrt_mu     0.14000\n",
      "epoch      99.999 | loss_total     0.89655 | train_MAE     0.90044 | valid_MAE     0.91329 | grad_wrt_mu     0.06000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9128096000002875"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a new loss function! \n",
    "# I've changed the loss functions in all the 3 .py files we had for the previous problems\n",
    "\n",
    "# M1\n",
    "SEED = 101\n",
    "M1_abs = CollabFilterMeanOnly(batch_size=100, random_state=SEED)\n",
    "M1_abs.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M1_abs.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)\n",
    "ratigs_hat_va_M1_abs = M1_abs.predict(valid_tuple[0], valid_tuple[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128096000002875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid 100 M1 abs\n",
    "ratigs_hat_va_M1_abs = M1_abs.predict(valid_tuple[0], valid_tuple[1])\n",
    "metrics.mean_absolute_error(valid_tuple[2], ratigs_hat_va_M1_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8961072858290873"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 100 M1 abs\n",
    "ratigs_hat_te_M1_abs = M1_abs.predict(test_tuple[0], test_tuple[1])\n",
    "metrics.mean_absolute_error(test_tuple[2], ratigs_hat_te_M1_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total     3.53820 | train_MAE     3.53059 | valid_MAE     3.50620 | grad_wrt_mu     1.00000\n",
      "epoch       0.143 | loss_total     3.40860 | train_MAE     3.43059 | valid_MAE     3.40620 | grad_wrt_mu     1.00000\n",
      "epoch       0.286 | loss_total     3.32110 | train_MAE     3.33059 | valid_MAE     3.30620 | grad_wrt_mu     1.00000\n",
      "epoch       0.429 | loss_total     3.23920 | train_MAE     3.23059 | valid_MAE     3.20620 | grad_wrt_mu     1.00000\n",
      "epoch       0.571 | loss_total     3.13740 | train_MAE     3.13059 | valid_MAE     3.10620 | grad_wrt_mu     1.00000\n",
      "epoch       0.714 | loss_total     3.03120 | train_MAE     3.03059 | valid_MAE     3.00620 | grad_wrt_mu     1.00000\n",
      "epoch       0.857 | loss_total     2.93840 | train_MAE     2.93059 | valid_MAE     2.90620 | grad_wrt_mu     1.00000\n",
      "epoch       1.000 | loss_total     2.82950 | train_MAE     2.83059 | valid_MAE     2.80620 | grad_wrt_mu     1.00000\n",
      "epoch       1.143 | loss_total     2.71850 | train_MAE     2.73059 | valid_MAE     2.70620 | grad_wrt_mu     1.00000\n",
      "epoch       1.286 | loss_total     2.64190 | train_MAE     2.63059 | valid_MAE     2.60620 | grad_wrt_mu     1.00000\n",
      "epoch       1.429 | loss_total     2.52500 | train_MAE     2.53059 | valid_MAE     2.50620 | grad_wrt_mu     1.00000\n",
      "epoch       1.571 | loss_total     2.44846 | train_MAE     2.44286 | valid_MAE     2.41858 | grad_wrt_mu     0.87340\n",
      "epoch       1.714 | loss_total     2.36060 | train_MAE     2.36624 | valid_MAE     2.34205 | grad_wrt_mu     0.87540\n",
      "epoch       1.857 | loss_total     2.29850 | train_MAE     2.28944 | valid_MAE     2.26535 | grad_wrt_mu     0.87420\n",
      "epoch       2.000 | loss_total     2.20249 | train_MAE     2.21275 | valid_MAE     2.18875 | grad_wrt_mu     0.88080\n",
      "epoch       2.571 | loss_total     2.13733 | train_MAE     1.90454 | valid_MAE     1.88093 | grad_wrt_mu     0.87560\n",
      "epoch       3.000 | loss_total     1.90760 | train_MAE     1.67400 | valid_MAE     1.65068 | grad_wrt_mu     0.87580\n",
      "epoch       3.571 | loss_total     1.63538 | train_MAE     1.48479 | valid_MAE     1.46389 | grad_wrt_mu     0.64020\n",
      "epoch       4.000 | loss_total     1.48297 | train_MAE     1.35812 | valid_MAE     1.33904 | grad_wrt_mu     0.64500\n",
      "epoch       4.571 | loss_total     1.31436 | train_MAE     1.18930 | valid_MAE     1.17262 | grad_wrt_mu     0.65960\n",
      "epoch       5.000 | loss_total     1.18977 | train_MAE     1.06175 | valid_MAE     1.04689 | grad_wrt_mu     0.65600\n",
      "epoch       5.571 | loss_total     1.04561 | train_MAE     0.99602 | valid_MAE     0.98374 | grad_wrt_mu     0.11860\n",
      "epoch       6.000 | loss_total     1.00022 | train_MAE     0.99242 | valid_MAE     0.98109 | grad_wrt_mu     0.11540\n",
      "epoch       6.571 | loss_total     0.99279 | train_MAE     0.98745 | valid_MAE     0.97742 | grad_wrt_mu     0.11340\n",
      "epoch       7.000 | loss_total     0.98604 | train_MAE     0.98401 | valid_MAE     0.97489 | grad_wrt_mu     0.10040\n",
      "epoch       7.571 | loss_total     0.98306 | train_MAE     0.97919 | valid_MAE     0.97134 | grad_wrt_mu     0.10280\n",
      "epoch       8.000 | loss_total     0.97877 | train_MAE     0.97559 | valid_MAE     0.96868 | grad_wrt_mu     0.10120\n",
      "epoch       9.000 | loss_total     0.96992 | train_MAE     0.96718 | valid_MAE     0.96248 | grad_wrt_mu     0.10440\n",
      "epoch      10.000 | loss_total     0.96391 | train_MAE     0.95877 | valid_MAE     0.95628 | grad_wrt_mu     0.11480\n",
      "epoch      11.000 | loss_total     0.95487 | train_MAE     0.95035 | valid_MAE     0.95008 | grad_wrt_mu     0.12580\n",
      "epoch      12.000 | loss_total     0.94358 | train_MAE     0.94194 | valid_MAE     0.94388 | grad_wrt_mu     0.11940\n",
      "epoch      13.000 | loss_total     0.93705 | train_MAE     0.93353 | valid_MAE     0.93768 | grad_wrt_mu     0.12460\n",
      "epoch      14.000 | loss_total     0.93106 | train_MAE     0.92512 | valid_MAE     0.93148 | grad_wrt_mu     0.10860\n",
      "epoch      15.000 | loss_total     0.91794 | train_MAE     0.91670 | valid_MAE     0.92528 | grad_wrt_mu     0.10900\n",
      "epoch      16.000 | loss_total     0.91199 | train_MAE     0.90829 | valid_MAE     0.91908 | grad_wrt_mu     0.11860\n",
      "epoch      17.000 | loss_total     0.90652 | train_MAE     0.89988 | valid_MAE     0.91288 | grad_wrt_mu     0.09220\n",
      "epoch      18.000 | loss_total     0.89271 | train_MAE     0.89906 | valid_MAE     0.91228 | grad_wrt_mu     0.12120\n",
      "epoch      19.000 | loss_total     0.89729 | train_MAE     0.89825 | valid_MAE     0.91168 | grad_wrt_mu     0.10380\n",
      "epoch      20.000 | loss_total     0.89686 | train_MAE     0.89732 | valid_MAE     0.91100 | grad_wrt_mu     0.10380\n",
      "epoch      21.000 | loss_total     0.89716 | train_MAE     0.89619 | valid_MAE     0.91016 | grad_wrt_mu     0.10740\n",
      "epoch      22.000 | loss_total     0.89470 | train_MAE     0.89528 | valid_MAE     0.90949 | grad_wrt_mu     0.11400\n",
      "epoch      23.000 | loss_total     0.89765 | train_MAE     0.89446 | valid_MAE     0.90889 | grad_wrt_mu     0.10920\n",
      "epoch      24.000 | loss_total     0.89595 | train_MAE     0.89372 | valid_MAE     0.90834 | grad_wrt_mu     0.10260\n",
      "epoch      25.000 | loss_total     0.89574 | train_MAE     0.89440 | valid_MAE     0.90924 | grad_wrt_mu     0.58420\n",
      "epoch      26.000 | loss_total     0.89639 | train_MAE     0.89914 | valid_MAE     0.91234 | grad_wrt_mu     0.11440\n",
      "epoch      27.000 | loss_total     0.89460 | train_MAE     0.89830 | valid_MAE     0.91172 | grad_wrt_mu     0.11400\n",
      "epoch      28.000 | loss_total     0.89617 | train_MAE     0.89744 | valid_MAE     0.91109 | grad_wrt_mu     0.11240\n",
      "epoch      29.000 | loss_total     0.89708 | train_MAE     0.89669 | valid_MAE     0.91053 | grad_wrt_mu     0.10800\n",
      "epoch      30.000 | loss_total     0.89551 | train_MAE     0.89580 | valid_MAE     0.90988 | grad_wrt_mu     0.09400\n",
      "epoch      31.000 | loss_total     0.89681 | train_MAE     0.89501 | valid_MAE     0.90929 | grad_wrt_mu     0.10420\n",
      "epoch      32.000 | loss_total     0.89566 | train_MAE     0.89408 | valid_MAE     0.90861 | grad_wrt_mu     0.11140\n",
      "epoch      34.000 | loss_total     0.89378 | train_MAE     0.89672 | valid_MAE     0.91160 | grad_wrt_mu     0.58040\n",
      "epoch      36.000 | loss_total     0.89610 | train_MAE     0.89785 | valid_MAE     0.91138 | grad_wrt_mu     0.10780\n",
      "epoch      38.000 | loss_total     0.89500 | train_MAE     0.89597 | valid_MAE     0.91000 | grad_wrt_mu     0.10820\n",
      "epoch      40.000 | loss_total     0.89685 | train_MAE     0.89426 | valid_MAE     0.90874 | grad_wrt_mu     0.10160\n",
      "epoch      42.000 | loss_total     0.89744 | train_MAE     0.89422 | valid_MAE     0.90905 | grad_wrt_mu     0.58000\n",
      "epoch      44.000 | loss_total     0.89379 | train_MAE     0.89848 | valid_MAE     0.91185 | grad_wrt_mu     0.10060\n",
      "epoch      46.000 | loss_total     0.89559 | train_MAE     0.89681 | valid_MAE     0.91062 | grad_wrt_mu     0.10640\n",
      "epoch      48.000 | loss_total     0.89838 | train_MAE     0.89514 | valid_MAE     0.90939 | grad_wrt_mu     0.10500\n",
      "epoch      50.000 | loss_total     0.89688 | train_MAE     0.89345 | valid_MAE     0.90814 | grad_wrt_mu     0.10820\n",
      "epoch      52.000 | loss_total     0.89589 | train_MAE     0.89910 | valid_MAE     0.91231 | grad_wrt_mu     0.10340\n",
      "epoch      54.000 | loss_total     0.89508 | train_MAE     0.89743 | valid_MAE     0.91107 | grad_wrt_mu     0.12720\n",
      "epoch      56.000 | loss_total     0.89564 | train_MAE     0.89555 | valid_MAE     0.90969 | grad_wrt_mu     0.11460\n",
      "epoch      58.000 | loss_total     0.89511 | train_MAE     0.89379 | valid_MAE     0.90839 | grad_wrt_mu     0.11440\n",
      "epoch      60.000 | loss_total     0.89507 | train_MAE     0.89812 | valid_MAE     0.91302 | grad_wrt_mu     0.57320\n",
      "epoch      62.000 | loss_total     0.89473 | train_MAE     0.89760 | valid_MAE     0.91120 | grad_wrt_mu     0.12080\n",
      "epoch      64.000 | loss_total     0.89601 | train_MAE     0.89588 | valid_MAE     0.90993 | grad_wrt_mu     0.10820\n",
      "epoch      66.000 | loss_total     0.89612 | train_MAE     0.89419 | valid_MAE     0.90869 | grad_wrt_mu     0.10360\n",
      "epoch      68.000 | loss_total     0.89533 | train_MAE     0.89587 | valid_MAE     0.91073 | grad_wrt_mu     0.57300\n",
      "epoch      70.000 | loss_total     0.89724 | train_MAE     0.89818 | valid_MAE     0.91163 | grad_wrt_mu     0.11020\n",
      "epoch      72.000 | loss_total     0.89761 | train_MAE     0.89639 | valid_MAE     0.91031 | grad_wrt_mu     0.10640\n",
      "epoch      74.000 | loss_total     0.89596 | train_MAE     0.89455 | valid_MAE     0.90895 | grad_wrt_mu     0.10920\n",
      "epoch      76.000 | loss_total     0.89624 | train_MAE     0.89390 | valid_MAE     0.90873 | grad_wrt_mu     0.57040\n",
      "epoch      78.000 | loss_total     0.89852 | train_MAE     0.89848 | valid_MAE     0.91185 | grad_wrt_mu     0.08440\n",
      "epoch      80.000 | loss_total     0.89525 | train_MAE     0.89690 | valid_MAE     0.91068 | grad_wrt_mu     0.10380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      82.000 | loss_total     0.89917 | train_MAE     0.89504 | valid_MAE     0.90931 | grad_wrt_mu     0.09760\n",
      "epoch      84.000 | loss_total     0.89833 | train_MAE     0.89311 | valid_MAE     0.90793 | grad_wrt_mu     0.57020\n",
      "epoch      86.000 | loss_total     0.89696 | train_MAE     0.89850 | valid_MAE     0.91187 | grad_wrt_mu     0.11780\n",
      "epoch      88.000 | loss_total     0.89537 | train_MAE     0.89669 | valid_MAE     0.91053 | grad_wrt_mu     0.10260\n",
      "epoch      90.000 | loss_total     0.89819 | train_MAE     0.89495 | valid_MAE     0.90924 | grad_wrt_mu     0.11440\n",
      "epoch      92.000 | loss_total     0.89684 | train_MAE     0.89328 | valid_MAE     0.90802 | grad_wrt_mu     0.09700\n",
      "epoch      94.000 | loss_total     0.89782 | train_MAE     0.89904 | valid_MAE     0.91226 | grad_wrt_mu     0.10460\n",
      "epoch      96.000 | loss_total     0.89696 | train_MAE     0.89703 | valid_MAE     0.91078 | grad_wrt_mu     0.10260\n",
      "epoch      98.000 | loss_total     0.89633 | train_MAE     0.89541 | valid_MAE     0.90959 | grad_wrt_mu     0.11020\n",
      "epoch      99.857 | loss_total     0.89585 | train_MAE     0.89475 | valid_MAE     0.90910 | grad_wrt_mu     0.10020\n"
     ]
    }
   ],
   "source": [
    "# M1 batch size 100 abs\n",
    "M1_10000_abs = CollabFilterMeanOnly(batch_size=10000, random_state=SEED)\n",
    "M1_10000_abs.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M1_10000_abs.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9082880319999999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid 10000 M1 abs\n",
    "ratigs_hat_va_M1_10000_abs = M1_10000_abs.predict(valid_tuple[0], valid_tuple[1])\n",
    "metrics.mean_absolute_error(valid_tuple[2], ratigs_hat_va_M1_10000_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8894315132105682"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 10000 M1 abs\n",
    "ratigs_hat_te_M1_10000_abs = M1_10000_abs.predict(test_tuple[0], test_tuple[1])\n",
    "metrics.mean_absolute_error(test_tuple[2], ratigs_hat_te_M1_10000_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total     3.64000 | train_MAE     3.53059 | valid_MAE     3.50620 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       0.001 | loss_total     3.62950 | train_MAE     3.43023 | valid_MAE     3.40585 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       0.003 | loss_total     3.34921 | train_MAE     3.32984 | valid_MAE     3.30547 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       0.004 | loss_total     3.38889 | train_MAE     3.22944 | valid_MAE     3.20507 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       0.126 | loss_total     0.96410 | train_MAE     0.93710 | valid_MAE     0.93957 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00056\n",
      "epoch       0.250 | loss_total     0.98308 | train_MAE     0.88927 | valid_MAE     0.90405 | grad_wrt_mu     0.12000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00057\n",
      "epoch       0.376 | loss_total     0.93393 | train_MAE     0.88641 | valid_MAE     0.90087 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00055\n",
      "epoch       0.500 | loss_total     0.93345 | train_MAE     0.88430 | valid_MAE     0.89890 | grad_wrt_mu     0.12000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00058\n",
      "epoch       0.626 | loss_total     0.90025 | train_MAE     0.88243 | valid_MAE     0.89672 | grad_wrt_mu     0.12000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00054\n",
      "epoch       0.750 | loss_total     1.01919 | train_MAE     0.88154 | valid_MAE     0.89516 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00054\n",
      "epoch       0.876 | loss_total     0.85396 | train_MAE     0.87793 | valid_MAE     0.89254 | grad_wrt_mu     0.12000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00058\n",
      "epoch       1.000 | loss_total     0.79154 | train_MAE     0.87583 | valid_MAE     0.89014 | grad_wrt_mu     0.18000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00054\n",
      "epoch       1.126 | loss_total     0.93321 | train_MAE     0.87524 | valid_MAE     0.89014 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00104 | grad_wrt_c_per_item     0.00054\n",
      "epoch       1.250 | loss_total     0.94531 | train_MAE     0.87237 | valid_MAE     0.88622 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00056\n",
      "epoch       1.376 | loss_total     0.83995 | train_MAE     0.86994 | valid_MAE     0.88386 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00055\n",
      "epoch       1.500 | loss_total     0.82754 | train_MAE     0.86762 | valid_MAE     0.88193 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00104 | grad_wrt_c_per_item     0.00057\n",
      "epoch       1.626 | loss_total     0.91519 | train_MAE     0.86547 | valid_MAE     0.87979 | grad_wrt_mu     0.16000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00052\n",
      "epoch       1.750 | loss_total     0.76072 | train_MAE     0.86329 | valid_MAE     0.87758 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00056\n",
      "epoch       1.876 | loss_total     0.88367 | train_MAE     0.86117 | valid_MAE     0.87532 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00054\n",
      "epoch       2.000 | loss_total     0.86584 | train_MAE     0.85929 | valid_MAE     0.87363 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00057\n",
      "epoch       2.500 | loss_total     0.86024 | train_MAE     0.85322 | valid_MAE     0.86789 | grad_wrt_mu     0.36000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00056\n",
      "epoch       3.000 | loss_total     0.85220 | train_MAE     0.84359 | valid_MAE     0.85706 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00055\n",
      "epoch       3.500 | loss_total     0.84631 | train_MAE     0.83685 | valid_MAE     0.85124 | grad_wrt_mu     0.18000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00055\n",
      "epoch       4.000 | loss_total     0.83781 | train_MAE     0.82991 | valid_MAE     0.84347 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00056\n",
      "epoch       4.500 | loss_total     0.83361 | train_MAE     0.82309 | valid_MAE     0.83672 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00104 | grad_wrt_c_per_item     0.00055\n",
      "epoch       5.000 | loss_total     0.82414 | train_MAE     0.81642 | valid_MAE     0.83060 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00051\n",
      "epoch       5.500 | loss_total     0.81371 | train_MAE     0.81014 | valid_MAE     0.82451 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00056\n",
      "epoch       6.000 | loss_total     0.81146 | train_MAE     0.80533 | valid_MAE     0.81854 | grad_wrt_mu     0.14000 | grad_wrt_b_per_user     0.00091 | grad_wrt_c_per_item     0.00055\n",
      "epoch       6.500 | loss_total     0.80666 | train_MAE     0.79927 | valid_MAE     0.81372 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00056\n",
      "epoch       7.000 | loss_total     0.80046 | train_MAE     0.79447 | valid_MAE     0.80915 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00091 | grad_wrt_c_per_item     0.00057\n",
      "epoch       7.500 | loss_total     0.79694 | train_MAE     0.78988 | valid_MAE     0.80438 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00054\n",
      "epoch       8.000 | loss_total     0.79140 | train_MAE     0.78595 | valid_MAE     0.80073 | grad_wrt_mu     0.16000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00054\n",
      "epoch       9.000 | loss_total     0.78336 | train_MAE     0.77878 | valid_MAE     0.79415 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00091 | grad_wrt_c_per_item     0.00054\n",
      "epoch      10.000 | loss_total     0.77667 | train_MAE     0.77269 | valid_MAE     0.78859 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00054\n",
      "epoch      11.000 | loss_total     0.77164 | train_MAE     0.76782 | valid_MAE     0.78408 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00087 | grad_wrt_c_per_item     0.00056\n",
      "epoch      12.000 | loss_total     0.76689 | train_MAE     0.76368 | valid_MAE     0.78045 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00055\n",
      "epoch      13.000 | loss_total     0.76312 | train_MAE     0.76036 | valid_MAE     0.77696 | grad_wrt_mu     0.16000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00054\n",
      "epoch      14.000 | loss_total     0.75957 | train_MAE     0.75687 | valid_MAE     0.77459 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00055\n",
      "epoch      15.000 | loss_total     0.75660 | train_MAE     0.75508 | valid_MAE     0.77404 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00051\n",
      "epoch      16.000 | loss_total     0.75397 | train_MAE     0.75151 | valid_MAE     0.77023 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00052\n",
      "epoch      17.000 | loss_total     0.75166 | train_MAE     0.74919 | valid_MAE     0.76824 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00058\n",
      "epoch      18.000 | loss_total     0.74941 | train_MAE     0.74743 | valid_MAE     0.76727 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00057\n",
      "epoch      19.000 | loss_total     0.74747 | train_MAE     0.74518 | valid_MAE     0.76483 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00050\n",
      "epoch      20.000 | loss_total     0.74552 | train_MAE     0.74341 | valid_MAE     0.76341 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00058\n",
      "epoch      21.000 | loss_total     0.74358 | train_MAE     0.74177 | valid_MAE     0.76217 | grad_wrt_mu     0.16000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      22.000 | loss_total     0.74251 | train_MAE     0.74029 | valid_MAE     0.76089 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00057\n",
      "epoch      23.000 | loss_total     0.74067 | train_MAE     0.74000 | valid_MAE     0.76193 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00056\n",
      "epoch      24.000 | loss_total     0.73928 | train_MAE     0.73972 | valid_MAE     0.76212 | grad_wrt_mu     0.18000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00056\n",
      "epoch      25.000 | loss_total     0.73805 | train_MAE     0.73624 | valid_MAE     0.75813 | grad_wrt_mu     0.14000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00058\n",
      "epoch      26.000 | loss_total     0.73692 | train_MAE     0.73524 | valid_MAE     0.75779 | grad_wrt_mu     0.14000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00057\n",
      "epoch      27.000 | loss_total     0.73568 | train_MAE     0.73415 | valid_MAE     0.75707 | grad_wrt_mu     0.14000 | grad_wrt_b_per_user     0.00091 | grad_wrt_c_per_item     0.00054\n",
      "epoch      28.000 | loss_total     0.73465 | train_MAE     0.73303 | valid_MAE     0.75614 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00056\n",
      "epoch      29.000 | loss_total     0.73365 | train_MAE     0.73204 | valid_MAE     0.75539 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00052\n",
      "epoch      30.000 | loss_total     0.73289 | train_MAE     0.73112 | valid_MAE     0.75473 | grad_wrt_mu     0.12000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00057\n",
      "epoch      31.000 | loss_total     0.73190 | train_MAE     0.73067 | valid_MAE     0.75483 | grad_wrt_mu     0.12000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00057\n",
      "epoch      32.000 | loss_total     0.73113 | train_MAE     0.72989 | valid_MAE     0.75433 | grad_wrt_mu     0.14000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00051\n",
      "epoch      34.000 | loss_total     0.72943 | train_MAE     0.72975 | valid_MAE     0.75498 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00056\n",
      "epoch      36.000 | loss_total     0.72821 | train_MAE     0.72683 | valid_MAE     0.75216 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00054\n",
      "epoch      38.000 | loss_total     0.72687 | train_MAE     0.72545 | valid_MAE     0.75058 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00056\n",
      "epoch      40.000 | loss_total     0.72570 | train_MAE     0.72460 | valid_MAE     0.74970 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00059\n",
      "epoch      42.000 | loss_total     0.72468 | train_MAE     0.72328 | valid_MAE     0.74962 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00052\n",
      "epoch      44.000 | loss_total     0.72351 | train_MAE     0.72228 | valid_MAE     0.74898 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00050\n",
      "epoch      46.000 | loss_total     0.72276 | train_MAE     0.72261 | valid_MAE     0.74782 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00055\n",
      "epoch      48.000 | loss_total     0.72209 | train_MAE     0.72068 | valid_MAE     0.74806 | grad_wrt_mu     0.00000 | grad_wrt_b_per_user     0.00104 | grad_wrt_c_per_item     0.00054\n",
      "epoch      50.000 | loss_total     0.72087 | train_MAE     0.71987 | valid_MAE     0.74750 | grad_wrt_mu     0.18000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00054\n",
      "epoch      52.000 | loss_total     0.72023 | train_MAE     0.71957 | valid_MAE     0.74611 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00056\n",
      "epoch      54.000 | loss_total     0.71940 | train_MAE     0.71833 | valid_MAE     0.74633 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00089 | grad_wrt_c_per_item     0.00056\n",
      "epoch      56.000 | loss_total     0.71883 | train_MAE     0.71812 | valid_MAE     0.74515 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00054\n",
      "epoch      58.000 | loss_total     0.71838 | train_MAE     0.71685 | valid_MAE     0.74500 | grad_wrt_mu     0.00000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00055\n",
      "epoch      60.000 | loss_total     0.71764 | train_MAE     0.71725 | valid_MAE     0.74435 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00057\n",
      "epoch      62.000 | loss_total     0.71703 | train_MAE     0.71588 | valid_MAE     0.74388 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00055\n",
      "epoch      64.000 | loss_total     0.71672 | train_MAE     0.71520 | valid_MAE     0.74376 | grad_wrt_mu     0.22000 | grad_wrt_b_per_user     0.00089 | grad_wrt_c_per_item     0.00056\n",
      "epoch      66.000 | loss_total     0.71610 | train_MAE     0.71474 | valid_MAE     0.74323 | grad_wrt_mu     0.18000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00056\n",
      "epoch      68.000 | loss_total     0.71564 | train_MAE     0.71424 | valid_MAE     0.74304 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00056\n",
      "epoch      70.000 | loss_total     0.71541 | train_MAE     0.71436 | valid_MAE     0.74242 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00057\n",
      "epoch      72.000 | loss_total     0.71489 | train_MAE     0.71341 | valid_MAE     0.74231 | grad_wrt_mu     0.08000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00055\n",
      "epoch      74.000 | loss_total     0.71436 | train_MAE     0.71305 | valid_MAE     0.74234 | grad_wrt_mu     0.00000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00054\n",
      "epoch      76.000 | loss_total     0.71401 | train_MAE     0.71280 | valid_MAE     0.74229 | grad_wrt_mu     0.00000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00052\n",
      "epoch      78.000 | loss_total     0.71342 | train_MAE     0.71235 | valid_MAE     0.74173 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00055\n",
      "epoch      80.000 | loss_total     0.71329 | train_MAE     0.71198 | valid_MAE     0.74120 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00055\n",
      "epoch      82.000 | loss_total     0.71316 | train_MAE     0.71258 | valid_MAE     0.74244 | grad_wrt_mu     0.22000 | grad_wrt_b_per_user     0.00093 | grad_wrt_c_per_item     0.00056\n",
      "epoch      84.000 | loss_total     0.71282 | train_MAE     0.71139 | valid_MAE     0.74067 | grad_wrt_mu     0.18000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00056\n",
      "epoch      86.000 | loss_total     0.71253 | train_MAE     0.71129 | valid_MAE     0.74106 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00098 | grad_wrt_c_per_item     0.00054\n",
      "epoch      88.000 | loss_total     0.71192 | train_MAE     0.71197 | valid_MAE     0.74202 | grad_wrt_mu     0.20000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00054\n",
      "epoch      90.000 | loss_total     0.71185 | train_MAE     0.71061 | valid_MAE     0.73998 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00100 | grad_wrt_c_per_item     0.00059\n",
      "epoch      92.000 | loss_total     0.71146 | train_MAE     0.71031 | valid_MAE     0.73995 | grad_wrt_mu     0.14000 | grad_wrt_b_per_user     0.00089 | grad_wrt_c_per_item     0.00059\n",
      "epoch      94.000 | loss_total     0.71147 | train_MAE     0.71165 | valid_MAE     0.73967 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00056\n",
      "epoch      96.000 | loss_total     0.71117 | train_MAE     0.71047 | valid_MAE     0.73933 | grad_wrt_mu     0.14000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00052\n",
      "epoch      98.000 | loss_total     0.71076 | train_MAE     0.71018 | valid_MAE     0.73918 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00057\n",
      "epoch      99.999 | loss_total     0.71066 | train_MAE     0.70953 | valid_MAE     0.73977 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00102 | grad_wrt_c_per_item     0.00054\n",
      "epoch       0.000 | loss_total     3.53820 | train_MAE     3.53059 | valid_MAE     3.50620 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       0.143 | loss_total     3.40823 | train_MAE     3.43021 | valid_MAE     3.40583 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       0.286 | loss_total     3.32036 | train_MAE     3.32984 | valid_MAE     3.30546 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       0.429 | loss_total     3.23809 | train_MAE     3.22947 | valid_MAE     3.20509 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       0.571 | loss_total     3.13593 | train_MAE     3.12910 | valid_MAE     3.10472 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       0.714 | loss_total     3.02936 | train_MAE     3.02873 | valid_MAE     3.00435 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       0.857 | loss_total     2.93619 | train_MAE     2.92836 | valid_MAE     2.90399 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       1.000 | loss_total     2.82688 | train_MAE     2.82799 | valid_MAE     2.80362 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       1.143 | loss_total     2.71554 | train_MAE     2.72761 | valid_MAE     2.70324 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       1.286 | loss_total     2.63855 | train_MAE     2.62724 | valid_MAE     2.60287 | grad_wrt_mu     1.00000 | grad_wrt_b_per_user     0.00106 | grad_wrt_c_per_item     0.00059\n",
      "epoch       1.429 | loss_total     2.52175 | train_MAE     2.52732 | valid_MAE     2.50296 | grad_wrt_mu     0.87700 | grad_wrt_b_per_user     0.00094 | grad_wrt_c_per_item     0.00053\n",
      "epoch       1.571 | loss_total     2.45567 | train_MAE     2.45008 | valid_MAE     2.42582 | grad_wrt_mu     0.87340 | grad_wrt_b_per_user     0.00094 | grad_wrt_c_per_item     0.00053\n",
      "epoch       1.714 | loss_total     2.36753 | train_MAE     2.37316 | valid_MAE     2.34899 | grad_wrt_mu     0.87540 | grad_wrt_b_per_user     0.00094 | grad_wrt_c_per_item     0.00053\n",
      "epoch       1.857 | loss_total     2.30516 | train_MAE     2.29606 | valid_MAE     2.27199 | grad_wrt_mu     0.87420 | grad_wrt_b_per_user     0.00094 | grad_wrt_c_per_item     0.00053\n",
      "epoch       2.000 | loss_total     2.20885 | train_MAE     2.21907 | valid_MAE     2.19510 | grad_wrt_mu     0.88080 | grad_wrt_b_per_user     0.00095 | grad_wrt_c_per_item     0.00053\n",
      "epoch       2.571 | loss_total     2.14336 | train_MAE     1.90965 | valid_MAE     1.88608 | grad_wrt_mu     0.87560 | grad_wrt_b_per_user     0.00094 | grad_wrt_c_per_item     0.00053\n",
      "epoch       3.000 | loss_total     1.91270 | train_MAE     1.67821 | valid_MAE     1.65493 | grad_wrt_mu     0.87580 | grad_wrt_b_per_user     0.00094 | grad_wrt_c_per_item     0.00053\n",
      "epoch       3.571 | loss_total     1.63870 | train_MAE     1.48694 | valid_MAE     1.46606 | grad_wrt_mu     0.64020 | grad_wrt_b_per_user     0.00072 | grad_wrt_c_per_item     0.00042\n",
      "epoch       4.000 | loss_total     1.48512 | train_MAE     1.35970 | valid_MAE     1.34065 | grad_wrt_mu     0.64500 | grad_wrt_b_per_user     0.00072 | grad_wrt_c_per_item     0.00042\n",
      "epoch       4.571 | loss_total     1.31576 | train_MAE     1.19011 | valid_MAE     1.17349 | grad_wrt_mu     0.65960 | grad_wrt_b_per_user     0.00074 | grad_wrt_c_per_item     0.00043\n",
      "epoch       5.000 | loss_total     1.19059 | train_MAE     1.06199 | valid_MAE     1.04721 | grad_wrt_mu     0.65600 | grad_wrt_b_per_user     0.00073 | grad_wrt_c_per_item     0.00042\n",
      "epoch       5.571 | loss_total     1.04543 | train_MAE     0.99509 | valid_MAE     0.98287 | grad_wrt_mu     0.11860 | grad_wrt_b_per_user     0.00039 | grad_wrt_c_per_item     0.00025\n",
      "epoch       6.000 | loss_total     0.99940 | train_MAE     0.99132 | valid_MAE     0.98007 | grad_wrt_mu     0.11540 | grad_wrt_b_per_user     0.00039 | grad_wrt_c_per_item     0.00026\n",
      "epoch       6.571 | loss_total     0.99164 | train_MAE     0.98613 | valid_MAE     0.97620 | grad_wrt_mu     0.11340 | grad_wrt_b_per_user     0.00038 | grad_wrt_c_per_item     0.00025\n",
      "epoch       7.000 | loss_total     0.98474 | train_MAE     0.98252 | valid_MAE     0.97350 | grad_wrt_mu     0.10040 | grad_wrt_b_per_user     0.00039 | grad_wrt_c_per_item     0.00025\n",
      "epoch       7.571 | loss_total     0.98152 | train_MAE     0.97748 | valid_MAE     0.96975 | grad_wrt_mu     0.10280 | grad_wrt_b_per_user     0.00038 | grad_wrt_c_per_item     0.00025\n",
      "epoch       8.000 | loss_total     0.97706 | train_MAE     0.97371 | valid_MAE     0.96694 | grad_wrt_mu     0.10120 | grad_wrt_b_per_user     0.00040 | grad_wrt_c_per_item     0.00024\n",
      "epoch       9.000 | loss_total     0.96783 | train_MAE     0.96491 | valid_MAE     0.96038 | grad_wrt_mu     0.10440 | grad_wrt_b_per_user     0.00038 | grad_wrt_c_per_item     0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      10.000 | loss_total     0.96143 | train_MAE     0.95610 | valid_MAE     0.95382 | grad_wrt_mu     0.11480 | grad_wrt_b_per_user     0.00038 | grad_wrt_c_per_item     0.00025\n",
      "epoch      11.000 | loss_total     0.95196 | train_MAE     0.94730 | valid_MAE     0.94725 | grad_wrt_mu     0.12580 | grad_wrt_b_per_user     0.00039 | grad_wrt_c_per_item     0.00025\n",
      "epoch      12.000 | loss_total     0.94035 | train_MAE     0.93850 | valid_MAE     0.94069 | grad_wrt_mu     0.11940 | grad_wrt_b_per_user     0.00038 | grad_wrt_c_per_item     0.00025\n",
      "epoch      13.000 | loss_total     0.93336 | train_MAE     0.92969 | valid_MAE     0.93413 | grad_wrt_mu     0.12460 | grad_wrt_b_per_user     0.00039 | grad_wrt_c_per_item     0.00026\n",
      "epoch      14.000 | loss_total     0.92700 | train_MAE     0.92089 | valid_MAE     0.92756 | grad_wrt_mu     0.10860 | grad_wrt_b_per_user     0.00037 | grad_wrt_c_per_item     0.00026\n",
      "epoch      15.000 | loss_total     0.91354 | train_MAE     0.91208 | valid_MAE     0.92100 | grad_wrt_mu     0.10900 | grad_wrt_b_per_user     0.00038 | grad_wrt_c_per_item     0.00025\n",
      "epoch      16.000 | loss_total     0.90715 | train_MAE     0.90328 | valid_MAE     0.91444 | grad_wrt_mu     0.11860 | grad_wrt_b_per_user     0.00038 | grad_wrt_c_per_item     0.00024\n",
      "epoch      17.000 | loss_total     0.90131 | train_MAE     0.89447 | valid_MAE     0.90788 | grad_wrt_mu     0.09220 | grad_wrt_b_per_user     0.00037 | grad_wrt_c_per_item     0.00025\n",
      "epoch      18.000 | loss_total     0.88713 | train_MAE     0.89008 | valid_MAE     0.90478 | grad_wrt_mu     0.01120 | grad_wrt_b_per_user     0.00034 | grad_wrt_c_per_item     0.00021\n",
      "epoch      19.000 | loss_total     0.89101 | train_MAE     0.88987 | valid_MAE     0.90455 | grad_wrt_mu     0.00060 | grad_wrt_b_per_user     0.00033 | grad_wrt_c_per_item     0.00022\n",
      "epoch      20.000 | loss_total     0.89034 | train_MAE     0.88966 | valid_MAE     0.90435 | grad_wrt_mu     0.01140 | grad_wrt_b_per_user     0.00034 | grad_wrt_c_per_item     0.00021\n",
      "epoch      21.000 | loss_total     0.89058 | train_MAE     0.88948 | valid_MAE     0.90425 | grad_wrt_mu     0.02960 | grad_wrt_b_per_user     0.00032 | grad_wrt_c_per_item     0.00020\n",
      "epoch      22.000 | loss_total     0.88790 | train_MAE     0.88928 | valid_MAE     0.90404 | grad_wrt_mu     0.02580 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      23.000 | loss_total     0.89093 | train_MAE     0.88908 | valid_MAE     0.90383 | grad_wrt_mu     0.01660 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      24.000 | loss_total     0.88898 | train_MAE     0.88889 | valid_MAE     0.90365 | grad_wrt_mu     0.02240 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      25.000 | loss_total     0.88851 | train_MAE     0.88870 | valid_MAE     0.90344 | grad_wrt_mu     0.01940 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      26.000 | loss_total     0.88835 | train_MAE     0.88853 | valid_MAE     0.90322 | grad_wrt_mu     0.02100 | grad_wrt_b_per_user     0.00032 | grad_wrt_c_per_item     0.00021\n",
      "epoch      27.000 | loss_total     0.88682 | train_MAE     0.88835 | valid_MAE     0.90312 | grad_wrt_mu     0.01220 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00019\n",
      "epoch      28.000 | loss_total     0.88810 | train_MAE     0.88817 | valid_MAE     0.90291 | grad_wrt_mu     0.01260 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00018\n",
      "epoch      29.000 | loss_total     0.88891 | train_MAE     0.88799 | valid_MAE     0.90274 | grad_wrt_mu     0.01080 | grad_wrt_b_per_user     0.00032 | grad_wrt_c_per_item     0.00020\n",
      "epoch      30.000 | loss_total     0.88729 | train_MAE     0.88781 | valid_MAE     0.90253 | grad_wrt_mu     0.00580 | grad_wrt_b_per_user     0.00034 | grad_wrt_c_per_item     0.00020\n",
      "epoch      31.000 | loss_total     0.88861 | train_MAE     0.88764 | valid_MAE     0.90237 | grad_wrt_mu     0.01120 | grad_wrt_b_per_user     0.00033 | grad_wrt_c_per_item     0.00019\n",
      "epoch      32.000 | loss_total     0.88731 | train_MAE     0.88747 | valid_MAE     0.90222 | grad_wrt_mu     0.01340 | grad_wrt_b_per_user     0.00032 | grad_wrt_c_per_item     0.00019\n",
      "epoch      34.000 | loss_total     0.88452 | train_MAE     0.88713 | valid_MAE     0.90189 | grad_wrt_mu     0.01580 | grad_wrt_b_per_user     0.00032 | grad_wrt_c_per_item     0.00019\n",
      "epoch      36.000 | loss_total     0.88666 | train_MAE     0.88680 | valid_MAE     0.90156 | grad_wrt_mu     0.02040 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00019\n",
      "epoch      38.000 | loss_total     0.88537 | train_MAE     0.88646 | valid_MAE     0.90113 | grad_wrt_mu     0.01560 | grad_wrt_b_per_user     0.00032 | grad_wrt_c_per_item     0.00021\n",
      "epoch      40.000 | loss_total     0.88691 | train_MAE     0.88614 | valid_MAE     0.90092 | grad_wrt_mu     0.03420 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00018\n",
      "epoch      42.000 | loss_total     0.88716 | train_MAE     0.88577 | valid_MAE     0.90046 | grad_wrt_mu     0.00280 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00019\n",
      "epoch      44.000 | loss_total     0.88297 | train_MAE     0.88544 | valid_MAE     0.90017 | grad_wrt_mu     0.01540 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      46.000 | loss_total     0.88461 | train_MAE     0.88510 | valid_MAE     0.89977 | grad_wrt_mu     0.01500 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      48.000 | loss_total     0.88706 | train_MAE     0.88476 | valid_MAE     0.89944 | grad_wrt_mu     0.01040 | grad_wrt_b_per_user     0.00034 | grad_wrt_c_per_item     0.00020\n",
      "epoch      50.000 | loss_total     0.88550 | train_MAE     0.88443 | valid_MAE     0.89913 | grad_wrt_mu     0.00980 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00019\n",
      "epoch      52.000 | loss_total     0.88357 | train_MAE     0.88409 | valid_MAE     0.89879 | grad_wrt_mu     0.01220 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00020\n",
      "epoch      54.000 | loss_total     0.88260 | train_MAE     0.88376 | valid_MAE     0.89846 | grad_wrt_mu     0.00760 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00018\n",
      "epoch      56.000 | loss_total     0.88290 | train_MAE     0.88343 | valid_MAE     0.89813 | grad_wrt_mu     0.00440 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00019\n",
      "epoch      58.000 | loss_total     0.88241 | train_MAE     0.88310 | valid_MAE     0.89775 | grad_wrt_mu     0.00600 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00020\n",
      "epoch      60.000 | loss_total     0.88155 | train_MAE     0.88276 | valid_MAE     0.89742 | grad_wrt_mu     0.00780 | grad_wrt_b_per_user     0.00029 | grad_wrt_c_per_item     0.00019\n",
      "epoch      62.000 | loss_total     0.88092 | train_MAE     0.88244 | valid_MAE     0.89712 | grad_wrt_mu     0.00200 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00019\n",
      "epoch      64.000 | loss_total     0.88198 | train_MAE     0.88210 | valid_MAE     0.89676 | grad_wrt_mu     0.00220 | grad_wrt_b_per_user     0.00029 | grad_wrt_c_per_item     0.00020\n",
      "epoch      66.000 | loss_total     0.88229 | train_MAE     0.88178 | valid_MAE     0.89639 | grad_wrt_mu     0.00340 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00019\n",
      "epoch      68.000 | loss_total     0.88069 | train_MAE     0.88145 | valid_MAE     0.89613 | grad_wrt_mu     0.00180 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00019\n",
      "epoch      70.000 | loss_total     0.88195 | train_MAE     0.88113 | valid_MAE     0.89571 | grad_wrt_mu     0.01360 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00021\n",
      "epoch      72.000 | loss_total     0.88225 | train_MAE     0.88078 | valid_MAE     0.89540 | grad_wrt_mu     0.00320 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00020\n",
      "epoch      74.000 | loss_total     0.88054 | train_MAE     0.88045 | valid_MAE     0.89507 | grad_wrt_mu     0.00220 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      76.000 | loss_total     0.88051 | train_MAE     0.88012 | valid_MAE     0.89476 | grad_wrt_mu     0.00900 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      78.000 | loss_total     0.88210 | train_MAE     0.87979 | valid_MAE     0.89441 | grad_wrt_mu     0.02340 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00020\n",
      "epoch      80.000 | loss_total     0.87863 | train_MAE     0.87946 | valid_MAE     0.89407 | grad_wrt_mu     0.00800 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00019\n",
      "epoch      82.000 | loss_total     0.88238 | train_MAE     0.87914 | valid_MAE     0.89371 | grad_wrt_mu     0.00340 | grad_wrt_b_per_user     0.00029 | grad_wrt_c_per_item     0.00019\n",
      "epoch      84.000 | loss_total     0.88149 | train_MAE     0.87880 | valid_MAE     0.89343 | grad_wrt_mu     0.01920 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      86.000 | loss_total     0.87915 | train_MAE     0.87848 | valid_MAE     0.89304 | grad_wrt_mu     0.01780 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00021\n",
      "epoch      88.000 | loss_total     0.87741 | train_MAE     0.87816 | valid_MAE     0.89281 | grad_wrt_mu     0.02140 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00019\n",
      "epoch      90.000 | loss_total     0.87996 | train_MAE     0.87781 | valid_MAE     0.89238 | grad_wrt_mu     0.01100 | grad_wrt_b_per_user     0.00030 | grad_wrt_c_per_item     0.00020\n",
      "epoch      92.000 | loss_total     0.87854 | train_MAE     0.87749 | valid_MAE     0.89203 | grad_wrt_mu     0.00160 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      94.000 | loss_total     0.87850 | train_MAE     0.87715 | valid_MAE     0.89173 | grad_wrt_mu     0.00420 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      96.000 | loss_total     0.87753 | train_MAE     0.87683 | valid_MAE     0.89138 | grad_wrt_mu     0.00260 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      98.000 | loss_total     0.87672 | train_MAE     0.87650 | valid_MAE     0.89104 | grad_wrt_mu     0.00140 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n",
      "epoch      99.857 | loss_total     0.87627 | train_MAE     0.87619 | valid_MAE     0.89074 | grad_wrt_mu     0.00180 | grad_wrt_b_per_user     0.00031 | grad_wrt_c_per_item     0.00020\n"
     ]
    }
   ],
   "source": [
    "# M2\n",
    "SEED = 101\n",
    "M2_100_abs = CollabFilterOneScalarPerItem(batch_size=100, random_state=SEED)\n",
    "M2_10000_abs = CollabFilterOneScalarPerItem(batch_size=10000, random_state=SEED)\n",
    "\n",
    "M2_100_abs.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M2_100_abs.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)\n",
    "\n",
    "M2_10000_abs.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M2_10000_abs.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8907148360000002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation 10000 abs\n",
    "ratigs_hat_va_M2_10000_abs = M2_10000_abs.predict(valid_tuple[0], valid_tuple[1])\n",
    "metrics.mean_absolute_error(valid_tuple[2], ratigs_hat_va_M2_10000_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8744634207365892"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 10000 abs\n",
    "ratigs_hat_te_M2_10000_abs = M2_10000_abs.predict(test_tuple[0], test_tuple[1])\n",
    "metrics.mean_absolute_error(test_tuple[2], ratigs_hat_te_M2_10000_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396861999999975"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation 100 abs\n",
    "ratigs_hat_va_M2_100_abs = M2_100_abs.predict(valid_tuple[0], valid_tuple[1])\n",
    "metrics.mean_absolute_error(valid_tuple[2], ratigs_hat_va_M2_100_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74579223378703"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 100 abs\n",
    "ratigs_hat_te_M2_100_abs = M2_100_abs.predict(test_tuple[0], test_tuple[1])\n",
    "metrics.mean_absolute_error(test_tuple[2], ratigs_hat_te_M2_100_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 2)\n",
      "(1682, 2)\n",
      "epoch       0.000 | loss_total     0.96800 | train_MAE     1.00261 | valid_MAE     0.98860 | grad_wrt_mu     0.35200 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00044 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.014 | loss_total     0.96272 | train_MAE     0.99478 | valid_MAE     0.98281 | grad_wrt_mu     0.11600 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00043 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.029 | loss_total     1.00199 | train_MAE     0.99212 | valid_MAE     0.98083 | grad_wrt_mu     0.09400 | grad_wrt_b_per_user     0.00069 | grad_wrt_c_per_item     0.00042 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.043 | loss_total     0.97818 | train_MAE     0.98994 | valid_MAE     0.97920 | grad_wrt_mu     0.05800 | grad_wrt_b_per_user     0.00068 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.129 | loss_total     0.98157 | train_MAE     0.97490 | valid_MAE     0.96800 | grad_wrt_mu     0.13800 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.257 | loss_total     0.94058 | train_MAE     0.95148 | valid_MAE     0.95056 | grad_wrt_mu     0.14000 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.386 | loss_total     0.93746 | train_MAE     0.93080 | valid_MAE     0.93510 | grad_wrt_mu     0.14600 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00042 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.500 | loss_total     0.90609 | train_MAE     0.91055 | valid_MAE     0.92000 | grad_wrt_mu     0.12000 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.629 | loss_total     0.93094 | train_MAE     0.89047 | valid_MAE     0.90510 | grad_wrt_mu     0.04400 | grad_wrt_b_per_user     0.00068 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.757 | loss_total     0.87090 | train_MAE     0.89149 | valid_MAE     0.90565 | grad_wrt_mu     0.14400 | grad_wrt_b_per_user     0.00067 | grad_wrt_c_per_item     0.00042 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.886 | loss_total     0.89757 | train_MAE     0.89033 | valid_MAE     0.90468 | grad_wrt_mu     0.07000 | grad_wrt_b_per_user     0.00068 | grad_wrt_c_per_item     0.00042 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.000 | loss_total     0.94955 | train_MAE     0.89378 | valid_MAE     0.90705 | grad_wrt_mu     0.03800 | grad_wrt_b_per_user     0.00069 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.129 | loss_total     0.87482 | train_MAE     0.88932 | valid_MAE     0.90425 | grad_wrt_mu     0.16800 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.257 | loss_total     0.89296 | train_MAE     0.88812 | valid_MAE     0.90284 | grad_wrt_mu     0.00600 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.386 | loss_total     0.88953 | train_MAE     0.88770 | valid_MAE     0.90233 | grad_wrt_mu     0.06600 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.500 | loss_total     0.89107 | train_MAE     0.88772 | valid_MAE     0.90214 | grad_wrt_mu     0.10800 | grad_wrt_b_per_user     0.00068 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.629 | loss_total     0.90317 | train_MAE     0.88701 | valid_MAE     0.90186 | grad_wrt_mu     0.06800 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.757 | loss_total     0.91062 | train_MAE     0.88819 | valid_MAE     0.90216 | grad_wrt_mu     0.09400 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.886 | loss_total     0.90099 | train_MAE     0.88589 | valid_MAE     0.90058 | grad_wrt_mu     0.00600 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.000 | loss_total     0.90591 | train_MAE     0.88556 | valid_MAE     0.90030 | grad_wrt_mu     0.02400 | grad_wrt_b_per_user     0.00068 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.500 | loss_total     0.88368 | train_MAE     0.88388 | valid_MAE     0.89857 | grad_wrt_mu     0.04400 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.000 | loss_total     0.88360 | train_MAE     0.88219 | valid_MAE     0.89684 | grad_wrt_mu     0.04400 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.500 | loss_total     0.88425 | train_MAE     0.88050 | valid_MAE     0.89497 | grad_wrt_mu     0.05800 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.000 | loss_total     0.88137 | train_MAE     0.87894 | valid_MAE     0.89328 | grad_wrt_mu     0.02800 | grad_wrt_b_per_user     0.00068 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.500 | loss_total     0.87773 | train_MAE     0.87720 | valid_MAE     0.89168 | grad_wrt_mu     0.02200 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.000 | loss_total     0.87731 | train_MAE     0.87615 | valid_MAE     0.89092 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.500 | loss_total     0.87514 | train_MAE     0.87424 | valid_MAE     0.88827 | grad_wrt_mu     0.05600 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.000 | loss_total     0.87402 | train_MAE     0.87222 | valid_MAE     0.88658 | grad_wrt_mu     0.02800 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.500 | loss_total     0.87178 | train_MAE     0.87068 | valid_MAE     0.88521 | grad_wrt_mu     0.03800 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.000 | loss_total     0.87117 | train_MAE     0.86892 | valid_MAE     0.88327 | grad_wrt_mu     0.01400 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.500 | loss_total     0.87139 | train_MAE     0.86732 | valid_MAE     0.88168 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       8.000 | loss_total     0.86685 | train_MAE     0.86572 | valid_MAE     0.87981 | grad_wrt_mu     0.05200 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       9.000 | loss_total     0.86460 | train_MAE     0.86259 | valid_MAE     0.87646 | grad_wrt_mu     0.05200 | grad_wrt_b_per_user     0.00069 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      10.000 | loss_total     0.86125 | train_MAE     0.85925 | valid_MAE     0.87309 | grad_wrt_mu     0.00400 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      11.000 | loss_total     0.85758 | train_MAE     0.85575 | valid_MAE     0.86986 | grad_wrt_mu     0.01800 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      12.000 | loss_total     0.85417 | train_MAE     0.85248 | valid_MAE     0.86660 | grad_wrt_mu     0.01600 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      13.000 | loss_total     0.85151 | train_MAE     0.84934 | valid_MAE     0.86352 | grad_wrt_mu     0.05200 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      14.000 | loss_total     0.84771 | train_MAE     0.84629 | valid_MAE     0.86051 | grad_wrt_mu     0.00400 | grad_wrt_b_per_user     0.00067 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      15.000 | loss_total     0.84521 | train_MAE     0.84346 | valid_MAE     0.85730 | grad_wrt_mu     0.00200 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      16.000 | loss_total     0.84175 | train_MAE     0.84064 | valid_MAE     0.85471 | grad_wrt_mu     0.01200 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      17.000 | loss_total     0.84032 | train_MAE     0.83797 | valid_MAE     0.85224 | grad_wrt_mu     0.01600 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      18.000 | loss_total     0.83572 | train_MAE     0.83573 | valid_MAE     0.84923 | grad_wrt_mu     0.04600 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      19.000 | loss_total     0.83483 | train_MAE     0.83258 | valid_MAE     0.84668 | grad_wrt_mu     0.01400 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      20.000 | loss_total     0.83167 | train_MAE     0.83000 | valid_MAE     0.84386 | grad_wrt_mu     0.01200 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      21.000 | loss_total     0.82800 | train_MAE     0.82724 | valid_MAE     0.84150 | grad_wrt_mu     0.01800 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      22.000 | loss_total     0.82628 | train_MAE     0.82462 | valid_MAE     0.83897 | grad_wrt_mu     0.01400 | grad_wrt_b_per_user     0.00067 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      23.000 | loss_total     0.82374 | train_MAE     0.82189 | valid_MAE     0.83597 | grad_wrt_mu     0.04800 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      24.000 | loss_total     0.82039 | train_MAE     0.81934 | valid_MAE     0.83321 | grad_wrt_mu     0.03400 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      25.000 | loss_total     0.81879 | train_MAE     0.81663 | valid_MAE     0.83091 | grad_wrt_mu     0.02400 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      26.000 | loss_total     0.81566 | train_MAE     0.81413 | valid_MAE     0.82820 | grad_wrt_mu     0.03400 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      27.000 | loss_total     0.81332 | train_MAE     0.81161 | valid_MAE     0.82596 | grad_wrt_mu     0.05200 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      28.000 | loss_total     0.80992 | train_MAE     0.80920 | valid_MAE     0.82352 | grad_wrt_mu     0.00400 | grad_wrt_b_per_user     0.00059 | grad_wrt_c_per_item     0.00035 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      29.000 | loss_total     0.80843 | train_MAE     0.80688 | valid_MAE     0.82119 | grad_wrt_mu     0.00000 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      30.000 | loss_total     0.80584 | train_MAE     0.80465 | valid_MAE     0.81888 | grad_wrt_mu     0.02600 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      31.000 | loss_total     0.80447 | train_MAE     0.80252 | valid_MAE     0.81706 | grad_wrt_mu     0.03600 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      32.000 | loss_total     0.80104 | train_MAE     0.80042 | valid_MAE     0.81496 | grad_wrt_mu     0.04600 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      34.000 | loss_total     0.79795 | train_MAE     0.79655 | valid_MAE     0.81118 | grad_wrt_mu     0.02800 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      36.000 | loss_total     0.79428 | train_MAE     0.79290 | valid_MAE     0.80751 | grad_wrt_mu     0.01400 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      38.000 | loss_total     0.79059 | train_MAE     0.78953 | valid_MAE     0.80403 | grad_wrt_mu     0.00600 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      40.000 | loss_total     0.78748 | train_MAE     0.78631 | valid_MAE     0.80133 | grad_wrt_mu     0.00800 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      42.000 | loss_total     0.78410 | train_MAE     0.78329 | valid_MAE     0.79844 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00059 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      44.000 | loss_total     0.78084 | train_MAE     0.78054 | valid_MAE     0.79598 | grad_wrt_mu     0.02400 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      46.000 | loss_total     0.77886 | train_MAE     0.77781 | valid_MAE     0.79332 | grad_wrt_mu     0.00400 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      48.000 | loss_total     0.77618 | train_MAE     0.77540 | valid_MAE     0.79086 | grad_wrt_mu     0.05800 | grad_wrt_b_per_user     0.00059 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      50.000 | loss_total     0.77346 | train_MAE     0.77309 | valid_MAE     0.78893 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      52.000 | loss_total     0.77152 | train_MAE     0.77107 | valid_MAE     0.78726 | grad_wrt_mu     0.03400 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      54.000 | loss_total     0.76995 | train_MAE     0.76913 | valid_MAE     0.78532 | grad_wrt_mu     0.07400 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      56.000 | loss_total     0.76777 | train_MAE     0.76743 | valid_MAE     0.78408 | grad_wrt_mu     0.05000 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      58.000 | loss_total     0.76683 | train_MAE     0.76572 | valid_MAE     0.78214 | grad_wrt_mu     0.00600 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      60.000 | loss_total     0.76543 | train_MAE     0.76426 | valid_MAE     0.78135 | grad_wrt_mu     0.03400 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00035 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      62.000 | loss_total     0.76305 | train_MAE     0.76261 | valid_MAE     0.77966 | grad_wrt_mu     0.05600 | grad_wrt_b_per_user     0.00058 | grad_wrt_c_per_item     0.00035 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      64.000 | loss_total     0.76201 | train_MAE     0.76116 | valid_MAE     0.77831 | grad_wrt_mu     0.01200 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      66.000 | loss_total     0.76059 | train_MAE     0.75979 | valid_MAE     0.77715 | grad_wrt_mu     0.03200 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      68.000 | loss_total     0.75897 | train_MAE     0.75849 | valid_MAE     0.77596 | grad_wrt_mu     0.00400 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      70.000 | loss_total     0.75768 | train_MAE     0.75728 | valid_MAE     0.77480 | grad_wrt_mu     0.01000 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      72.000 | loss_total     0.75656 | train_MAE     0.75608 | valid_MAE     0.77388 | grad_wrt_mu     0.00400 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      74.000 | loss_total     0.75472 | train_MAE     0.75500 | valid_MAE     0.77285 | grad_wrt_mu     0.04400 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      76.000 | loss_total     0.75439 | train_MAE     0.75387 | valid_MAE     0.77210 | grad_wrt_mu     0.05600 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      78.000 | loss_total     0.75363 | train_MAE     0.75288 | valid_MAE     0.77147 | grad_wrt_mu     0.00000 | grad_wrt_b_per_user     0.00058 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      80.000 | loss_total     0.75227 | train_MAE     0.75216 | valid_MAE     0.77019 | grad_wrt_mu     0.06400 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      82.000 | loss_total     0.75183 | train_MAE     0.75104 | valid_MAE     0.76942 | grad_wrt_mu     0.03400 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      84.000 | loss_total     0.75040 | train_MAE     0.75015 | valid_MAE     0.76865 | grad_wrt_mu     0.04400 | grad_wrt_b_per_user     0.00058 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      86.000 | loss_total     0.74876 | train_MAE     0.74910 | valid_MAE     0.76809 | grad_wrt_mu     0.02600 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      88.000 | loss_total     0.74862 | train_MAE     0.74827 | valid_MAE     0.76757 | grad_wrt_mu     0.05400 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      90.000 | loss_total     0.74787 | train_MAE     0.74744 | valid_MAE     0.76665 | grad_wrt_mu     0.05200 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      92.000 | loss_total     0.74722 | train_MAE     0.74667 | valid_MAE     0.76630 | grad_wrt_mu     0.01000 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      94.000 | loss_total     0.74634 | train_MAE     0.74585 | valid_MAE     0.76542 | grad_wrt_mu     0.02400 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      96.000 | loss_total     0.74470 | train_MAE     0.74525 | valid_MAE     0.76464 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      98.000 | loss_total     0.74450 | train_MAE     0.74437 | valid_MAE     0.76430 | grad_wrt_mu     0.02200 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch      99.986 | loss_total     0.74412 | train_MAE     0.74393 | valid_MAE     0.76352 | grad_wrt_mu     0.05600 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n"
     ]
    }
   ],
   "source": [
    "# M3\n",
    "M3_2f_abs = CollabFilterOneVectorPerItem(step_size=0.2, n_epochs=100, batch_size=1000, random_state=SEED, n_factors=2)\n",
    "M3_2f_abs.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M3_2f_abs.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636443979529388"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation M3 abs 2f\n",
    "ratigs_hat_va_M3_abs = M3_2f_abs.predict(valid_tuple[0], valid_tuple[1])\n",
    "metrics.mean_absolute_error(valid_tuple[2], ratigs_hat_va_M3_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7650305599389229"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test M3 abs 2f\n",
    "ratigs_hat_test_M3_2f_abs = M3_2f_abs.predict(test_tuple[0], test_tuple[1])\n",
    "metrics.mean_absolute_error(test_tuple[2], ratigs_hat_test_M3_2f_abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 surprise SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.529480398257623"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import surprise\n",
    "from surprise import SVD\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "reader = Reader(\n",
    "    line_format='user item rating', sep=',',\n",
    "    rating_scale=(1, 5), skip_lines=1)\n",
    "\n",
    "## Load the entire dev set in surprise's format\n",
    "dev_set = surprise.Dataset.load_from_file(\n",
    "    'data_movie_lens_100k/ratings_all_development_set.csv', reader=reader)\n",
    "\n",
    "dev_set_for_fit = dev_set.build_full_trainset()\n",
    "dev_set_for_predict = dev_set_for_fit.build_testset()\n",
    "dev_set_for_fit.global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89992\n",
      "89992\n",
      "70000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(dev_set_for_fit.n_ratings)\n",
    "print(len(dev_set_for_predict))\n",
    "\n",
    "print(len(train_tuple[0]))\n",
    "print(len(valid_tuple[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.trainset.Trainset at 0x7fa2f5cb89d0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set_for_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set_for_fit.rating_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fa2f5bc1310>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVD model, which is like our M3\n",
    "# Only difference from our M3 is that the regularization is applied slightly differently (to the per-item and per-users bias parameters)\n",
    "\n",
    "model = surprise.SVD(n_factors=2, n_epochs=10, lr_all=0.01, random_state=0)\n",
    "model.fit(dev_set_for_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.test(dev_set_for_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ratings = [pred.est for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.7544139699224877,\n",
       " 3.6351699413391376,\n",
       " 2.864122198932828,\n",
       " 3.66237014292207,\n",
       " 2.781590281352215,\n",
       " 3.4909390383839556,\n",
       " 3.28503507316072,\n",
       " 3.447567488743219,\n",
       " 3.676881893677601,\n",
       " 2.6360915836606584,\n",
       " 3.8022331784545,\n",
       " 3.9267406203704662,\n",
       " 3.90545194867554,\n",
       " 3.766371652831956,\n",
       " 3.3826628899657374,\n",
       " 3.544797127778221,\n",
       " 3.1234296829681814,\n",
       " 3.4903961081216575,\n",
       " 1.9097432387266664,\n",
       " 3.3757262969278754,\n",
       " 3.0857097524091284,\n",
       " 2.183946647576814,\n",
       " 2.8360640348598207,\n",
       " 2.6205221483279666,\n",
       " 2.4939416810488444,\n",
       " 3.0131551627401936,\n",
       " 3.9273116791777616,\n",
       " 3.071875409919961,\n",
       " 2.687745312230733,\n",
       " 2.3711908524602303,\n",
       " 2.989109479251282,\n",
       " 3.51585845817975,\n",
       " 3.710110205243731,\n",
       " 3.280051929519022,\n",
       " 3.3679590296998665,\n",
       " 3.582629752444322,\n",
       " 3.1200002561214917,\n",
       " 4.004363110962659,\n",
       " 3.4276708928927864,\n",
       " 4.180628607916344,\n",
       " 3.131040627379854,\n",
       " 3.4628659079550976,\n",
       " 3.6277007930661744,\n",
       " 3.74694695061736,\n",
       " 3.1080343870396128,\n",
       " 3.6607750336267104,\n",
       " 3.5263251162845966,\n",
       " 3.5383030412847476,\n",
       " 3.475641263701675,\n",
       " 3.038754282972734,\n",
       " 3.1276114548625156,\n",
       " 3.8223566199431467,\n",
       " 3.589994904098478,\n",
       " 3.9782703253142,\n",
       " 3.836733982843402,\n",
       " 3.6341396895687885,\n",
       " 3.340517014990731,\n",
       " 2.8626976708682834,\n",
       " 3.3197925124571537,\n",
       " 3.5644355448299514,\n",
       " 3.543037350491065,\n",
       " 3.525105460856227,\n",
       " 3.867856756354157,\n",
       " 3.7543503054662946,\n",
       " 3.5042777513628156,\n",
       " 2.9147694846068832,\n",
       " 3.5676232192639286,\n",
       " 4.228165103911078,\n",
       " 3.036419224116619,\n",
       " 3.810873918740923,\n",
       " 3.3373544537397315,\n",
       " 3.724950749245291,\n",
       " 3.817785118285619,\n",
       " 3.0753966246618467,\n",
       " 3.069923862594064,\n",
       " 3.25520787894429,\n",
       " 2.178781979723477,\n",
       " 3.0962950963857883,\n",
       " 3.4388759238455555,\n",
       " 4.19302666338734,\n",
       " 3.667874236063284,\n",
       " 3.7071107755906687,\n",
       " 2.848647738380186,\n",
       " 3.610664799209616,\n",
       " 3.4558981956343047,\n",
       " 3.419488966761142,\n",
       " 3.309280409054455,\n",
       " 2.85207677539017,\n",
       " 3.5221519757176245,\n",
       " 2.3977420395059656,\n",
       " 3.4978026819335772,\n",
       " 2.4042245110943905,\n",
       " 3.3774678467406134,\n",
       " 2.7093851771491564,\n",
       " 3.577367795787706,\n",
       " 3.6032512596655892,\n",
       " 3.5889090619524664,\n",
       " 2.6475908334090503,\n",
       " 3.488539497606026,\n",
       " 3.400235209735371,\n",
       " 3.3768376159170534,\n",
       " 3.591461172719616,\n",
       " 3.3223029013009877,\n",
       " 3.632179182633553,\n",
       " 3.6295174898494897,\n",
       " 2.780474735745664,\n",
       " 2.752916204780448,\n",
       " 2.6860120901037803,\n",
       " 3.874472584893843,\n",
       " 3.6182419306387614,\n",
       " 2.947047076156393,\n",
       " 3.623222020362585,\n",
       " 4.280070860902743,\n",
       " 2.5222373998896557,\n",
       " 3.1719792064161685,\n",
       " 3.131098695580455,\n",
       " 4.065594929776657,\n",
       " 2.6997682802910483,\n",
       " 2.774307611091494,\n",
       " 2.9611448066911996,\n",
       " 2.7645858154028886,\n",
       " 3.359793735089522,\n",
       " 2.5707781279239215,\n",
       " 3.845019256481856,\n",
       " 3.363832560164426,\n",
       " 3.549197503355146,\n",
       " 2.434460775909691,\n",
       " 3.3881510141117395,\n",
       " 3.8481401189641544,\n",
       " 2.9124217233233107,\n",
       " 3.1334388285515247,\n",
       " 3.3586275338609757,\n",
       " 2.6538340042936923,\n",
       " 2.105187589741242,\n",
       " 3.3472452852994152,\n",
       " 2.9205095499065674,\n",
       " 3.789082936745628,\n",
       " 3.0521329890343205,\n",
       " 3.6461858323037655,\n",
       " 3.273869432628258,\n",
       " 3.2520930072526535,\n",
       " 3.557650990615947,\n",
       " 3.6194562713866034,\n",
       " 3.0781318857921036,\n",
       " 3.1841308877206744,\n",
       " 3.151932941229952,\n",
       " 3.421549947100464,\n",
       " 3.366041749185773,\n",
       " 4.1059857392313015,\n",
       " 4.813380000052596,\n",
       " 4.046480985205102,\n",
       " 4.953405656910257,\n",
       " 3.878946987328771,\n",
       " 4.34435179555126,\n",
       " 4.105170075751243,\n",
       " 4.11553985045634,\n",
       " 5,\n",
       " 3.5956408457065443,\n",
       " 4.2877104947313605,\n",
       " 3.5118903659319947,\n",
       " 3.9549114485897574,\n",
       " 4.628411193460353,\n",
       " 3.724566435125059,\n",
       " 4.063568276722094,\n",
       " 3.3989918055612907,\n",
       " 4.766944777856634,\n",
       " 3.3790334875818275,\n",
       " 2.940779365330883,\n",
       " 3.75699770671541,\n",
       " 3.8889803670186303,\n",
       " 4.2402621199785235,\n",
       " 4.761252858825848,\n",
       " 3.8558785661973216,\n",
       " 4.2873240993033,\n",
       " 3.512439061852319,\n",
       " 3.410136464475024,\n",
       " 4.351005799871181,\n",
       " 4.735738639099124,\n",
       " 4.498014568874006,\n",
       " 4.650172158025803,\n",
       " 4.771372676403305,\n",
       " 4.433142463916008,\n",
       " 5,\n",
       " 4.065460834071927,\n",
       " 4.7861585757559135,\n",
       " 3.5845046837351973,\n",
       " 2.987603139966331,\n",
       " 4.081571051011867,\n",
       " 4.520915523218133,\n",
       " 2.9827866273264507,\n",
       " 4.836282486244576,\n",
       " 3.4997523643582027,\n",
       " 4.887982802059476,\n",
       " 4.621011725230252,\n",
       " 4.36353002824373,\n",
       " 4.78422422669574,\n",
       " 4.348282641031105,\n",
       " 3.426703567619774,\n",
       " 3.3929345872298984,\n",
       " 3.43190040240627,\n",
       " 3.8004691251014107,\n",
       " 4.89514682576358,\n",
       " 4.290860445812213,\n",
       " 4.094201940505293,\n",
       " 4.046810056926326,\n",
       " 4.703014801681854,\n",
       " 3.987447807059764,\n",
       " 3.8697809088369803,\n",
       " 4.7550389584622295,\n",
       " 4.671060231343246,\n",
       " 4.476865103552721,\n",
       " 4.128702877410957,\n",
       " 3.1800502424420944,\n",
       " 3.682500205691453,\n",
       " 4.176347051894715,\n",
       " 4.029479786878969,\n",
       " 4.904600098371828,\n",
       " 4.163489326917492,\n",
       " 4.377013037067209,\n",
       " 3.5291433260750975,\n",
       " 4.689790915607197,\n",
       " 3.839144887173626,\n",
       " 3.8198326697663116,\n",
       " 4.704636563724923,\n",
       " 3.4857719397299785,\n",
       " 4.510162840928856,\n",
       " 3.5514420493771213,\n",
       " 4.8357939541624635,\n",
       " 4.484281346598561,\n",
       " 3.908620704040306,\n",
       " 5,\n",
       " 3.149531499628068,\n",
       " 4.067728180874597,\n",
       " 4.204437932023208,\n",
       " 4.1362939640453025,\n",
       " 3.344307782271022,\n",
       " 4.365887548954541,\n",
       " 3.595382593714294,\n",
       " 4.954593727699095,\n",
       " 4.342437977322079,\n",
       " 5,\n",
       " 4.216281976675117,\n",
       " 3.9671537524865053,\n",
       " 4.741769521472271,\n",
       " 4.365369557435596,\n",
       " 4.825670584455289,\n",
       " 4.757149483223061,\n",
       " 3.9816201044598936,\n",
       " 4.726767568953377,\n",
       " 4.560729950370727,\n",
       " 3.978898442106845,\n",
       " 4.22245817629008,\n",
       " 3.6276262476729517,\n",
       " 3.9087049460578007,\n",
       " 4.8008401607215,\n",
       " 3.6967414462127115,\n",
       " 3.7938754954823795,\n",
       " 5,\n",
       " 4.1939779173124005,\n",
       " 3.833136828489588,\n",
       " 4.87450536937609,\n",
       " 4.099854851607126,\n",
       " 3.9299019767001484,\n",
       " 3.3387755898937286,\n",
       " 4.357987276960731,\n",
       " 3.623732476317252,\n",
       " 4.436052377361568,\n",
       " 3.9797223820587777,\n",
       " 5,\n",
       " 3.896911824676075,\n",
       " 4.453541693648852,\n",
       " 3.967136226637765,\n",
       " 4.709040907455769,\n",
       " 4.652632020987477,\n",
       " 3.639347493891142,\n",
       " 4.322310001468318,\n",
       " 4.702191324449082,\n",
       " 4.328100792768192,\n",
       " 4.343338041966972,\n",
       " 3.9038532479928696,\n",
       " 3.5646230323981913,\n",
       " 3.705245654198817,\n",
       " 4.921524709887353,\n",
       " 3.954929225201192,\n",
       " 3.4829880046530213,\n",
       " 4.498088584803077,\n",
       " 3.7817375367619444,\n",
       " 3.2395369909541243,\n",
       " 3.974889393650867,\n",
       " 4.355064723690154,\n",
       " 4.286818196313209,\n",
       " 3.2285613566745,\n",
       " 3.268481245963331,\n",
       " 3.78315131210036,\n",
       " 3.620084964599882,\n",
       " 4.616982742759661,\n",
       " 3.9438956763885966,\n",
       " 4.200562868598101,\n",
       " 4.683344878319533,\n",
       " 4.248468280288113,\n",
       " 3.054874996820212,\n",
       " 3.6357178432273862,\n",
       " 4.137732811486013,\n",
       " 4.086004470061534,\n",
       " 3.91185341326471,\n",
       " 4.780279556256636,\n",
       " 3.691972094657823,\n",
       " 3.8190860809126197,\n",
       " 5,\n",
       " 4.3308521915604095,\n",
       " 3.701684344183454,\n",
       " 4.402056141349373,\n",
       " 4.450754286124358,\n",
       " 3.9847087085720445,\n",
       " 3.5419897454102993,\n",
       " 4.109287716414436,\n",
       " 4.314591809583396,\n",
       " 4.319669994637918,\n",
       " 4.482996577482,\n",
       " 4.631257208649329,\n",
       " 4.827621236637517,\n",
       " 3.8054927751735597,\n",
       " 3.365097294330855,\n",
       " 3.995302245988661,\n",
       " 4.39596040190339,\n",
       " 4.136594319199509,\n",
       " 5,\n",
       " 5,\n",
       " 4.101283213422157,\n",
       " 3.952976169290554,\n",
       " 4.542718482080836,\n",
       " 4.319843767687103,\n",
       " 4.0200495618695715,\n",
       " 4.284026443196536,\n",
       " 3.9867974198121936,\n",
       " 4.604181275322941,\n",
       " 3.8388377970056613,\n",
       " 3.8256343959162904,\n",
       " 4.683648364463319,\n",
       " 4.582614228876723,\n",
       " 4.633197128649582,\n",
       " 3.4328159532448916,\n",
       " 5,\n",
       " 3.9786706216986243,\n",
       " 4.107732598117083,\n",
       " 3.309417515755281,\n",
       " 4.468497821737734,\n",
       " 3.5008835655577792,\n",
       " 3.301622511794343,\n",
       " 4.236698877972563,\n",
       " 4.545443812405976,\n",
       " 4.725233272194922,\n",
       " 3.764592597702507,\n",
       " 4.553567159763672,\n",
       " 4.092907424327955,\n",
       " 3.2374881828540425,\n",
       " 3.823105206044293,\n",
       " 4.369878816856992,\n",
       " 3.6891676975491894,\n",
       " 4.866138840740202,\n",
       " 4.460209302446597,\n",
       " 4.320026940801959,\n",
       " 4.993232287884359,\n",
       " 4.326114551506916,\n",
       " 4.732277416615818,\n",
       " 4.648826681030494,\n",
       " 4.389979719109982,\n",
       " 3.629651846329606,\n",
       " 4.830049930354046,\n",
       " 3.882241447712457,\n",
       " 4.699730506825973,\n",
       " 4.263339622985481,\n",
       " 4.239590285248368,\n",
       " 4.376097075041523,\n",
       " 4.270847398750225,\n",
       " 4.650095202512716,\n",
       " 5,\n",
       " 4.1677863721128325,\n",
       " 3.6936396268136678,\n",
       " 3.5182639190032785,\n",
       " 4.674521628924734,\n",
       " 4.748351056545202,\n",
       " 4.725829766892863,\n",
       " 4.423399842235243,\n",
       " 3.823955973363952,\n",
       " 4.031730129480749,\n",
       " 3.2986185993259896,\n",
       " 3.0352932727564315,\n",
       " 4.156290716597999,\n",
       " 4.146453297482889,\n",
       " 4.427057508541563,\n",
       " 3.1149484946539925,\n",
       " 3.889495710122814,\n",
       " 3.3773410439001945,\n",
       " 4.060507742767404,\n",
       " 3.243593572907824,\n",
       " 3.956420506927549,\n",
       " 2.9655089028673403,\n",
       " 3.868752885649499,\n",
       " 4.1652142272895345,\n",
       " 3.177610598608261,\n",
       " 3.140430283906247,\n",
       " 2.699504886880721,\n",
       " 4.3993691549393175,\n",
       " 3.648455645529884,\n",
       " 4.187749157552119,\n",
       " 3.8466409577215237,\n",
       " 3.749459549974009,\n",
       " 3.6276962056813438,\n",
       " 4.394206720722917,\n",
       " 3.28477034304004,\n",
       " 4.15195445217323,\n",
       " 4.2473175738542785,\n",
       " 3.5539825203069193,\n",
       " 4.215679940530958,\n",
       " 2.9683214004733736,\n",
       " 4.653088786237726,\n",
       " 3.572624886641266,\n",
       " 3.9909278420038015,\n",
       " 3.558511510658402,\n",
       " 3.2430673562270687,\n",
       " 3.1010245181231464,\n",
       " 4.052176475792213,\n",
       " 3.0346601826212893,\n",
       " 2.9442917353188736,\n",
       " 3.67140336239901,\n",
       " 3.5810935375164052,\n",
       " 4.169228642160298,\n",
       " 3.7113993005407657,\n",
       " 3.9080362996533924,\n",
       " 3.7919199689386955,\n",
       " 3.892027356648067,\n",
       " 4.083894106772525,\n",
       " 4.140745033932949,\n",
       " 3.402617337092601,\n",
       " 4.51070016434168,\n",
       " 3.693106870555827,\n",
       " 3.8754131056489434,\n",
       " 3.93604904493014,\n",
       " 3.0212645833956913,\n",
       " 3.6388575746033975,\n",
       " 4.034669162183434,\n",
       " 3.844682040038591,\n",
       " 3.4505858672615,\n",
       " 3.973465167158527,\n",
       " 4.572204171610951,\n",
       " 4.413706515606749,\n",
       " 3.582556729459052,\n",
       " 4.635819044609759,\n",
       " 4.28992919030423,\n",
       " 3.0449337527842304,\n",
       " 4.711675953701797,\n",
       " 3.856690167543196,\n",
       " 2.852576109714334,\n",
       " 3.0687667503435243,\n",
       " 3.7994644191267315,\n",
       " 3.5747065198213814,\n",
       " 4.3535307809169375,\n",
       " 3.875422833230759,\n",
       " 4.418795695568132,\n",
       " 4.865514428965056,\n",
       " 3.5405300473475068,\n",
       " 4.390510228108157,\n",
       " 3.5817452892364186,\n",
       " 4.0296634930989015,\n",
       " 3.0817936655128504,\n",
       " 3.324285234759227,\n",
       " 3.574990511187695,\n",
       " 4.25516015446659,\n",
       " 3.146570576324675,\n",
       " 3.542336277525292,\n",
       " 4.112508934178505,\n",
       " 3.41701857584401,\n",
       " 3.447968211338478,\n",
       " 3.1914390289005943,\n",
       " 3.3929887360435065,\n",
       " 3.6142960992427735,\n",
       " 3.1238903917795087,\n",
       " 3.3501997112961037,\n",
       " 3.381243092948948,\n",
       " 3.243893133738749,\n",
       " 3.7417381807634724,\n",
       " 3.4392261584839745,\n",
       " 4.183035236992703,\n",
       " 2.972100268091557,\n",
       " 3.2509990733101173,\n",
       " 3.554692037490144,\n",
       " 3.8635011007365625,\n",
       " 3.7103302484013905,\n",
       " 4.5098636747212195,\n",
       " 3.7786060180945333,\n",
       " 3.472794216631955,\n",
       " 4.076435438824852,\n",
       " 3.2856498585799243,\n",
       " 4.090800968499968,\n",
       " 3.6949487133973142,\n",
       " 3.903618124305005,\n",
       " 4.377497956960162,\n",
       " 3.609405452666787,\n",
       " 4.562867219581099,\n",
       " 3.099550055559965,\n",
       " 3.5923689863101904,\n",
       " 3.727846629548514,\n",
       " 4.030376532664325,\n",
       " 4.201951335513663,\n",
       " 4.56922385235853,\n",
       " 3.196571677528768,\n",
       " 3.9871782104218143,\n",
       " 4.358730336010625,\n",
       " 4.383024818341528,\n",
       " 3.4253590075314317,\n",
       " 3.0612793156193834,\n",
       " 3.969596458647768,\n",
       " 3.859764126043032,\n",
       " 2.655262860584616,\n",
       " 4.437989473516523,\n",
       " 4.390016259301293,\n",
       " 4.443035444576743,\n",
       " 2.767592074020714,\n",
       " 3.63624980785159,\n",
       " 3.4385660345673164,\n",
       " 2.8344608724489904,\n",
       " 3.443870060204009,\n",
       " 3.3946624691175695,\n",
       " 4.509039383120362,\n",
       " 3.7119777781344983,\n",
       " 3.476289255547175,\n",
       " 2.872327700370983,\n",
       " 3.505945202485089,\n",
       " 3.2637210761255733,\n",
       " 3.38826974239024,\n",
       " 3.3741314082772824,\n",
       " 2.9030571277836534,\n",
       " 3.201073273891589,\n",
       " 3.4292038663178523,\n",
       " 4.027892653518496,\n",
       " 3.6981395854032244,\n",
       " 3.7828297290037765,\n",
       " 3.416156318080971,\n",
       " 3.0610374429833933,\n",
       " 4.107344883893858,\n",
       " 3.601317075083802,\n",
       " 3.078564985341645,\n",
       " 3.270865696973181,\n",
       " 2.925939481766606,\n",
       " 3.522462792438874,\n",
       " 4.326577287359853,\n",
       " 3.738208267406685,\n",
       " 3.158214258896961,\n",
       " 3.2663508969504207,\n",
       " 3.0562618133644586,\n",
       " 3.7658384824891296,\n",
       " 3.5248514703921834,\n",
       " 3.116537823172747,\n",
       " 3.0901054481566135,\n",
       " 3.6741879846851075,\n",
       " 4.166413014526055,\n",
       " 3.7351122060871336,\n",
       " 2.8452170186959,\n",
       " 2.9053664008358333,\n",
       " 4.072626234175889,\n",
       " 4.000932367050117,\n",
       " 3.3559452800303244,\n",
       " 2.770000188151711,\n",
       " 3.276638952801914,\n",
       " 3.586689417439216,\n",
       " 3.56418824512581,\n",
       " 3.1741515964097107,\n",
       " 3.081607111605285,\n",
       " 3.8396923514239405,\n",
       " 4.257033477674551,\n",
       " 3.83767212661151,\n",
       " 4.040267393460899,\n",
       " 2.889420474246444,\n",
       " 3.010186434228872,\n",
       " 3.679273650434239,\n",
       " 3.3349845275437002,\n",
       " 3.002221317280665,\n",
       " 3.5750464913302875,\n",
       " 3.2355647072848286,\n",
       " 3.8679277315696736,\n",
       " 3.854035209895313,\n",
       " 2.4917915732274887,\n",
       " 3.6173797262813596,\n",
       " 2.9404021955336144,\n",
       " 4.258593589359659,\n",
       " 3.9458701523880566,\n",
       " 3.4644615662790312,\n",
       " 4.086122140280337,\n",
       " 3.1648273260890045,\n",
       " 3.7209199963887323,\n",
       " 4.456715720590361,\n",
       " 3.3233706099638165,\n",
       " 3.768636566248947,\n",
       " 4.786033396541129,\n",
       " 3.0448034202919594,\n",
       " 3.391188012629703,\n",
       " 3.43279491817882,\n",
       " 3.663147353073962,\n",
       " 4.116825320022568,\n",
       " 3.6748691105526996,\n",
       " 3.446318922315598,\n",
       " 3.9699347957531903,\n",
       " 3.228579733843941,\n",
       " 4.5817458554372275,\n",
       " 4.018756010245249,\n",
       " 3.3230545227353447,\n",
       " 3.5719085221964466,\n",
       " 3.748255482403119,\n",
       " 3.4649272648533826,\n",
       " 3.74165826560174,\n",
       " 3.9872541582885357,\n",
       " 4.018340696547043,\n",
       " 3.2301065162049705,\n",
       " 3.9222862144067183,\n",
       " 3.3496596607213682,\n",
       " 4.0876142453483935,\n",
       " 3.1803157021056645,\n",
       " 2.8356847766429674,\n",
       " 3.1453258123681143,\n",
       " 3.383096098486357,\n",
       " 3.4784455907378344,\n",
       " 3.204363950672173,\n",
       " 2.8452705472391346,\n",
       " 3.4039244884869237,\n",
       " 3.927604370316153,\n",
       " 3.0163578187923252,\n",
       " 2.323492049055916,\n",
       " 3.4416300535791415,\n",
       " 3.99276446699854,\n",
       " 3.711971442726235,\n",
       " 3.0737075494518624,\n",
       " 4.3022149707343065,\n",
       " 4.302102566779778,\n",
       " 3.572686366898427,\n",
       " 3.6010349243690016,\n",
       " 3.5630242982925524,\n",
       " 4.053228371707571,\n",
       " 3.21527042054659,\n",
       " 4.733252982475669,\n",
       " 3.872802646043218,\n",
       " 2.636195358641,\n",
       " 3.9699755788579263,\n",
       " 2.7665725408896886,\n",
       " 3.946204692007359,\n",
       " 4.496788836669158,\n",
       " 3.936800482693648,\n",
       " 2.6324047287618186,\n",
       " 3.629573653384487,\n",
       " 3.3354202223386697,\n",
       " 2.834995896746917,\n",
       " 3.0579304333831665,\n",
       " 3.255727572922334,\n",
       " 4.248909412041013,\n",
       " 3.822838787563163,\n",
       " 4.454767295213642,\n",
       " 3.0280034959567925,\n",
       " 3.7728387590613712,\n",
       " 3.757030406477448,\n",
       " 3.6393875675156826,\n",
       " 3.278452854346681,\n",
       " 3.8118884584536668,\n",
       " 3.6185948786499025,\n",
       " 2.620453521440357,\n",
       " 3.0786311490443468,\n",
       " 3.353428308532816,\n",
       " 2.6909115231126144,\n",
       " 3.338813344808837,\n",
       " 4.424099695857634,\n",
       " 3.096056757496324,\n",
       " 4.490065248040481,\n",
       " 3.310901891904167,\n",
       " 3.5901869908927098,\n",
       " 3.7215610262840557,\n",
       " 4.136798501031559,\n",
       " 2.748642944987384,\n",
       " 3.3901245482836324,\n",
       " 3.760972451946495,\n",
       " 4.093969020049472,\n",
       " 3.3808085834582813,\n",
       " 3.1883552860427007,\n",
       " 4.199629499492187,\n",
       " 3.8665062257527087,\n",
       " 3.0372163817634967,\n",
       " 2.94702967543198,\n",
       " 3.8870329708007265,\n",
       " 3.737998189602716,\n",
       " 3.905535321273931,\n",
       " 3.6926285357088737,\n",
       " 3.6270359916223995,\n",
       " 3.4431638409771472,\n",
       " 3.73280802749695,\n",
       " 4.181563285731016,\n",
       " 4.001924784130647,\n",
       " 2.9355751921647686,\n",
       " 3.7322091788692684,\n",
       " 3.287717638470581,\n",
       " 3.8301994752886164,\n",
       " 2.8308380540898157,\n",
       " 3.9318935715454377,\n",
       " 2.602642016892927,\n",
       " 3.7585062785924936,\n",
       " 3.5192696748878673,\n",
       " 3.8535806765019935,\n",
       " 3.8342307911402673,\n",
       " 2.700088922762212,\n",
       " 4.114401263447368,\n",
       " 3.8381607907456687,\n",
       " 3.9329378289580403,\n",
       " 3.5976015233748537,\n",
       " 3.4823684644847535,\n",
       " 3.4689888012740924,\n",
       " 2.8833678088987433,\n",
       " 3.663869492971238,\n",
       " 2.6368022384619727,\n",
       " 3.606170408772546,\n",
       " 3.793017496562052,\n",
       " 2.7687299881179,\n",
       " 3.816952537770411,\n",
       " 3.5390326586107883,\n",
       " 3.4992456182832443,\n",
       " 3.434955786452678,\n",
       " 3.0980057419175058,\n",
       " 4.197123073031123,\n",
       " 3.8191002377346863,\n",
       " 4.082341290528779,\n",
       " 3.7753866745990097,\n",
       " 2.83469674878493,\n",
       " 3.8145519002355384,\n",
       " 3.003012356438584,\n",
       " 3.7062335757814293,\n",
       " 3.651840381460134,\n",
       " 3.817941213899506,\n",
       " 4.346299326886173,\n",
       " 3.8496412617919473,\n",
       " 3.943129018474867,\n",
       " 3.3695504564752015,\n",
       " 4.000227535303001,\n",
       " 3.6493422457148186,\n",
       " 3.0555907799302453,\n",
       " 4.047062509662974,\n",
       " 3.4697391729195504,\n",
       " 3.915679390468228,\n",
       " 3.541726009493453,\n",
       " 3.4128504415957197,\n",
       " 3.6462125845997764,\n",
       " 3.7579747030043897,\n",
       " 3.069242452639721,\n",
       " 3.870666398540265,\n",
       " 3.032843866496726,\n",
       " 3.613486625141667,\n",
       " 3.537303100570758,\n",
       " 4.353561428553171,\n",
       " 3.6160307252180615,\n",
       " 3.3482737190046215,\n",
       " 4.032113483649199,\n",
       " 4.0130621844404395,\n",
       " 2.669011810717983,\n",
       " 3.2727046965926365,\n",
       " 4.06430210275509,\n",
       " 3.744501120181279,\n",
       " 3.299687870999787,\n",
       " 3.708711711200579,\n",
       " 3.7257134145964126,\n",
       " 3.0196660364825556,\n",
       " 3.187776363369516,\n",
       " 2.899994175619303,\n",
       " 2.7136905690761606,\n",
       " 4.0400173776781285,\n",
       " 3.431219169233538,\n",
       " 3.5788790924664347,\n",
       " 2.6272898870565413,\n",
       " 4.006998136037277,\n",
       " 3.9731861664920363,\n",
       " 3.1508684252352905,\n",
       " 3.6679875249281766,\n",
       " 3.5455968127954742,\n",
       " 3.233183746108968,\n",
       " 3.455859937092492,\n",
       " 3.9868883646797406,\n",
       " 3.7344695602670823,\n",
       " 2.815898548680533,\n",
       " 2.4164787108051664,\n",
       " 3.8132179464882068,\n",
       " 3.380476038786975,\n",
       " 3.661175953869269,\n",
       " 3.4009770578451044,\n",
       " 2.4581654624203337,\n",
       " 3.721118650983676,\n",
       " 3.3571556868413794,\n",
       " 4.032833907256104,\n",
       " 3.60953456877695,\n",
       " 3.4282275768458623,\n",
       " 2.9914815594986477,\n",
       " 4.21010728592212,\n",
       " 3.6112781512885577,\n",
       " 3.6600105380083106,\n",
       " 2.6194815721769684,\n",
       " 2.7824927277840623,\n",
       " 3.3418611029147214,\n",
       " 3.864898563760558,\n",
       " 3.913626067529257,\n",
       " 2.9476925719927514,\n",
       " 3.8476291790971797,\n",
       " 3.2243412859628005,\n",
       " 3.776323854373485,\n",
       " 3.8778434691734995,\n",
       " 3.7314029881300033,\n",
       " 4.075798465446956,\n",
       " 3.453619731238438,\n",
       " 3.501338502465571,\n",
       " 4.383374292597708,\n",
       " 3.8234357462385433,\n",
       " 3.7920534511057533,\n",
       " 3.851690178483406,\n",
       " 3.526958776123033,\n",
       " 3.89978414965486,\n",
       " 3.660956984069669,\n",
       " 4.065553489854106,\n",
       " 3.7889385889245335,\n",
       " 3.750527975450011,\n",
       " 3.9251701429613157,\n",
       " 3.510544957515468,\n",
       " 3.9247319406407564,\n",
       " 4.027310528901469,\n",
       " 2.633680229817502,\n",
       " 3.6680242519714166,\n",
       " 3.7881156016171573,\n",
       " 3.0375825826333216,\n",
       " 3.98130497676459,\n",
       " 3.312941291003078,\n",
       " 2.9797230312649967,\n",
       " 4.056624639274787,\n",
       " 3.5697712723762036,\n",
       " 3.0660848084793173,\n",
       " 4.190023644151563,\n",
       " 3.8744334315706594,\n",
       " 3.502228730332752,\n",
       " 3.2256234532235175,\n",
       " 2.368511944809709,\n",
       " 3.4551706649513996,\n",
       " 3.0649394951033972,\n",
       " 2.808523131810591,\n",
       " 3.902639677475413,\n",
       " 2.7477147245328744,\n",
       " 3.5098738805259506,\n",
       " 3.081797155330603,\n",
       " 3.178456824895931,\n",
       " 4.102975633167605,\n",
       " 3.6305169544200893,\n",
       " 3.7335577644007243,\n",
       " 3.4090935764324666,\n",
       " 3.9738094454293567,\n",
       " 3.0527620858489297,\n",
       " 2.9147729496820536,\n",
       " 4.166017599532008,\n",
       " 3.0566076252638212,\n",
       " 3.7873352082463323,\n",
       " 4.108860017121733,\n",
       " 3.453246997064977,\n",
       " 3.729869524603783,\n",
       " 3.4835083342666966,\n",
       " 3.5075564174454095,\n",
       " 3.493225404523577,\n",
       " 2.9287063964320557,\n",
       " 3.4873068749063827,\n",
       " 3.9058048016228724,\n",
       " 3.979114519030484,\n",
       " 3.2475321719614265,\n",
       " 3.942774076165319,\n",
       " 3.7825609123554718,\n",
       " 3.3555202850827768,\n",
       " 4.149909488031543,\n",
       " 3.389008698420888,\n",
       " 3.852919869595797,\n",
       " 3.451368528264316,\n",
       " 3.0370882498115597,\n",
       " 3.5881904529755073,\n",
       " 3.389794790937705,\n",
       " 3.636495120368935,\n",
       " 3.5280560274846744,\n",
       " 4.064162629284333,\n",
       " 4.2795758626784774,\n",
       " 3.4769230272087825,\n",
       " 3.42149974378852,\n",
       " 3.97896909824044,\n",
       " 4.250450286279708,\n",
       " 4.10833779360328,\n",
       " 3.082330401301654,\n",
       " 3.959842356820062,\n",
       " 3.4176197974418367,\n",
       " 3.390890516573728,\n",
       " 4.0499965088418,\n",
       " 3.2740477835731383,\n",
       " 3.645156744289572,\n",
       " 4.171014076144758,\n",
       " 3.933846350007761,\n",
       " 3.47144692995813,\n",
       " 3.322849273150573,\n",
       " 2.9706049000420967,\n",
       " 3.837091931988994,\n",
       " 3.88215284693863,\n",
       " 2.831081068060614,\n",
       " 3.9678035280830897,\n",
       " 3.328390931108416,\n",
       " 3.821323234284158,\n",
       " 3.7879387935687405,\n",
       " 2.959648994470427,\n",
       " 4.2292529144584705,\n",
       " 4.163246209317896,\n",
       " 4.393835971258752,\n",
       " 3.2882209015702686,\n",
       " 4.198674210447553,\n",
       " 4.652571487495585,\n",
       " 3.906716940813481,\n",
       " 4.435932545307672,\n",
       " 3.9399459592023223,\n",
       " 3.7526362570798932,\n",
       " 4.129123812403266,\n",
       " 3.768761560354265,\n",
       " 4.088595355299064,\n",
       " 3.3530400383385683,\n",
       " 3.8186570743407904,\n",
       " 4.14291622530542,\n",
       " 2.7110890838578126,\n",
       " 4.12004246495431,\n",
       " 3.9561370203938435,\n",
       " 4.207828062784404,\n",
       " 4.0132162456263565,\n",
       " 4.106566470365008,\n",
       " 3.277997754494643,\n",
       " 3.99038212315186,\n",
       " 3.8177867907125975,\n",
       " 4.4347441418110956,\n",
       " 4.469176365173298,\n",
       " 4.1079923988172204,\n",
       " 4.037911981083087,\n",
       " 4.166668323380499,\n",
       " 4.339956410115315,\n",
       " 3.6525266673068733,\n",
       " 3.144758091504114,\n",
       " 4.042554433687209,\n",
       " 3.4757498897672385,\n",
       " 4.3854229008617045,\n",
       " 4.012814763452052,\n",
       " 3.4360839092957645,\n",
       " 4.2399264894410145,\n",
       " 4.232214481449798,\n",
       " 3.405775286834142,\n",
       " 4.540146695351435,\n",
       " 4.426973858028863,\n",
       " 3.740118582869415,\n",
       " 3.9554344001825856,\n",
       " 4.783120255463141,\n",
       " 3.4144108311240395,\n",
       " 3.8230969059687263,\n",
       " 4.546004912436285,\n",
       " 3.1910668075116466,\n",
       " 4.09532311322807,\n",
       " 3.790667039418865,\n",
       " 3.780806033111927,\n",
       " 3.9450951176696285,\n",
       " 4.469033740120604,\n",
       " 4.34553597640413,\n",
       " 3.9899155936684463,\n",
       " 3.813712910835764,\n",
       " 3.9675296566481597,\n",
       " 3.0339705688593814,\n",
       " 4.462207624512534,\n",
       " 4.247431762374263,\n",
       " 4.165373116935485,\n",
       " 4.192473175083182,\n",
       " 4.1930189062681125,\n",
       " 4.430583522631407,\n",
       " 4.053852132655214,\n",
       " 4.202869034972939,\n",
       " 3.7901636400448546,\n",
       " 3.6205113951677603,\n",
       " 3.8045215200404097,\n",
       " 3.637829286045364,\n",
       " 3.2604562135656283,\n",
       " 3.2678072350421665,\n",
       " 4.3480750267551445,\n",
       " 4.203153341392641,\n",
       " 4.087190816847552,\n",
       " 3.591205555996744,\n",
       " 3.89464859772992,\n",
       " 4.603969717989438,\n",
       " 3.9496028352290176,\n",
       " 4.419411471377042,\n",
       " 3.1857845816647314,\n",
       " 3.4623012036226517,\n",
       " 3.839586916546504,\n",
       " 3.6013158266169225,\n",
       " 3.659949914458342,\n",
       " 3.4897121119256056,\n",
       " 4.40676398572233,\n",
       " 4.214914660849687,\n",
       " 4.35924576210622,\n",
       " 4.401699861929462,\n",
       " ...]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.7195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.719504723761859"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise.accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of V (per item vectors): \n",
      "(1662, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of V (per item vectors): \")\n",
    "print(model.qi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The real way to use the surprise package + some scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7670608818265595\n",
      "{'n_epochs': 100, 'lr_all': 0.005, 'reg_all': 0.4, 'n_factors': 2}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "param_grid = {'n_epochs': [10, 100], 'lr_all': [0.005, 0.05],\n",
    "              'reg_all': [0.4, 0.6], 'n_factors': [2, 10, 50]}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['mae'], cv=3)\n",
    "\n",
    "gs.fit(dev_set)\n",
    "\n",
    "# best MAE score\n",
    "print(gs.best_score['mae'])\n",
    "\n",
    "# combination of parameters that gave the best MAE score\n",
    "print(gs.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id item_id rating\n",
      "0     503     204    NaN\n"
     ]
    }
   ],
   "source": [
    "# For leaderboard SVD\n",
    "test_data_lb = pd.read_csv('data_movie_lens_100k/ratings_masked_leaderboard_set.csv', dtype=str)\n",
    "test_dataset_lb = Dataset.load_from_df(test_data_lb, reader=reader)\n",
    "test_datasetL_lb_to_use = test_dataset_lb.build_full_trainset().build_testset()\n",
    "\n",
    "\n",
    "model = surprise.SVD(n_factors=2, n_epochs=100, lr_all=0.005, reg_all=0.4, random_state=100)\n",
    "model.fit(dev_set_for_fit)\n",
    "\n",
    "predictions_leaderboard = model.test(test_datasetL_lb_to_use)\n",
    "pred_ratings_test_leaderboard = [pred.est for pred in predictions_leaderboard]\n",
    "\n",
    "np.savetxt(fname='predicted_ratings_leaderboard.txt', X=pred_ratings_test_leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For leaderboard SVD -- one prediction at a time\n",
    "def predict_leaderboard_surprise(fitted_model):\n",
    "    test_data_lb_df = pd.read_csv('data_movie_lens_100k/ratings_masked_leaderboard_set.csv', dtype=str)\n",
    "    predictions_for_document = list()\n",
    "    \n",
    "    for i in range(len(test_data_lb_df.index)):\n",
    "        singleton_df = test_data_lb_df.iloc[i:i+1]\n",
    "\n",
    "        test_dataset_lb = Dataset.load_from_df(singleton_df, reader=reader)\n",
    "        test_datasetL_lb_to_use = test_dataset_lb.build_full_trainset().build_testset()\n",
    "\n",
    "        predictions_leaderboard = fitted_model.test(test_datasetL_lb_to_use)\n",
    "        pred_ratings_test_leaderboard = [pred.est for pred in predictions_leaderboard]\n",
    "        \n",
    "        predictions_for_document.append(pred_ratings_test_leaderboard)\n",
    "\n",
    "    np.savetxt(fname='predicted_ratings_leaderboard.txt', X=predictions_for_document)\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "model = surprise.SVD(n_factors=2, n_epochs=100, lr_all=0.005, reg_all=0.4, random_state=100)\n",
    "model.fit(dev_set_for_fit)\n",
    "predict_leaderboard_surprise(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVDpp\n",
    "from surprise.model_selection import GridSearchCV\n",
    "param_grid = {'n_epochs': [10, 100], 'lr_all': [0.005, 0.05],\n",
    "              'reg_all': [0.4, 0.6], 'n_factors': [2, 10, 50]}\n",
    "\n",
    "gs = GridSearchCV(SVDpp, param_grid, measures=['mae'], cv=3)\n",
    "\n",
    "gs.fit(dev_set)\n",
    "\n",
    "# best MAE score\n",
    "print(gs.best_score['mae'])\n",
    "\n",
    "# combination of parameters that gave the best MAE score\n",
    "print(gs.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.7552682713304354\n",
      "{'k': 75}\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNWithMeans\n",
    "\n",
    "param_grid = {'k': [1, 2, 5, 10, 25, 50, 75, 100]}\n",
    "\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=['mae'], cv=3)\n",
    "\n",
    "gs.fit(dev_set)\n",
    "\n",
    "# best MAE score\n",
    "print(gs.best_score['mae'])\n",
    "\n",
    "# combination of parameters that gave the best MAE score\n",
    "print(gs.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.7287\n",
      "n_epochs= 10 n_factors= 2 lr= 0.005 MAE= 0.7287320694099013\n",
      "MAE:  0.6769\n",
      "n_epochs= 10 n_factors= 2 lr= 0.05 MAE= 0.6769477162302701\n",
      "MAE:  0.7236\n",
      "n_epochs= 10 n_factors= 10 lr= 0.005 MAE= 0.7236111624828467\n",
      "MAE:  0.5706\n",
      "n_epochs= 10 n_factors= 10 lr= 0.05 MAE= 0.5705911994638758\n",
      "MAE:  0.6960\n",
      "n_epochs= 10 n_factors= 50 lr= 0.005 MAE= 0.6960446333271161\n",
      "MAE:  0.2987\n",
      "n_epochs= 10 n_factors= 50 lr= 0.05 MAE= 0.2987074682219659\n",
      "MAE:  0.6597\n",
      "n_epochs= 100 n_factors= 2 lr= 0.005 MAE= 0.6597044976313768\n",
      "MAE:  0.6706\n",
      "n_epochs= 100 n_factors= 2 lr= 0.05 MAE= 0.6705688149998453\n",
      "MAE:  0.5462\n",
      "n_epochs= 100 n_factors= 10 lr= 0.005 MAE= 0.5461735874580168\n",
      "MAE:  0.5356\n",
      "n_epochs= 100 n_factors= 10 lr= 0.05 MAE= 0.5355770562745512\n",
      "MAE:  0.2868\n",
      "n_epochs= 100 n_factors= 50 lr= 0.005 MAE= 0.2867664109695388\n",
      "MAE:  0.2098\n",
      "n_epochs= 100 n_factors= 50 lr= 0.05 MAE= 0.20982254334441225\n"
     ]
    }
   ],
   "source": [
    "# Trying with diff # of factors and epochs\n",
    "N_epochs = [10, 100]\n",
    "N_factors = [2, 10, 50]\n",
    "N_lr = [0.005, 0.05]\n",
    "for n_epochs in N_epochs:\n",
    "    for n_factors in N_factors:\n",
    "        for lr in N_lr:\n",
    "            model = surprise.SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr, random_state=100)\n",
    "            model.fit(dev_set_for_fit)\n",
    "            predictions = model.test(dev_set_for_predict)\n",
    "            print('n_epochs=', n_epochs, 'n_factors=', n_factors, 'lr=', lr, 'MAE=', surprise.accuracy.mae(predictions, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the report Problem 4\n",
    "We tried SVD. The error on the heldout was really good, down to 0.2, but when submitting to the Leaderboard, the error was really bad (worse than 1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training set form the current training set (training tuple), then choose hyperparam on the validation set \n",
    "# (create validation set by calling .build_full_trainset().build_testset() on the validation set we have). Finally,\n",
    "# retrain the model using the chosen hyperparameters on both the training and validation dataset and test on the test set\n",
    "# (again, create the test set by doing .build_full_trainset().build_testset() on the test set.) \n",
    "\n",
    "# for the leaderboard\n",
    "\n",
    "# Read test data as a pandas dataframe\n",
    "# The important bit here is dtype=str, so that it matches your training data\n",
    "test_data = pd.read_csv('data_movie_lens_100k/ratings_masked_leaderboard_set.csv', dtype=str)\n",
    "# Now we turn that dataframe into a surprise Dataset, using the reader object from the surprise demo\n",
    "test_data = Dataset.load_from_df(test_data, reader=reader)\n",
    "# Now we have to turn it into a... TestSet?? by first turning it into a TrainSet???\n",
    "# This part is weird...\n",
    "test_data = test_data.build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = surprise.SVD(n_factors=10, n_epochs=10, lr_all=0.005, random_state=100)\n",
    "model.fit(dev_set_for_fit)\n",
    "\n",
    "predictions = model.test(test_data)\n",
    "pred_ratings_test = [pred.est for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(fname='predicted_ratings_leaderboard.txt', X=pred_ratings_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the train - valid - test data problem for the surprise package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>662</td>\n",
       "      <td>761</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>912</td>\n",
       "      <td>917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>415</td>\n",
       "      <td>813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>842</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>574</td>\n",
       "      <td>505</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>757</td>\n",
       "      <td>472</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>503</td>\n",
       "      <td>204</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating\n",
       "0          662      761       5\n",
       "1          298       90       4\n",
       "2           90      349       4\n",
       "3          912      917       4\n",
       "4          302       42       3\n",
       "...        ...      ...     ...\n",
       "69995      415      813       4\n",
       "69996      842      120       3\n",
       "69997      574      505       2\n",
       "69998      757      472       5\n",
       "69999      503      204       3\n",
       "\n",
       "[70000 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_tuple, test_tuple, valid_tuple, n_users, n_items = load_train_valid_test_datasets(data_path=data_path)\n",
    "\n",
    "#print(train_tuple)\n",
    "N = len(train_tuple[0])\n",
    "print(N)\n",
    "tr_data = np.hstack((np.hstack((train_tuple[0].reshape((N, 1)), train_tuple[1].reshape((N, 1)))), train_tuple[2].reshape((N, 1))))\n",
    "df_tr = pd.DataFrame(data=tr_data, columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "df_tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>772</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>471</td>\n",
       "      <td>228</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>641</td>\n",
       "      <td>401</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>312</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>504</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>221</td>\n",
       "      <td>1218</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>91</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>926</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>522</td>\n",
       "      <td>547</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>788</td>\n",
       "      <td>247</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  rating\n",
       "0         772       36       3\n",
       "1         471      228       5\n",
       "2         641      401       4\n",
       "3         312       98       4\n",
       "4          58      504       5\n",
       "...       ...      ...     ...\n",
       "9995      221     1218       4\n",
       "9996       91      594       2\n",
       "9997      926       94       5\n",
       "9998      522      547       4\n",
       "9999      788      247       3\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_va = len(valid_tuple[0])\n",
    "print(N_va)\n",
    "va_data = np.hstack((np.hstack((valid_tuple[0].reshape((N_va, 1)), valid_tuple[1].reshape((N_va, 1)))), valid_tuple[2].reshape((N_va, 1))))\n",
    "df_va = pd.DataFrame(data=va_data, columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "df_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>392</td>\n",
       "      <td>783</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>586</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261</td>\n",
       "      <td>776</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>660</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>269</td>\n",
       "      <td>277</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>900</td>\n",
       "      <td>433</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>151</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>275</td>\n",
       "      <td>1093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>378</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9992 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  rating\n",
       "0         392      783       3\n",
       "1          56      586       4\n",
       "2         261      776       4\n",
       "3         449      660       4\n",
       "4         268      119       1\n",
       "...       ...      ...     ...\n",
       "9987      269      277       5\n",
       "9988      900      433       5\n",
       "9989      151      110       5\n",
       "9990      275     1093       1\n",
       "9991      378       88       4\n",
       "\n",
       "[9992 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_te = len(test_tuple[0])\n",
    "print(N_te)\n",
    "te_data = np.hstack((np.hstack((test_tuple[0].reshape((N_te, 1)), test_tuple[1].reshape((N_te, 1)))), test_tuple[2].reshape((N_te, 1))))\n",
    "df_te = pd.DataFrame(data=te_data, columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>662</td>\n",
       "      <td>761</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>912</td>\n",
       "      <td>917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>221</td>\n",
       "      <td>1218</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>91</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>926</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>522</td>\n",
       "      <td>547</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>788</td>\n",
       "      <td>247</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  rating\n",
       "0         662      761       5\n",
       "1         298       90       4\n",
       "2          90      349       4\n",
       "3         912      917       4\n",
       "4         302       42       3\n",
       "...       ...      ...     ...\n",
       "9995      221     1218       4\n",
       "9996       91      594       2\n",
       "9997      926       94       5\n",
       "9998      522      547       4\n",
       "9999      788      247       3\n",
       "\n",
       "[80000 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I have to join tr and va for the final model\n",
    "\n",
    "df_tr_va = df_tr.append(df_va)\n",
    "df_tr_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>662</td>\n",
       "      <td>761</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>912</td>\n",
       "      <td>917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>269</td>\n",
       "      <td>277</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>900</td>\n",
       "      <td>433</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>151</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>275</td>\n",
       "      <td>1093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>378</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89992 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  rating\n",
       "0         662      761       5\n",
       "1         298       90       4\n",
       "2          90      349       4\n",
       "3         912      917       4\n",
       "4         302       42       3\n",
       "...       ...      ...     ...\n",
       "9987      269      277       5\n",
       "9988      900      433       5\n",
       "9989      151      110       5\n",
       "9990      275     1093       1\n",
       "9991      378       88       4\n",
       "\n",
       "[89992 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr_all = df_tr_va.append(df_te) # for the leaderboard\n",
    "df_tr_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 SVD redone with the new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = Dataset.load_from_df(df_tr, reader=reader)\n",
    "va_dataset = Dataset.load_from_df(df_va, reader=reader)\n",
    "te_dataset = Dataset.load_from_df(df_te, reader=reader)\n",
    "\n",
    "tr_va_dataset = Dataset.load_from_df(df_tr_va, reader=reader)\n",
    "tr_all_dataset = Dataset.load_from_df(df_tr_all, reader=reader)\n",
    "\n",
    "tr_dataset_to_use = tr_dataset.build_full_trainset()\n",
    "va_dataset_to_use = va_dataset.build_full_trainset().build_testset()\n",
    "te_dataset_to_use = te_dataset.build_full_trainset().build_testset()\n",
    "\n",
    "tr_va_dataset_to_use = tr_va_dataset.build_full_trainset()\n",
    "tr_all_dataset_to_use = tr_all_dataset.build_full_trainset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epochs= 200 n_factors= 2 lr= 0.0005 MAE= 0.7427902566268069\n",
      "n_epochs= 200 n_factors= 2 lr= 0.005 MAE= 0.7302809683521548\n",
      "n_epochs= 200 n_factors= 10 lr= 0.0005 MAE= 0.7403163937649515\n",
      "n_epochs= 200 n_factors= 10 lr= 0.005 MAE= 0.7745971295515799\n",
      "n_epochs= 200 n_factors= 25 lr= 0.0005 MAE= 0.7386487557781783\n",
      "n_epochs= 200 n_factors= 25 lr= 0.005 MAE= 0.8216460336084914\n",
      "n_epochs= 200 n_factors= 50 lr= 0.0005 MAE= 0.7401001402789591\n",
      "n_epochs= 200 n_factors= 50 lr= 0.005 MAE= 0.8086281165783002\n",
      "n_epochs= 200 n_factors= 75 lr= 0.0005 MAE= 0.7398330737476907\n",
      "n_epochs= 200 n_factors= 75 lr= 0.005 MAE= 0.7890197194387587\n"
     ]
    }
   ],
   "source": [
    "# SEE CELL BELOW FOR RESULTS, NOT THIS ONE **************************************************************************\n",
    "N_epochs = [100]\n",
    "N_factors = [x for x in range(2, 50)]\n",
    "N_lr = [0.005]\n",
    "for n_epochs in N_epochs:\n",
    "    for n_factors in N_factors:\n",
    "        for lr in N_lr:\n",
    "            model = surprise.SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr, random_state=100)\n",
    "            model.fit(tr_dataset_to_use)\n",
    "            predictions = model.test(va_dataset_to_use)\n",
    "            print('n_epochs=', n_epochs, 'n_factors=', n_factors, 'lr=', lr, 'MAE=', surprise.accuracy.mae(predictions, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-aed94293e493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_epochs='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_factors='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' best MAE='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "N_factors = [x for x in range(2, 50)]\n",
    "maes = list()\n",
    "\n",
    "for n_factors in N_factors:\n",
    "    print(n_factors, end =\" \")\n",
    "    model = surprise.SVD(n_factors=n_factors, n_epochs=100, lr_all=0.005, random_state=100)\n",
    "    model.fit(tr_dataset_to_use)\n",
    "    predictions = model.test(va_dataset_to_use)\n",
    "    maes.append(surprise.accuracy.mae(predictions, verbose=False))\n",
    "\n",
    "\n",
    "print('n_epochs=', 100, 'n_factors=', n_factors[np.argmin(maes)], 'lr=', 0.005, ' best MAE=', np.min(maes))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epochs= 100 n_factors= 3 lr= 0.005  best MAE= 0.7277392342414558\n"
     ]
    }
   ],
   "source": [
    "print('n_epochs=', 100, 'n_factors=', N_factors[np.argmin(maes)], 'lr=', 0.005, ' best MAE=', np.min(maes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epochs= 100 n_factors= 3 lr= 0.005 MAE= 0.7304729740791633\n"
     ]
    }
   ],
   "source": [
    "# computing MAE on the test set\n",
    "# first, retraining on both tr+va dataset\n",
    "model = surprise.SVD(n_factors=3, n_epochs=100, lr_all=0.005, random_state=100)\n",
    "model.fit(tr_va_dataset_to_use)\n",
    "predictions = model.test(te_dataset_to_use)\n",
    "print('n_epochs=', 100, 'n_factors=', 3, 'lr=', 0.005, 'MAE=', surprise.accuracy.mae(predictions, verbose=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>503</td>\n",
       "      <td>204</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>795</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>403</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>327</td>\n",
       "      <td>740</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>463</td>\n",
       "      <td>292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>372</td>\n",
       "      <td>485</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>763</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>499</td>\n",
       "      <td>163</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>654</td>\n",
       "      <td>933</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id item_id rating\n",
       "0        503     204    NaN\n",
       "1        795     185    NaN\n",
       "2         42     403    NaN\n",
       "3        327     740    NaN\n",
       "4        285      98    NaN\n",
       "...      ...     ...    ...\n",
       "9995     463     292    NaN\n",
       "9996     372     485    NaN\n",
       "9997     763     190    NaN\n",
       "9998     499     163    NaN\n",
       "9999     654     933    NaN\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_lb_df = pd.read_csv('data_movie_lens_100k/ratings_masked_leaderboard_set.csv', dtype=str)\n",
    "#test_data_lb_df.iloc[1]\n",
    "test_data_lb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the leaderboard\n",
    "\n",
    "#def predict_leaderboard_surprise(fitted_model):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the leaderboard\n",
    "\n",
    "def predict_leaderboard_surprise(fitted_model):\n",
    "    test_data_lb_df = pd.read_csv('data_movie_lens_100k/ratings_masked_leaderboard_set.csv', dtype=str)\n",
    "    predictions_for_document = list()\n",
    "    \n",
    "    for i in range(len(test_data_lb_df.index)):\n",
    "        singleton_df = test_data_lb_df.iloc[i:i+1]\n",
    "\n",
    "        test_dataset_lb = Dataset.load_from_df(singleton_df, reader=reader)\n",
    "        test_datasetL_lb_to_use = test_dataset_lb.build_full_trainset().build_testset()\n",
    "\n",
    "        predictions_leaderboard = fitted_model.test(test_datasetL_lb_to_use)\n",
    "        pred_ratings_test_leaderboard = [pred.est for pred in predictions_leaderboard]\n",
    "        \n",
    "        predictions_for_document.append(pred_ratings_test_leaderboard)\n",
    "\n",
    "    np.savetxt(fname='predicted_ratings_leaderboard.txt', X=predictions_for_document)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "model = surprise.SVD(n_factors=3, n_epochs=100, lr_all=0.005, random_state=100)\n",
    "model.fit(tr_all_dataset_to_use)\n",
    "predict_leaderboard_surprise(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id item_id rating\n",
      "0     503     204    NaN\n"
     ]
    }
   ],
   "source": [
    "test_data_lb = pd.read_csv('data_movie_lens_100k/ratings_masked_leaderboard_set.csv', dtype=str)\n",
    "print(test_data_lb.iloc[0:1])\n",
    "test_dataset_lb = Dataset.load_from_df(test_data_lb, reader=reader)\n",
    "test_datasetL_lb_to_use = test_dataset_lb.build_full_trainset().build_testset()\n",
    "\n",
    "\n",
    "model = surprise.SVD(n_factors=3, n_epochs=100, lr_all=0.005, random_state=100)\n",
    "model.fit(tr_all_dataset_to_use)\n",
    "\n",
    "predictions_leaderboard = model.test(test_datasetL_lb_to_use)\n",
    "pred_ratings_test_leaderboard = [pred.est for pred in predictions_leaderboard]\n",
    "\n",
    "np.savetxt(fname='predicted_ratings_leaderboard.txt', X=pred_ratings_test_leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the whole dataset like before\n",
    "test_data_lb = pd.read_csv('data_movie_lens_100k/ratings_masked_leaderboard_set.csv', dtype=str)\n",
    "test_dataset_lb = Dataset.load_from_df(test_data_lb, reader=reader)\n",
    "test_datasetL_lb_to_use = test_dataset_lb.build_full_trainset().build_testset()\n",
    "\n",
    "\n",
    "model = surprise.SVD(n_factors=3, n_epochs=100, lr_all=0.005, random_state=100)\n",
    "model.fit(tr_all_dataset_to_use)\n",
    "\n",
    "\n",
    "predictions_leaderboard = model.test(test_datasetL_lb_to_use)\n",
    "pred_ratings_test_leaderboard = [pred.est for pred in predictions_leaderboard]\n",
    "\n",
    "np.savetxt(fname='predicted_ratings_leaderboard.txt', X=pred_ratings_test_leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 basic KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [x for x in range(20, 101)]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "min mae =  0.777074467502959 , with k =  23\n"
     ]
    }
   ],
   "source": [
    "#surprise.prediction_algorithms.knns.KNNBasic(k=40, min_k=1)\n",
    "# DENSE GRID (no early stopping since it was running very fast)\n",
    "\n",
    "# min mae =  0.777074467502959 , with k =  23\n",
    "\n",
    "ks = [x for x in range(1, 101)]\n",
    "maes = list()\n",
    "prev_mae = 100.\n",
    "for k in ks:\n",
    "    model = surprise.prediction_algorithms.knns.KNNBasic(k=k, random_state=100)\n",
    "    model.fit(tr_dataset_to_use)\n",
    "    predictions = model.test(va_dataset_to_use)\n",
    "    mae = surprise.accuracy.mae(predictions, verbose=False)\n",
    "    #print('k=', k, 'MAE=', mae)\n",
    "    maes.append(mae)\n",
    "    \n",
    "print('min mae = ', np.min(maes), ', with k = ', np.argmin(maes) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min mae =  0.777074467502959 , with k =  23\n"
     ]
    }
   ],
   "source": [
    "print('min mae = ', np.min(maes), ', with k = ', ks[np.argmin(maes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "k= 23 MAE= 0.7707467448339492\n"
     ]
    }
   ],
   "source": [
    "# computing MAE on the test set\n",
    "# first, retraining on both tr+va dataset\n",
    "model = surprise.prediction_algorithms.knns.KNNBasic(k=23, random_state=100) # TODO change k\n",
    "model.fit(tr_va_dataset_to_use)\n",
    "predictions = model.test(te_dataset_to_use)\n",
    "print('k=', 23, 'MAE=', surprise.accuracy.mae(predictions, verbose=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>orig_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>938</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>939</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>940</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>941</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>942</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  age  is_male  orig_user_id\n",
       "0          0   24        1             1\n",
       "1          1   53        0             2\n",
       "2          2   23        1             3\n",
       "3          3   24        1             4\n",
       "4          4   33        0             5\n",
       "..       ...  ...      ...           ...\n",
       "938      938   26        0           939\n",
       "939      939   32        1           940\n",
       "940      940   20        1           941\n",
       "941      941   48        0           942\n",
       "942      942   22        1           943\n",
       "\n",
       "[943 rows x 4 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read user info\n",
    "user_info_df = pd.read_csv('data_movie_lens_100k/user_info.csv')\n",
    "user_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(70000,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-1abd4e792a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple_all_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple_all_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtuple_all_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple_all_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple_all_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtuple_all_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple_all_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# create train data for our model by joining the train, valid and test sets (we already choose our hyperparameters\n",
    "# and which model is the best)\n",
    "\n",
    "tuple_all_data = train_tuple\n",
    "\n",
    "for i in range(len(tuple_all_data)):\n",
    "    print(len(tuple_all_data))\n",
    "    print(tuple_all_data[i].shape)\n",
    "    tuple_all_data[i] = np.vstack((tuple_all_data[i], valid_tuple[i]))\n",
    "    print(tuple_all_data[i].shape)\n",
    "    tuple_all_data[i] = np.concatvstack enate((tuple_all_data[i], test_tuple[i]))\n",
    "    print(tuple_all_data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the M3 again # TODO: ASK ISAAC FOR THE BEST PARAMS\n",
    "SEED = 100\n",
    "M3_2f = CollabFilterOneVectorPerItem(step_size=0.2, n_epochs=100, batch_size=1000, random_state=SEED, n_factors=2)\n",
    "\n",
    "M3_2f.init_parameter_dict(n_users=n_users, n_items=n_items, train_tuple=train_tuple)\n",
    "M3_2f.fit(train_data_tuple=train_tuple, valid_data_tuple=valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ProjectC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
